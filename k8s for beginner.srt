1
00:00:00,719 --> 00:00:03,040
你好，欢迎来到kubernetes课程完整版
hello and welcome to this complete

2
00:00:03,040 --> 00:00:06,640
这门课程将会有
kubernetes course the course is a mix of

3
00:00:06,640 --> 00:00:09,760
生动的理论解释
animated theoretic explanations but also

4
00:00:09,760 --> 00:00:13,360
和易于上手的实践演示
hands-on demos for you to follow along

5
00:00:13,360 --> 00:00:15,280
首先让我们快速浏览一下
so let's quickly go through the topics

6
00:00:15,280 --> 00:00:17,760
我会在这门课中讲到的知识点
i'll cover in this course

7
00:00:17,760 --> 00:00:20,000
第一部分将会
the first part gives you a great

8
00:00:20,000 --> 00:00:21,600
介绍kubernetes(简称k8s)
introduction to kubernetes

9
00:00:21,600 --> 00:00:23,840
我们将从基本概念开始
we'll start with the basic concepts of

10
00:00:23,840 --> 00:00:25,119
解释kubernetes是什么
what kubernetes actually

11
00:00:25,119 --> 00:00:27,119
它解决什么问题
is what problems it solves and the

12
00:00:27,119 --> 00:00:29,039
以及kubernetes的架构
kubernetes architecture

13
00:00:29,039 --> 00:00:30,560
通过展示kubernetes所有的主要组件
you will learn how you can use

14
00:00:30,560 --> 00:00:32,559
你会学到如何使用kubernetes
kubernetes by showcasing

15
00:00:32,559 --> 00:00:35,120
在学习主要概念之后
all the main components after learning

16
00:00:35,120 --> 00:00:36,399
我们将会
the main concepts

17
00:00:36,399 --> 00:00:38,640
学习和安装minikube
we will learn and install minikube for

18
00:00:38,640 --> 00:00:40,480
从而实现一个本地kubernetes集群
a local kubernetes cluster

19
00:00:40,480 --> 00:00:42,559
我们将学习如何通过通过kubectl命令
and we will go through the main commands

20
00:00:42,559 --> 00:00:45,520
来创建调试和删除一个pod
of creating debugging and deleting

21
00:00:45,520 --> 00:00:49,039
kubectl即为kubernetes的
pods using kubectl which is kubernetes

22
00:00:49,039 --> 00:00:50,480
命令行工具
command line tool

23
00:00:50,480 --> 00:00:53,440
在了解kubectl的主要命令后
after knowing kubectl main commands i

24
00:00:53,440 --> 00:00:55,039
我将解释kubernetes yaml
will explain kubernetes yaml

25
00:00:55,039 --> 00:00:56,640
配置文件
configuration files

26
00:00:56,640 --> 00:00:58,399
我们将用它来创建和
which we will use to create and

27
00:00:58,399 --> 00:01:00,879
配置组件
configure components

28
00:01:00,879 --> 00:01:02,960
然后我们将进行实际应用
then we will go through a practical use

29
00:01:02,960 --> 00:01:05,360
我们将部署一个简单的
case where we'll deploy a simple

30
00:01:05,360 --> 00:01:06,159
应用程序
application

31
00:01:06,159 --> 00:01:09,520
在kubernetes集群中进行本地设置
setup in kubernetes cluster locally

32
00:01:09,520 --> 00:01:12,640
来获得您的第一次使用kubernetes的实践经验
to get your first hands-on experience with kubernetes

33
00:01:12,640 --> 00:01:15,200
从而对使用该工具更有信心
and feel more confident about the tool

34
00:01:15,200 --> 00:01:16,479
在第二部分
in the second part

35
00:01:16,479 --> 00:01:19,360
我们会学习更高级且
we will go into more advanced and

36
00:01:19,360 --> 00:01:20,799
重要的概念
important concepts

37
00:01:20,799 --> 00:01:24,560
比如使用命名空间组织你的组件
like organizing your components using namespaces

38
00:01:24,560 --> 00:01:27,040
以及如何使用k8s Ingress
how to make your app available from

39
00:01:27,040 --> 00:01:28,960
让你的应用程序在kubernetes外部依然可用
outside using kubernetes

40
00:01:28,960 --> 00:01:31,520
同时学习helm
ingress and learn about helm which is

41
00:01:31,520 --> 00:01:32,880
它是k8s的包管理器
the package manager

42
00:01:32,880 --> 00:01:36,960
此外，我们还会更加深入地学习三个组件
for kubernetes in addition we will look at three components

43
00:01:36,960 --> 00:01:40,240
首先是如何在kubernetes中使用卷
in more detail first how to persist data

44
00:01:40,240 --> 00:01:42,399
来持久化数据
in kubernetes using volumes

45
00:01:42,399 --> 00:01:44,320
第二，如何部署有状态的
second how to deploy stateful

46
00:01:44,320 --> 00:01:46,399
应用程序，比如
applications like databases

47
00:01:46,399 --> 00:01:50,560
使用状态集组件地数据库
using stateful set component and lastly

48
00:01:50,560 --> 00:01:53,600
最后我们会看到对应不同用例的不同的kubernetes服务类型
we will look at the different kubernetes service types

49
00:01:53,600 --> 00:01:56,240
如果你喜欢这个课程
for different use cases if you like the

50
00:01:56,240 --> 00:01:57,920
记得订阅我的频道
course be sure to subscribe to my

51
00:01:57,920 --> 00:02:00,240
更多类似的视频
channel for more videos like this

52
00:02:00,240 --> 00:02:02,240
参见视频描述
and also check out the video description

53
00:02:02,240 --> 00:02:06,079
从而订阅更多相关的优达课程等
for more related courses on udemy etc

54
00:02:06,079 --> 00:02:08,239
如果你们课程或课程结束后
if you guys have any questions during

55
00:02:08,239 --> 00:02:10,160
有任何问题
the course or after the course

56
00:02:10,160 --> 00:02:12,319
或者你只是想保持联系
or you want to simply stay in touch i

57
00:02:12,319 --> 00:02:14,400
我很乐意在社交网站上与你们联系
would love to connect with you on social media

58
00:02:14,400 --> 00:02:22,400
所以一定要订阅我哦
so be sure to follow me there as well

59
00:02:22,400 --> 00:02:24,400
在这段视频中，我将解释
so in this video i'm going to explain

60
00:02:24,400 --> 00:02:25,760
什么是kubernetes
what kubernetes is

61
00:02:25,760 --> 00:02:26,800
我们将从定义开始
we're going to start off with the

62
00:02:26,800 --> 00:02:29,120
来看它的官方定义是什么
definition to see what

63
00:02:29,120 --> 00:02:31,519
以及发挥了什么作用
official definition is and what it does

64
00:02:31,519 --> 00:02:34,319
然后我们会看一个问题的解决方案作为案例
then we're going to look at the problem solution

65
00:02:34,319 --> 00:02:37,040
来分析kubernetes出现的主要原因
case study of kubernetes basically why

66
00:02:37,040 --> 00:02:39,840
以及它能够解决什么问题
did kubernetes even come around and what problems

67
00:02:39,840 --> 00:02:42,480
那么我们从定义开始
does it solve so let's jump in right

68
00:02:42,480 --> 00:02:43,599
学习kubernetes是什么
into the definition

69
00:02:43,599 --> 00:02:46,879
kubernetes是一个开源的
what is kubernetes so kubernetes is an open source

70
00:02:46,879 --> 00:02:49,920
容器编排框架
container orchestration framework which

71
00:02:49,920 --> 00:02:51,519
最初是由
was originally developed by

72
00:02:51,519 --> 00:02:54,400
谷歌开发
google so on the foundation it manages

73
00:02:54,400 --> 00:02:56,879
它基本功能是可以管理容器，可以是docker容器
containers be docker containers or from

74
00:02:56,879 --> 00:02:58,959
也可以是来自其它技术的容器
some other technology

75
00:02:58,959 --> 00:03:01,599
这基本上意味着kubernetes
which basically means that kubernetes

76
00:03:01,599 --> 00:03:02,840
可以帮助您管理
helps you manage

77
00:03:02,840 --> 00:03:06,480
由数百或者成千上万的容器
applications that are made up of hundreds or maybe

78
00:03:06,480 --> 00:03:09,760
组成的应用程序
thousands of containers

79
00:03:09,760 --> 00:03:13,920
它可以帮助你不同的环境管理它们
and it helps you manage them in different environments

80
00:03:13,920 --> 00:03:16,560
比如物理机环境，虚拟机环境
like physical machines virtual machines

81
00:03:16,560 --> 00:03:19,440
或者云环境，甚至混合环境
or cloud environments or even hybrid

82
00:03:19,440 --> 00:03:21,840
那么k8s解决了什么问题呢
deployment environments so what problems

83
00:03:21,840 --> 00:03:23,519
以及
does kubernetes solve and

84
00:03:23,519 --> 00:03:27,360
容器编制工具需要完成哪些任务呢
what are the tasks of a container orchestration tool

85
00:03:27,360 --> 00:03:29,599
解答之前先来
actually so to go through this

86
00:03:29,599 --> 00:03:31,200
按时间顺序梳理一下需求
chronologically

87
00:03:31,200 --> 00:03:33,519
微服务的兴起引起了
the rise of microservices caused

88
00:03:33,519 --> 00:03:36,319
容器技术使用量的大幅增加
increased usage of container technologies

89
00:03:36,319 --> 00:03:37,920
因为容器可以为一些
because the containers actually offer

90
00:03:37,920 --> 00:03:39,440
小型的独立应用程序
the perfect host

91
00:03:39,440 --> 00:03:43,319
提供完美的主机
for small independent applications like

92
00:03:43,319 --> 00:03:45,120
比如微服务
microservices

93
00:03:45,120 --> 00:03:48,720
同时容器和微服务技术的兴起
and the rise of containers and the micro service technology

94
00:03:48,720 --> 00:03:51,440
导致了一些应用
actually resulted in applications that

95
00:03:51,440 --> 00:03:54,480
现在已经由数百个或者有时甚至
they're now comprised of hundreds or sometimes maybe

96
00:03:54,480 --> 00:03:56,799
数千个容器组成
even thousands of containers now

97
00:03:56,799 --> 00:03:58,959
使用脚本和自制的工具
managing those loads of containers

98
00:03:58,959 --> 00:04:02,080
跨多个环境
across multiple environments using

99
00:04:02,080 --> 00:04:06,159
管理这些容器是非常复杂的
scripts and self-made tools can be really complex

100
00:04:06,159 --> 00:04:08,640
有时对于某些场景
and sometimes even impossible so that

101
00:04:08,640 --> 00:04:11,200
甚至是不可能的
specific scenario actually caused

102
00:04:11,200 --> 00:04:14,640
这带来了对容器编排技术的需求
the need for having container orchestration

103
00:04:14,640 --> 00:04:17,759
所以像k8s这样的编排工具
technologies so what those orchestration

104
00:04:17,759 --> 00:04:19,280
做的工作
tools like kubernetes do

105
00:04:19,280 --> 00:04:22,800
实际上是保证以下特性
is actually guarantee following features

106
00:04:22,800 --> 00:04:26,639
一个是高可用性
one is high availability in simple words

107
00:04:26,639 --> 00:04:29,040
高可用性意味着
high availability means that the

108
00:04:29,040 --> 00:04:32,000
应用程序没有停机时间，所以总是用户可访问的
application has no downtime so it's always

109
00:04:32,000 --> 00:04:35,520
第二个是可伸缩性
accessible by the users a second one is

110
00:04:35,520 --> 00:04:37,919
可伸缩性意味着应用程序
scalability which means that application

111
00:04:37,919 --> 00:04:40,400
具有较高的性能
has high performance

112
00:04:40,400 --> 00:04:44,080
它的加载速度很快，用户从应用程序
it loads fast and the users have a very

113
00:04:44,080 --> 00:04:46,479
可以获得一个非常高的响应率
high response rates from the application

114
00:04:46,479 --> 00:04:47,440
第三个是灾难恢复
and the third one

115
00:04:47,440 --> 00:04:49,759
灾难恢复意味着
is disaster recovery which basically

116
00:04:49,759 --> 00:04:52,240
如果一个设备出现了某些问题
means that if an infrastructure has some problems

117
00:04:52,240 --> 00:04:55,280
比如数据丢失或者服务器爆炸
like data is lost or the servers explode

118
00:04:55,280 --> 00:04:58,160
或者服务器中心出了问题
or something bad happens with the server center

119
00:04:58,160 --> 00:05:00,000
设备必须有某种
the infrastructure has to have some kind

120
00:05:00,000 --> 00:05:02,000
备份数据的机制
of mechanism to back up the data

121
00:05:02,000 --> 00:05:04,400
并将其恢复到最新状态
and to restore it to the latest state so

122
00:05:04,400 --> 00:05:07,280
这样应用程序不会丢失任何数据
that application doesn't actually lose any data

123
00:05:07,280 --> 00:05:10,479
而容器化的应用程序可以在恢复之后
and the containerized application can run from the

124
00:05:10,479 --> 00:05:13,440
回到最新状态
latest state after the recovery and all

125
00:05:13,440 --> 00:05:15,600
所有这些功能
of these are functionalities that

126
00:05:15,600 --> 00:05:23,680
都由像k8s这样的容器编排技术所提供
container orchestration technologies like kubernetes offer

127
00:05:23,680 --> 00:05:25,440
在这个视频中，我想给你们一个
so in this video i want to give you an

128
00:05:25,440 --> 00:05:26,880
关于大部分k8s
overview of the most

129
00:05:26,880 --> 00:05:28,560
基本组件的概览
basic fundamental components of

130
00:05:28,560 --> 00:05:30,639
这些
kubernetes uh but just

131
00:05:30,639 --> 00:05:34,800
足够让你开始在生产中使用kubernetes
enough to actually get you started using kubernetes

132
00:05:34,800 --> 00:05:39,280
作为devops工程师或者一个软件开发人员
in practice either as a devops engineer or a software developer

133
00:05:39,280 --> 00:05:42,320
kubernetes有很多组件
now kubernetes has tons of components but

134
00:05:42,320 --> 00:05:43,759
但大多数时候你都是
most of the time you're going to be

135
00:05:43,759 --> 00:05:47,280
只用其中的一小部分
working with just a handful of them

136
00:05:47,280 --> 00:05:49,680
所以我要建立一个简单的例子
so i'm going to build a case of a simple

137
00:05:49,680 --> 00:05:51,120
使用javascript应用程序
javascript application

138
00:05:51,120 --> 00:05:53,360
搭配一个简单的数据库，我将要
with a simple database and i'm going to

139
00:05:53,360 --> 00:05:55,120
一步一步来揭示
show you step by step

140
00:05:55,120 --> 00:05:57,360
kubernetes的每个组件是如何
how each component of kubernetes

141
00:05:57,360 --> 00:05:59,280
在实际中帮助你部署
actually helps you to deploy

142
00:05:59,280 --> 00:06:03,039
您的应用程序的，以及每个组件
your application and what is the role of

143
00:06:03,039 --> 00:06:07,039
在扮演什么样的角色
each of those components

144
00:06:07,039 --> 00:06:10,800
我们从一个worker节点的基本构造开始
so let's start with the basic setup of a worker node

145
00:06:10,800 --> 00:06:13,840
或者用kubernetes的术语来说，一个节点
or in kubernetes terms a node

146
00:06:13,840 --> 00:06:17,600
节点可以是一个简单的物理的服务器，也可以是一个虚拟机
which is a simple server a physical or virtual machine

147
00:06:17,600 --> 00:06:20,720
k8s中最基本的，或者说最小的单元
and the basic component or the smallest unit

148
00:06:20,720 --> 00:06:24,639
被称为pod
of kubernetes is a pod so what pot is

149
00:06:24,639 --> 00:06:27,840
pod基本上是一个容器的抽象
is basically an abstraction over a container

150
00:06:27,840 --> 00:06:29,440
所以如果你熟悉docker容器
so if you're familiar with docker

151
00:06:29,440 --> 00:06:32,240
或容器镜像
containers or container images

152
00:06:32,240 --> 00:06:34,800
pod所做的就是创造
so basically what pod does is it creates

153
00:06:34,800 --> 00:06:36,880
这样的运行环境
this running environment

154
00:06:36,880 --> 00:06:39,919
或者在容器的顶部加一层
or a layer on top of the container and

155
00:06:39,919 --> 00:06:42,240
这么做的原因是kubernetes想要
the reason is because kubernetes wants to

156
00:06:42,240 --> 00:06:45,120
将容器运行时
abstract away the container runtime or

157
00:06:45,120 --> 00:06:47,039
或容器技术 抽象出来
container technologies

158
00:06:47,039 --> 00:06:50,160
这样你可以在想更换的时候随时更换
so that you can replace them if you want to

159
00:06:50,160 --> 00:06:53,440
同时还有一部分原因是你也许不想直接在k8s中
and also because you don't have to directly uh work

160
00:06:53,440 --> 00:06:57,280
使用docker或其他容器技术
with docker or whatever container technology

161
00:06:57,280 --> 00:06:59,120
所以你可能只想
you use in a kubernetes so you only

162
00:06:59,120 --> 00:07:00,639
与kubernetes层交互
interact with the kubernetes layer

163
00:07:00,639 --> 00:07:04,880
所以我们用pod作为我们自己的应用程序
so we have an application pod which is our own application

164
00:07:04,880 --> 00:07:07,840
它可能会使用数据库
and that will maybe use a database pod

165
00:07:07,840 --> 00:07:10,800
pod有自己的容器，这也是一个重要的知识点
with its own container and this is also an important

166
00:07:10,800 --> 00:07:14,319
pod通常只运行
concept here pod is usually meant to run

167
00:07:14,319 --> 00:07:17,440
一个应用程序容器
one application container inside of it

168
00:07:17,440 --> 00:07:20,560
然而您可以在一个pod里面运行多个容器
you can run multiple containers inside one pod

169
00:07:20,560 --> 00:07:22,400
但通常只有一种情况，即
but usually it's only the case if you

170
00:07:22,400 --> 00:07:24,479
pod中有一个主应用程序容器
have one main application container

171
00:07:24,479 --> 00:07:27,759
和一个辅助容器或一些
and a helper container or some side

172
00:07:27,759 --> 00:07:30,800
必须在pod里面运行的边缘服务
service that has to run inside of that

173
00:07:30,800 --> 00:07:33,440
你看，这没什么特别的
pod and you see this is nothing special

174
00:07:33,440 --> 00:07:34,639
你只是有一个服务器
you just have one server

175
00:07:34,639 --> 00:07:37,120
里面还有两个容器
and two containers running on it with a

176
00:07:37,120 --> 00:07:38,880
在其上有一个抽象层
abstraction layer on top of it

177
00:07:38,880 --> 00:07:40,720
现在我们来看看在k8s的世界里
so now let's see how they communicate

178
00:07:40,720 --> 00:07:42,720
它们是如何通信的
with each other in kubernetes world

179
00:07:42,720 --> 00:07:44,720
kubernetes给出了开箱即用的
so kubernetes offers out of the box a

180
00:07:44,720 --> 00:07:47,360
虚拟网络，即每个pod
virtual network which means that each

181
00:07:47,360 --> 00:07:50,400
有自己的ip地址
pod gets its own ip address

182
00:07:50,400 --> 00:07:52,479
pod获取ip，而不是容器
not the container the pod gets the ip

183
00:07:52,479 --> 00:07:54,879
每个pod之间
address and each pod

184
00:07:54,879 --> 00:07:56,879
可以使用该ip地址互相交流
can communicate with each other using

185
00:07:56,879 --> 00:07:59,120
该ip地址是一个内部ip
that ip address which is an internal ip

186
00:07:59,120 --> 00:08:01,360
显然不是外部可访问的
address obviously it's not the

187
00:08:01,360 --> 00:08:04,560
所以我的应用程序容器
public one so my application container

188
00:08:04,560 --> 00:08:07,840
可以通过ip地址与数据库通信
can communicate with database using the ip address

189
00:08:07,840 --> 00:08:11,039
然而，在k8s中的pod组件
however pod components in kubernetes

190
00:08:11,039 --> 00:08:13,840
还有一个重要的概念是 临时性
also an important concept are ephemeral

191
00:08:13,840 --> 00:08:16,080
也就是说
which means that they can die

192
00:08:16,080 --> 00:08:19,039
这些pod会非常容易“死”
very easily and when that happens for

193
00:08:19,039 --> 00:08:21,520
比如我可能会因为容器崩溃
example if i lose a database container

194
00:08:21,520 --> 00:08:24,240
或者应用程序内部崩溃
because the container crashed because

195
00:08:24,240 --> 00:08:26,400
或者因为我所在的服务器节点资源耗尽
the application crashed inside

196
00:08:26,400 --> 00:08:30,240
那么pod会“死”
or because the nodes the server that i'm running them

197
00:08:30,240 --> 00:08:34,640
此时我们丢失了一个数据库容器
on ran out resources the pod will die

198
00:08:34,640 --> 00:08:36,800
而一个新的pod会被重新创建
and a new one will get created in its

199
00:08:36,800 --> 00:08:38,800
如果这发生了
place and when that happens

200
00:08:38,800 --> 00:08:41,599
它将被分配一个新的ip地址
it will get assigned a new ip address

201
00:08:41,599 --> 00:08:44,080
这显然很不方便，如果你在用ip地址
which obviously is inconvenient if you are

202
00:08:44,080 --> 00:08:45,839
与数据库通信
communicating with the database using

203
00:08:45,839 --> 00:08:47,519
因为现在你必须
the ip address because now you have to

204
00:08:47,519 --> 00:08:49,279
在pod重启时再做调整
adjust it every time

205
00:08:49,279 --> 00:08:52,080
由于这个原因，另一个重要的
pod restarts and because of that another

206
00:08:52,080 --> 00:08:57,600
kubernetes的组件--“Service”派上了用场
component of kubernetes called service is used

207
00:08:57,600 --> 00:09:00,560
service基本上是一个静态ip地址
so service is basically a static ip

208
00:09:00,560 --> 00:09:02,480
或永久ip地址
address or permanent ip address

209
00:09:02,480 --> 00:09:06,399
它可以被赋给每一个pod
that can be attached so to say to each pod

210
00:09:06,399 --> 00:09:08,720
所以我的应用会有自己的service
so my app will have its own service and

211
00:09:08,720 --> 00:09:11,600
数据库pod也将拥有自己的service
database pod will have its own service

212
00:09:11,600 --> 00:09:14,880
好在service的生命周期
and the good thing here is that the life cycles

213
00:09:14,880 --> 00:09:17,920
并不与pod相关联
of service and the pod are not connected

214
00:09:17,920 --> 00:09:19,040
所以即使
so even if the

215
00:09:19,040 --> 00:09:22,880
pod终止服务，service及其ip地址
pod dies the service and its ip address

216
00:09:22,880 --> 00:09:26,959
将会被保留，这样你就不用做调整了
will stay so you don't have to change that

217
00:09:26,959 --> 00:09:30,080
很明显现在
endpoint anymore so now obviously you

218
00:09:30,080 --> 00:09:31,920
你想要你的应用程序
would want your application

219
00:09:31,920 --> 00:09:34,240
可以通过浏览器访问
to be accessible through a browser right

220
00:09:34,240 --> 00:09:36,000
为此你必须创造一个
and for this you would have to create

221
00:09:36,000 --> 00:09:38,640
外部service
an external service so external service

222
00:09:38,640 --> 00:09:39,920
这是一种可以
is a service that

223
00:09:39,920 --> 00:09:43,760
与外部源通信的service
opens the communication from external sources

224
00:09:43,760 --> 00:09:45,519
但显然你不会想让你的
but obviously you wouldn't want your

225
00:09:45,519 --> 00:09:47,519
数据库也对外开放
database to be open to the

226
00:09:47,519 --> 00:09:50,320
因此你将
public requests and for that you would

227
00:09:50,320 --> 00:09:51,680
创建一个所谓的
create something called an

228
00:09:51,680 --> 00:09:54,720
内部service，这也是service的一种类型
internal service so this is a type of a

229
00:09:54,720 --> 00:09:55,920
你可以在创建service时
service that you

230
00:09:55,920 --> 00:09:59,920
指定其类型，但是请注意
specify when creating one however if you notice

231
00:09:59,920 --> 00:10:04,079
外部service的url
the url of the external service is

232
00:10:04,079 --> 00:10:07,279
并不是很实用，基本上就是
not very practical so basically what you have

233
00:10:07,279 --> 00:10:10,560
一个http协议
is uh an http protocol with

234
00:10:10,560 --> 00:10:13,680
节点的ip地址（注意是节点而不是服务）
a node ip address so of the node

235
00:10:13,680 --> 00:10:16,320
和这个service的端口号
not the service and the port number of

236
00:10:16,320 --> 00:10:18,160
这很适合
the service which is

237
00:10:18,160 --> 00:10:20,160
测试目的
good for test purposes if you want to

238
00:10:20,160 --> 00:10:21,760
如果快速测试一些东西的话
test something very fast

239
00:10:21,760 --> 00:10:24,160
但通常对最终产品来说并不好
but not for the end product so usually

240
00:10:24,160 --> 00:10:25,920
您可能希望您的url看起来像这样
you would want your url to look like

241
00:10:25,920 --> 00:10:26,959
你可能想通过
this if you want to

242
00:10:26,959 --> 00:10:30,959
安全的https协议以及一个域名
talk to your application with a secure protocol

243
00:10:30,959 --> 00:10:34,240
与应用程序通信
and a domain name and for that there is

244
00:10:34,240 --> 00:10:36,720
为此，你需要kubernetes的另一个重要组件
another component of kubernetes called

245
00:10:36,720 --> 00:10:37,600
Ingress

246
00:10:37,600 --> 00:10:39,920
而不是service
so instead of service the request goes

247
00:10:39,920 --> 00:10:42,480
请求首先进入Ingress，然后转发到Service
first to ingress and it does the forwarding then

248
00:10:42,480 --> 00:10:45,279
现在我们看到了一些
to the service so now we saw some of the

249
00:10:45,279 --> 00:10:47,839
kubernetes的基本组件
very basic components of kubernetes

250
00:10:47,839 --> 00:10:50,480
正如你看到的，这是一个非常简单的配置
um and as you see this is a very simple

251
00:10:50,480 --> 00:10:52,640
只有一个服务器
setup we just have a one server

252
00:10:52,640 --> 00:10:56,079
还有几个运行的容器
um and a couple of containers running

253
00:10:56,079 --> 00:10:59,600
以及一些服务，这些看起来没什么特别的
and some services nothing really special

254
00:10:59,600 --> 00:11:02,160
看不出kubernetes的优势在哪里
where kubernetes advantages or the

255
00:11:02,160 --> 00:11:03,519
也看不出k8s真正酷的特性
actual cool features

256
00:11:03,519 --> 00:11:06,240
但我们要
really uh come forward but we're gonna

257
00:11:06,240 --> 00:11:07,760
一步一步来
get there step by step

258
00:11:07,760 --> 00:11:10,959
所以我们继续
so let's continue

259
00:11:10,959 --> 00:11:14,000
就像我们说的，pod可以通过使用service
so as we said pods communicate with each other

260
00:11:14,000 --> 00:11:16,240
实现相互通信，我的应用程序将
using a service so my application will

261
00:11:16,240 --> 00:11:18,160
有一个数据库端endpoint
have a database

262
00:11:18,160 --> 00:11:21,519
我们命名其为mongo-db-service
endpoint let's say called mongodb service

263
00:11:21,519 --> 00:11:23,440
它用来和数据库通信
that it uses to communicate with the

264
00:11:23,440 --> 00:11:24,959
然而
database but

265
00:11:24,959 --> 00:11:27,200
您也许可以配置修改
whether you configure usually this

266
00:11:27,200 --> 00:11:28,560
数据库url或
database url or

267
00:11:28,560 --> 00:11:31,920
数据库的端点，通过修改
endpoint usually you would do it in application

268
00:11:31,920 --> 00:11:35,040
程序的属性文件或某种类型的
properties file or as some kind of

269
00:11:35,040 --> 00:11:37,360
外部环境变量
external environmental variable but

270
00:11:37,360 --> 00:11:39,920
然而这些通常需要在已构建的应用程序镜像的内部来实现
usually it's inside of the built

271
00:11:39,920 --> 00:11:42,800
举例来说
image of the application so for example

272
00:11:42,800 --> 00:11:45,920
如果service的端点或service名称
if the endpoint of the service or service name

273
00:11:45,920 --> 00:11:48,720
在本例中被更改为mongo-db
in this case changed to mongodb you

274
00:11:48,720 --> 00:11:50,560
你还需要调整应用程序中的url
would have to adjust that url

275
00:11:50,560 --> 00:11:53,600
所以你通常不得不
in the application so usually you'd have to

276
00:11:53,600 --> 00:11:55,519
重新构建新版本的应用程序
rebuild the application with a new

277
00:11:55,519 --> 00:11:58,639
并更新到仓库中去
version and you have to push it to the repository

278
00:11:58,639 --> 00:12:02,160
之后你要在pod中拉取构建后的新镜像
and now you'll have to pull that new image

279
00:12:02,160 --> 00:12:04,880
并全部重启
in your pod and restart the whole thing

280
00:12:04,880 --> 00:12:05,279
所以
so

281
00:12:05,279 --> 00:12:08,639
因为一点小改动，比如数据库url更改
a little bit tedious for a small change like

282
00:12:08,639 --> 00:12:11,440
而要做这么多工作，着实有点繁琐
database url so for that purpose

283
00:12:11,440 --> 00:12:12,639
为此，kubernetes提供一种
kubernetes has

284
00:12:12,639 --> 00:12:15,680
叫做ConfigMap的组件
a component called config map so what it

285
00:12:15,680 --> 00:12:17,760
它可以从外部来
does is it's basically your external

286
00:12:17,760 --> 00:12:20,000
对应用程序进行配置
configuration to your application

287
00:12:20,000 --> 00:12:24,079
所以ConfigMap通常包含配置数据
so config map would usually contain configuration data

288
00:12:24,079 --> 00:12:26,800
比如您常用的数据库
like urls of a database or some other

289
00:12:26,800 --> 00:12:28,320
或其他service的url
services that you use

290
00:12:28,320 --> 00:12:32,079
在kubernetes中，你只需要把它连接到pod
and in kubernetes you just connect it to the pod

291
00:12:32,079 --> 00:12:35,519
这个pod就可以获得ConfigMap包含的数据
so that pod actually gets the data that config map

292
00:12:35,519 --> 00:12:39,200
现在如果您更改service的名称
contains and now if you change the name of the service

293
00:12:39,200 --> 00:12:41,279
或者service的端点
the endpoint of the service you just

294
00:12:41,279 --> 00:12:42,880
只需要调整ConfigMap
adjust the config map

295
00:12:42,880 --> 00:12:44,399
就这样，你不需要构建一个
and that's it you don't have to build a

296
00:12:44,399 --> 00:12:45,920
新的镜像，不必
new image and have to

297
00:12:45,920 --> 00:12:49,519
经历这整个循环
go through this whole cycle now part of the

298
00:12:49,519 --> 00:12:51,839
外部配置也可以是
external configuration can also be

299
00:12:51,839 --> 00:12:54,240
数据库用户名和密码
database username and password

300
00:12:54,240 --> 00:12:57,120
这些在应用程序部署过程中
right which may also change in the

301
00:12:57,120 --> 00:12:58,880
也可能会发生变化
application deployment process

302
00:12:58,880 --> 00:13:00,880
但是密码之类的
but putting a password or other

303
00:13:00,880 --> 00:13:02,720
凭证信息放在ConfigMap这种
credentials in a config map

304
00:13:02,720 --> 00:13:06,000
纯文本的格式中是不安全的
in a plain text format would be insecure

305
00:13:06,000 --> 00:13:07,200
即使它是外部配置
even though it's an external

306
00:13:07,200 --> 00:13:09,920
为此
configuration so for this purpose

307
00:13:09,920 --> 00:13:12,639
kubernetes有另一个组件叫做
kubernetes has another component called

308
00:13:12,639 --> 00:13:13,760
Secret

309
00:13:13,760 --> 00:13:16,399
Secret就像ConfigMap
so secret is just like config map but

310
00:13:16,399 --> 00:13:17,200
二者区别在于
the difference

311
00:13:17,200 --> 00:13:20,399
Secret是用来存储秘密数据的
is that it's used to store secret data

312
00:13:20,399 --> 00:13:23,279
例如凭证，它被存储起来
credentials for example and it's stored

313
00:13:23,279 --> 00:13:26,160
不是以纯文本格式，而是
not in a plain text format of course but in

314
00:13:26,160 --> 00:13:29,200
64进制编码格式
base 64 encoded format so

315
00:13:29,200 --> 00:13:32,240
所以Secret可以包含凭证之类的数据
secret would contain things like credentials

316
00:13:32,240 --> 00:13:34,240
当然，数据库用户名
and of course i mean database user you

317
00:13:34,240 --> 00:13:36,000
也可以放入ConfigMap中
could also put in config map

318
00:13:36,000 --> 00:13:39,680
但重要的密码凭证
but what's important is the passwords certificates

319
00:13:39,680 --> 00:13:43,120
那些你不想让别人能接触到的东西
things that you don't want other people to have access to

320
00:13:43,120 --> 00:13:46,240
可以放入Secret中，就像ConfigMap
would go in the secret and just like ConfigMap

321
00:13:46,240 --> 00:13:48,720
你只要把它连到你的pod里
you just connect it to your pod so that

322
00:13:48,720 --> 00:13:50,880
pod可以看到这些数据
pod can actually see those data

323
00:13:50,880 --> 00:13:52,720
并从Secret中读取
and read from the secret you can

324
00:13:52,720 --> 00:13:53,920
你可以将
actually use the

325
00:13:53,920 --> 00:13:56,639
pod里的ConfigMap或Secret
data from configmap or secret inside of

326
00:13:56,639 --> 00:13:58,240
用于
your application pod

327
00:13:58,240 --> 00:14:00,240
存储如环境变量
using for example environmental

328
00:14:00,240 --> 00:14:02,000
甚至
variables or even as

329
00:14:02,000 --> 00:14:04,959
作为一个属性文件，现在回顾一下
a properties file so now to review we've

330
00:14:04,959 --> 00:14:06,320
我们已经学习了
actually looked at

331
00:14:06,320 --> 00:14:10,560
几乎所有最常用的kubernetes基本组件
almost all mostly used kubernetes basic components

332
00:14:10,560 --> 00:14:14,000
我们已经学习了
we've looked at the pod we've seen

333
00:14:14,000 --> 00:14:17,760
怎么用Service，什么是Ingress
how services are used what is ingress component

334
00:14:17,760 --> 00:14:21,680
我们也学习了如何从外部进行配置
useful for and we've also seen external configuration

335
00:14:21,680 --> 00:14:27,680
通过使用ConfigMap和Secret
using config map and secrets

336
00:14:27,680 --> 00:14:31,120
现在我们来看另一个非常重要的概念
so now let's see another very important concept

337
00:14:31,120 --> 00:14:33,920
一般来说，就是数据存储
generally which is data storage and how

338
00:14:33,920 --> 00:14:35,519
它在kubernetes中如何工作
it works in kubernetes

339
00:14:35,519 --> 00:14:37,600
我们的应用程序有数据库部分
so we have this database part that our

340
00:14:37,600 --> 00:14:40,000
它有一些数据或者
application uses and it has some data or

341
00:14:40,000 --> 00:14:43,199
它生成一些数据，通过这种设置
it generates some data with this setup that you see now

342
00:14:43,199 --> 00:14:48,000
如果数据库容器或pod被重新启动
if the database container or the pod gets restarted

343
00:14:48,000 --> 00:14:50,880
数据就会消失
the data would be gone and that's

344
00:14:50,880 --> 00:14:52,079
这样有问题
problematic and

345
00:14:52,079 --> 00:14:54,560
而且很不方便，如果你想要
inconvenient obviously because you want

346
00:14:54,560 --> 00:14:57,040
您的数据库数据或日志数据
your database data or log data

347
00:14:57,040 --> 00:15:00,639
可长期可靠地持续使用的话
to be persisted reliably long term

348
00:15:00,639 --> 00:15:03,760
你可以在kubernetes中这样做,通过使用
and the way you can do it in kubernetes is using

349
00:15:03,760 --> 00:15:06,079
kubernetes的另一个组件
another component of kubernetes called

350
00:15:06,079 --> 00:15:07,600
Volumes

351
00:15:07,600 --> 00:15:11,040
它的工作原理是连接
and how it works is that it basically attaches

352
00:15:11,040 --> 00:15:14,560
硬盘上的物理存储器到你的pod上
a physical storage on a hard drive to your pod

353
00:15:14,560 --> 00:15:16,560
存储空间可以在
and that storage could be either on a

354
00:15:16,560 --> 00:15:18,800
本地机器，即pod运行时所处的相同
local machine meaning on the same

355
00:15:18,800 --> 00:15:21,519
服务器节点
server node where the pod is running or

356
00:15:21,519 --> 00:15:23,519
也可能在远程存储器上
it could be on a remote storage

357
00:15:23,519 --> 00:15:25,120
意思是kubernetes集群之外的机器
meaning outside of the kubernetes

358
00:15:25,120 --> 00:15:26,639
它可以是
cluster it could be

359
00:15:26,639 --> 00:15:29,199
云存储或者你自己的
a cloud storage or it could be your own

360
00:15:29,199 --> 00:15:30,560
第三方存储
premise storage

361
00:15:30,560 --> 00:15:32,639
注意，存储并不是kubernetes集群的一部分
which is not part of the kubernetes

362
00:15:32,639 --> 00:15:34,959
所以你只是有一个外部的
cluster so you just have an external

363
00:15:34,959 --> 00:15:36,160
引用
reference on it

364
00:15:36,160 --> 00:15:38,000
现在当数据库pod或
so now when the database pod or

365
00:15:38,000 --> 00:15:40,000
容器被重新启动
container gets restarted

366
00:15:40,000 --> 00:15:42,639
所有的数据都将保存在那里
all the data will be there persisted

367
00:15:42,639 --> 00:15:43,920
重要的是要理解
it's important to understand the

368
00:15:43,920 --> 00:15:46,959
k8s集群与
distinction between the kubernetes cluster

369
00:15:46,959 --> 00:15:49,040
它的所有组件和
and all of its components and the

370
00:15:49,040 --> 00:15:50,079
存储之间的区别
storage

371
00:15:50,079 --> 00:15:52,320
不管它是本地的还是
regardless of whether it's a local or

372
00:15:52,320 --> 00:15:53,680
远程存储
remote storage

373
00:15:53,680 --> 00:15:56,720
可以把存储器看作是一个外部硬盘
think of a storage as an external hard drive

374
00:15:56,720 --> 00:15:59,759
插入到kubernetes集群中
plugged in into the kubernetes cluster

375
00:15:59,759 --> 00:16:02,480
因为kubernetes集群是
because the point is kubernetes cluster

376
00:16:02,480 --> 00:16:04,240
不负责
explicitly doesn't manage

377
00:16:04,240 --> 00:16:07,120
任何数据持久性的，这意味着
any data persistence which means that

378
00:16:07,120 --> 00:16:08,720
您是kubernetes的用户
you as a kubernetes user

379
00:16:08,720 --> 00:16:11,360
或管理员，那您就要负责
or an administrator are responsible for

380
00:16:11,360 --> 00:16:12,800
备份数据
backing up the data

381
00:16:12,800 --> 00:16:15,920
复制、管理并保证数据被
replicating and managing it and making sure that it's

382
00:16:15,920 --> 00:16:19,040
保存在适当的硬件等
kept on a proper hardware etc

383
00:16:19,040 --> 00:16:24,240
因为这不关k8s的事
because it's not taking care of kubernetes

384
00:16:24,240 --> 00:16:25,759
现在让我们看看所有东西都在运行
so now let's see everything is running

385
00:16:25,759 --> 00:16:28,880
运行完全正确，用户可以通过浏览器，在这样的设置下
perfectly and a user can access our application

386
00:16:28,880 --> 00:16:31,600
访问我们的应用程序
through a browser now with this setup

387
00:16:31,600 --> 00:16:36,000
但如果我的应用程序pod死了
what happens if my application pod dies

388
00:16:36,000 --> 00:16:39,440
崩溃了，或我必须重新启动pod时，会发生什么
right crashes or i have to restart the

389
00:16:39,440 --> 00:16:43,600
因为我建了一个新的容器镜像
pod because i built a new container image

390
00:16:43,600 --> 00:16:46,480
基本上我会有一段宕机时间
basically i would have a downtime where

391
00:16:46,480 --> 00:16:48,880
用户不可以访问我的应用程序
a user can reach my application

392
00:16:48,880 --> 00:16:52,079
如果它发生在生产过程中
which is obviously a very bad thing if

393
00:16:52,079 --> 00:16:53,600
这显然是一件非常糟糕的事情
it happens in production

394
00:16:53,600 --> 00:16:56,000
能够恰当处理这类情况正是
and this is exactly the advantage of

395
00:16:56,000 --> 00:16:58,639
分布式系统和容器技术的优势所在
distributed systems and containers

396
00:16:58,639 --> 00:17:02,480
不只依赖一个应用程序pod
so instead of relying on just one application part and

397
00:17:02,480 --> 00:17:06,640
和一个数据库pod等等
one database pod etc we are replicating

398
00:17:06,640 --> 00:17:10,160
我们复制所有东西在多个服务器上
everything on multiple servers

399
00:17:10,160 --> 00:17:12,640
所以我们有另一个节点
so we would have another node where a

400
00:17:12,640 --> 00:17:14,160
作为我们的应用程序的
replica or clone

401
00:17:14,160 --> 00:17:17,120
副本或克隆
of our application would run which will

402
00:17:17,120 --> 00:17:19,760
复制后的也要连接到service上
also be connected to the service

403
00:17:19,760 --> 00:17:21,439
记住之前我们说过
so remember previously we said the

404
00:17:21,439 --> 00:17:22,959
service就像一个
service is like an

405
00:17:22,959 --> 00:17:26,880
带dns的持久静态ip地址
persistent static ip address with a dns name

406
00:17:26,880 --> 00:17:30,000
这样你就不必不断地
so that you don't have to constantly adjust

407
00:17:30,000 --> 00:17:32,880
在pod死亡之后做调整，同时
the end point when a pod dies but

408
00:17:32,880 --> 00:17:35,200
service也是一个负载均衡器
service is also a load balancer

409
00:17:35,200 --> 00:17:36,640
也就是说service会
which means that the service will

410
00:17:36,640 --> 00:17:38,640
捕获请求并转发
actually catch the request and forward

411
00:17:38,640 --> 00:17:40,720
到最不忙碌的地方去
it to whichever part is least busy

412
00:17:40,720 --> 00:17:43,679
所以它有这两种功能
so it has both of these functionalities

413
00:17:43,679 --> 00:17:45,120
但是为了创造
but in order to create the

414
00:17:45,120 --> 00:17:48,240
应用程序所在pod的副本
the second replica of the my application pod

415
00:17:48,240 --> 00:17:50,880
你并不应该再创建一个一样的东西
you wouldn't create a second part but

416
00:17:50,880 --> 00:17:53,200
相反，你应该为应用程序pod
instead you would define a blueprint

417
00:17:53,200 --> 00:17:57,440
定义一个蓝图，指定要有多少份
for a my application pod and specify how many replicas

418
00:17:57,440 --> 00:17:59,919
你想用来执行的pod副本
of that pod you would like to run and

419
00:17:59,919 --> 00:18:02,160
那个组件或者蓝图
that component or that blueprint

420
00:18:02,160 --> 00:18:05,440
被称为Deployment，它是另一个k8s的组件
is called deployment which is another component of

421
00:18:05,440 --> 00:18:08,320
实际场景中你将不会
kubernetes and in practice you would not

422
00:18:08,320 --> 00:18:11,520
直接与多个pod协作，或者说你不会创建pod来做副本
be working with pods or you would not be creating pods

423
00:18:11,520 --> 00:18:13,600
您将创建Deployment
you would be creating deployments

424
00:18:13,600 --> 00:18:15,760
因为这样你可以指定
because there you can specify

425
00:18:15,760 --> 00:18:20,160
有多少个副本，同时你还可以增加或减少
how many replicas and you can also scale up or scale down

426
00:18:20,160 --> 00:18:22,640
你所需的pod副本的数量
the number of replicas of pods that you

427
00:18:22,640 --> 00:18:25,120
所以我们说pod是一个
need so with pod we said that pod is a

428
00:18:25,120 --> 00:18:26,720
在容器之上的层的抽象
layer of abstraction

429
00:18:26,720 --> 00:18:30,080
而Deployment是
on top of containers and deployment is

430
00:18:30,080 --> 00:18:32,720
另一个在pod之上的抽象
another abstraction on top of pots which

431
00:18:32,720 --> 00:18:35,600
使得与pod交互更加方便
makes it more convenient to interact with the pods

432
00:18:35,600 --> 00:18:39,440
用于复制pod，以及做其他的配置
replicate them and do some other configuration

433
00:18:39,440 --> 00:18:42,000
所以在实践中，你大部分时间都在
so in practice you would mostly work

434
00:18:42,000 --> 00:18:44,400
使用Deployment而不是pod
with deployments and not with pods

435
00:18:44,400 --> 00:18:46,799
所以现在如果应用程序pod的一个副本
so now if one of the replicas of your

436
00:18:46,799 --> 00:18:48,400
将要消亡
application pod would die

437
00:18:48,400 --> 00:18:51,600
Service将把请求转发给
the service will forward the requests to

438
00:18:51,600 --> 00:18:53,840
另一个副本，这样你的应用程序
another one so your application would

439
00:18:53,840 --> 00:18:55,679
用户仍然可以访问
still be accessible for the user

440
00:18:55,679 --> 00:18:57,200
现在你可能想知道
so now you're probably wondering what

441
00:18:57,200 --> 00:18:58,880
数据库pod怎么办
about the database pod

442
00:18:58,880 --> 00:19:01,360
因为如果数据库pod死了
because if the database pod died your

443
00:19:01,360 --> 00:19:03,039
应用程序也将不可访问
application also wouldn't be

444
00:19:03,039 --> 00:19:06,080
所以我们需要一个数据库副本
accessible so we need a database

445
00:19:06,080 --> 00:19:08,880
然而我们不能
replica as well however we can't

446
00:19:08,880 --> 00:19:11,520
使用Deployment复制数据库
replicate database using a deployment

447
00:19:11,520 --> 00:19:14,880
原因是
and the reason for that is because database

448
00:19:14,880 --> 00:19:19,520
数据库有状态信息，这意味着如果我们有
has a state which is its data meaning that if we have

449
00:19:19,520 --> 00:19:22,240
数据库的克隆或副本
clones or replicas of the database they

450
00:19:22,240 --> 00:19:23,679
都需要
would all need to

451
00:19:23,679 --> 00:19:27,360
访问相同的共享数据存储
access the same shared data storage

452
00:19:27,360 --> 00:19:31,520
在那里你需要某种机制来管理
and there you would need some kind of mechanism that manages

453
00:19:31,520 --> 00:19:34,960
哪些pod正在写内容到存储中
which pods are currently writing to that storage

454
00:19:34,960 --> 00:19:37,039
或者是哪个pod从
or which pods are reading from the

455
00:19:37,039 --> 00:19:38,480
存储中读取数据以便
storage in order to

456
00:19:38,480 --> 00:19:42,080
避免数据不一致
avoid data inconsistencies and

457
00:19:42,080 --> 00:19:46,000
而这样的补充拷贝的机制
that mechanism in addition to replicating

458
00:19:46,000 --> 00:19:49,760
该功能由另一个kubernetes组件提供
feature is offered by another kubernetes component

459
00:19:49,760 --> 00:19:52,799
这个组件叫StatefulSet
called stateful set so this component

460
00:19:52,799 --> 00:19:57,200
是专门为数据库这样的应用而设计的
is meant specifically for applications like databases

461
00:19:57,200 --> 00:20:01,360
所以mysql mongodb elasticsearch
so mysql mongodb elasticsearch

462
00:20:01,360 --> 00:20:04,000
或任何其他有状态的应用程序
or any other stateful applications or

463
00:20:04,000 --> 00:20:05,360
或数据库
databases

464
00:20:05,360 --> 00:20:07,919
都应该使用StatefulSet创建
should be created using stateful sets

465
00:20:07,919 --> 00:20:09,679
而不是Deployment
and not deployments

466
00:20:09,679 --> 00:20:12,240
这是一个非常重要的区别
it's a very important distinction and

467
00:20:12,240 --> 00:20:14,480
StatefulSet就像Deployment一样
stateful set just like deployment

468
00:20:14,480 --> 00:20:17,919
能帮我复制pod
would take care of replicating the pods

469
00:20:17,919 --> 00:20:20,880
并将副本的规模进行缩放
and scaling them up or scaling them down

470
00:20:20,880 --> 00:20:22,720
但要确保数据库
but making sure the database

471
00:20:22,720 --> 00:20:25,200
读取和写入是同步的
reads and writes are synchronized so

472
00:20:25,200 --> 00:20:27,679
即没有数据库不一致的情况
that no database inconsistencies

473
00:20:27,679 --> 00:20:31,200
但是我必须在这里提到的是
are offered however i must mention here that

474
00:20:31,200 --> 00:20:35,360
使用StatefulSet部署k8s集群中的数据库应用
deploying database applications using stateful sets

475
00:20:35,360 --> 00:20:39,200
是比较枯燥的
in kubernetes cluster can be somewhat tedious

476
00:20:39,200 --> 00:20:42,080
所以这绝对比
so it's definitely more difficult than

477
00:20:42,080 --> 00:20:44,640
使用Deployment更困难，因为后者没有那么多挑战
working with deployments where you don't have

478
00:20:44,640 --> 00:20:46,640
这就是为什么
all these challenges that's why it's

479
00:20:46,640 --> 00:20:48,400
一种常见的做法是
also a common practice

480
00:20:48,400 --> 00:20:51,840
在k8s集群外部托管
to host database applications outside of

481
00:20:51,840 --> 00:20:53,440
数据库应用程序
the kubernetes cluster

482
00:20:53,440 --> 00:20:57,600
k8s集群只部署无状态的应用程序
and just have the deployments or stateless applications

483
00:20:57,600 --> 00:21:00,240
这样在kubernetes集群内部做复制和扩展
that replicate and scale with no problem

484
00:21:00,240 --> 00:21:02,400
就都没有问题
inside of the kubernetes cluster

485
00:21:02,400 --> 00:21:03,840
并可以与外部数据库通信
and communicate with the external

486
00:21:03,840 --> 00:21:06,080
现在我们有两个
database so now that we have two

487
00:21:06,080 --> 00:21:08,159
应用程序pod的副本
replicas of my application pod

488
00:21:08,159 --> 00:21:10,240
和两个数据库的副本
and two replicas of the database and

489
00:21:10,240 --> 00:21:12,080
它们都是负载平衡的
they're both load balanced

490
00:21:12,080 --> 00:21:14,559
我们的配置更健壮，这意味着
our setup is more robust which means

491
00:21:14,559 --> 00:21:15,200
现在
that now

492
00:21:15,200 --> 00:21:18,240
即使节点1的整个节点服务器
even if node 1 the whole node server

493
00:21:18,240 --> 00:21:21,520
重启或崩溃了
was actually rebooted or crashed

494
00:21:21,520 --> 00:21:23,440
没有任何东西可以在上面运行，我们仍然
and nothing could run on it we would

495
00:21:23,440 --> 00:21:25,280
还有第二个节点
still have a second node

496
00:21:25,280 --> 00:21:28,799
可以运行应用程序和数据库pod
with application and database pods running on it

497
00:21:28,799 --> 00:21:30,559
应用程序仍然是
and the application would still be

498
00:21:30,559 --> 00:21:32,159
用户可访问的
accessible by the user

499
00:21:32,159 --> 00:21:35,600
直到这两个副本被重新创建
until these two replicas get recreated

500
00:21:35,600 --> 00:21:38,000
这样你就可以避免停机
so you can avoid downtime so to

501
00:21:38,000 --> 00:21:39,120
总结一下
summarize

502
00:21:39,120 --> 00:21:41,600
我们已经看了最常用的
we have looked at the most used

503
00:21:41,600 --> 00:21:43,039
kubernetes组件
kubernetes components

504
00:21:43,039 --> 00:21:45,200
我们从pod和Service入手
we start with the pods and the services

505
00:21:45,200 --> 00:21:47,679
Service是为了能够实现pod之间的通信
in order to communicate between the pods

506
00:21:47,679 --> 00:21:50,720
Ingress组件用来
and the ingress component which is used

507
00:21:50,720 --> 00:21:53,280
路由接入我们的集群
to route traffic into the cluster we've

508
00:21:53,280 --> 00:21:55,360
同时我们也研究了利用ConfigMap\Secret
also looked at external configuration

509
00:21:55,360 --> 00:21:59,039
进行外部配置
using config maps and secrets and data persistence

510
00:21:59,039 --> 00:22:03,039
以及用volume实现数据持久化，最后我们看了一下
using volumes and finally we've looked at

511
00:22:03,039 --> 00:22:06,559
利用如Deployment和StatefulSet实现的
pod blueprints with replicating mechanisms

512
00:22:06,559 --> 00:22:09,520
副本机制，即pod蓝图
like deployments and stateful sets where

513
00:22:09,520 --> 00:22:10,400
StatefulSet

514
00:22:10,400 --> 00:22:13,520
专门用于有状态应用程序(如数据库）
is used specifically for stateful applications like

515
00:22:13,520 --> 00:22:16,400
当然，还有很多
databases and yes there are a lot more

516
00:22:16,400 --> 00:22:17,919
kubernetes组件
components that kubernetes

517
00:22:17,919 --> 00:22:21,679
但是这些是真正的核心，是最基本的组件
offers but these are really the core the basic ones

518
00:22:21,679 --> 00:22:24,799
只需使用这些核心组件即可
just using these core components you can

519
00:22:24,799 --> 00:22:32,799
构建出非常强大的kubernetes集群
actually build pretty powerful kubernetes clusters

520
00:22:32,799 --> 00:22:35,919
在这段视频中，我们将讨论
in this video we're gonna talk about basic

521
00:22:35,919 --> 00:22:40,400
kubernetes的基本架构，所以我们要学习
architecture of kubernetes so we're gonna look at

522
00:22:40,400 --> 00:22:44,000
kubernetes操纵的两种类型的节点
two types of nodes that kubernetes operates on

523
00:22:44,000 --> 00:22:46,559
一个是master，另一个是slave
one is master and another one is slave

524
00:22:46,559 --> 00:22:47,760
我们来看看
and we're gonna see what is the

525
00:22:47,760 --> 00:22:49,520
它们的区别
difference between those and which

526
00:22:49,520 --> 00:22:53,520
它们各自在集群中扮演什么角色
role each one of them has inside of the cluster

527
00:22:53,520 --> 00:22:55,039
我们来看看最基本的一些概念
and we're going to go through the basic

528
00:22:55,039 --> 00:22:57,520
关于kubernetes做什么，怎么做
concepts of how kubernetes does

529
00:22:57,520 --> 00:23:00,159
集群是怎样进行
what it does and how the cluster is

530
00:23:00,159 --> 00:23:02,000
自我管理和自我修复
self-managed and self-healing

531
00:23:02,000 --> 00:23:05,520
以及自动化工作的，你作为一个
and automated and how you as a operator

532
00:23:05,520 --> 00:23:07,679
kubernetes集群的操作员
of the kubernetes cluster

533
00:23:07,679 --> 00:23:13,679
最后应该有更少的手动操作
should end up having much less manual effort

534
00:23:13,679 --> 00:23:15,840
我们从一个节点的基本设置开始
and we're going to start with this basic

535
00:23:15,840 --> 00:23:17,679
该节点
setup of one node

536
00:23:17,679 --> 00:23:20,559
有两个应用程序部分在上面运行
with two application parts running on it

537
00:23:20,559 --> 00:23:23,840
所以k8s架构一个主要的组成部分是
so one of the main components of kubernetes architecture

538
00:23:23,840 --> 00:23:27,360
它的worker服务器或者说worker节点
are its worker servers or nodes and each

539
00:23:27,360 --> 00:23:28,720
每个节点将有多个
node will have multiple

540
00:23:28,720 --> 00:23:33,039
在该节点运行容器的应用程序pod
application pods with containers running on that node

541
00:23:33,039 --> 00:23:37,039
kubernetes的方法是使用三个进程
and the way kubernetes does it is using three processes

542
00:23:37,039 --> 00:23:40,159
必须安装在每个节点上
that must be installed on every node

543
00:23:40,159 --> 00:23:43,360
用于计划和管理这些pod
that are used to schedule and manage those parts

544
00:23:43,360 --> 00:23:46,640
节点就是实际工作的集群服务器
so nodes are the cluster servers that actually do

545
00:23:46,640 --> 00:23:50,480
这就是为什么有时候管它们叫worker节点
the work that's why sometimes also called worker nodes

546
00:23:50,480 --> 00:23:53,600
所以第一个在每个节点上都需要运行的进程
so the first process that needs to run

547
00:23:53,600 --> 00:23:56,000
是容器运行时
on every node is the container runtime

548
00:23:56,000 --> 00:23:57,760
在我的例子中，是docker
in my example i have docker

549
00:23:57,760 --> 00:23:59,520
但也可能是其他的技术
but it could be some other technology as

550
00:23:59,520 --> 00:24:01,919
因为应用程序pods内有
well so because application pods have

551
00:24:01,919 --> 00:24:04,080
运行的容器
containers running inside a container

552
00:24:04,080 --> 00:24:07,440
运行时需要安装在每个节点
runtime needs to be installed on every node

553
00:24:07,440 --> 00:24:10,400
而实际上对这些pod和容器
but the process that actually schedules

554
00:24:11,120 --> 00:24:14,240
进行调度的进程
those pods and the containers then underneath

555
00:24:14,240 --> 00:24:17,679
则是kubelet，它是k8s的一个进程
is cubelet which is a process of kubernetes

556
00:24:17,679 --> 00:24:20,960
它本身不同于容器运行时
itself unlike container runtime that has

557
00:24:20,960 --> 00:24:24,559
它同时具备既可以与容器运行时
interface with both container runtime

558
00:24:24,559 --> 00:24:27,760
又可以与机器本身，即节点进行交互的接口，因为
and the machine the node itself because

559
00:24:27,760 --> 00:24:29,440
到头来是kubelet
at the end of the day cubelet is

560
00:24:29,440 --> 00:24:32,320
负责接受配置信息
responsible for taking that configuration

561
00:24:32,320 --> 00:24:35,360
并在实际场景中运行或者启动一个
and actually running a pod or starting a pod

562
00:24:35,360 --> 00:24:38,400
里面有容器的pod，然后
with a container inside and then assigning

563
00:24:38,400 --> 00:24:41,679
将该节点的资源分配给容器
resources from that node to the container

564
00:24:41,679 --> 00:24:44,799
比如cpu ram和存储资源
like cpu ram and storage resources so

565
00:24:44,799 --> 00:24:47,279
所以kubernetes集群通常是由
usually kubernetes cluster is made up

566
00:24:47,279 --> 00:24:50,559
也必须由多个节点组成
of multiple nodes which also must have

567
00:24:50,559 --> 00:24:52,799
同时也必须安装好容器运行时和kubelet服务
container runtime and kubelet services

568
00:24:52,799 --> 00:24:54,880
你可以有几百个worker节点
installed and you can have hundreds of

569
00:24:54,880 --> 00:24:56,720
来运行
those worker nodes which will run

570
00:24:56,720 --> 00:24:59,600
其他部分、容器
other parts and containers and replicas

571
00:24:59,600 --> 00:25:01,360
和现有部分的副本
of the existing parts

572
00:25:01,360 --> 00:25:04,559
就像我的应用程序和数据库部分在这个例子里
like my app and database parts in this example

573
00:25:04,559 --> 00:25:07,600
而它们之间交互的方式
and the way that communication between them works

574
00:25:07,600 --> 00:25:10,960
则是使用Service，是一种
is using services which is sort of

575
00:25:10,960 --> 00:25:13,600
基本的负载均衡器
a load balancer that basically catches

576
00:25:13,600 --> 00:25:14,559
能够捕获指向pod
the request

577
00:25:14,559 --> 00:25:17,200
或应用程序的请求
directed to the pod or the application

578
00:25:17,200 --> 00:25:18,799
比如数据库
like database for example

579
00:25:18,799 --> 00:25:21,600
然后把它转发给相应的pod
and then forwards it to the respective

580
00:25:21,600 --> 00:25:23,279
第三个进程
pod and the third process

581
00:25:23,279 --> 00:25:25,840
负责转发请求
that is responsible for forwarding

582
00:25:25,840 --> 00:25:28,000
从服务转发到pod
requests from services to pods

583
00:25:28,000 --> 00:25:32,080
该进程就是kube proxy，其也是必须安装在
is actually cube proxy that also must be installed

584
00:25:32,080 --> 00:25:35,440
在每个节点的，kube proxy事实上
on every node and q proxy has actually

585
00:25:35,440 --> 00:25:38,480
内部有智能转发逻辑
intelligent forwarding logic inside

586
00:25:38,480 --> 00:25:40,960
这确保了通信能够
that makes sure that the communication

587
00:25:40,960 --> 00:25:42,880
以高效、低额外开支的方式进行
also works in a performant

588
00:25:42,880 --> 00:25:46,960
例如如果一个应用程序
way with low overhead for example if an application

589
00:25:46,960 --> 00:25:50,559
my-app副本正在发出数据库请求
my app replica is making a requested database

590
00:25:50,559 --> 00:25:52,880
相比于Service随机
instead of service just randomly

591
00:25:52,880 --> 00:25:54,320
转发请求到
forwarding the request to

592
00:25:54,320 --> 00:25:57,200
任何可能的副本，智能转发机制会
any replica it will actually forward it

593
00:25:57,200 --> 00:26:00,080
将请求转发到运行在相同节点上的副本
to the replica that is running on the same node

594
00:26:00,080 --> 00:26:03,039
作为发起请求的pod
as the pod that initiated the request

595
00:26:03,039 --> 00:26:06,559
因此这样就避免了发送请求给另一台机器
thus this way avoiding the network overhead

596
00:26:06,559 --> 00:26:08,400
所带来的网络开销
of sending the request

597
00:26:08,400 --> 00:26:11,520
做个总结
to another machine so to summarize

598
00:26:11,520 --> 00:26:14,720
两个kubernetes进程，kubelet
two kubernetes processes cubelet

599
00:26:14,720 --> 00:26:17,919
和kubeproxy都必须安装在
and cubeproxy must be installed

600
00:26:17,919 --> 00:26:20,559
每个kubernetes的worker节点上
on every kubernetes worker node along

601
00:26:20,559 --> 00:26:23,039
同时还要有独立的容器运行时
with an independent container runtime

602
00:26:23,039 --> 00:26:26,400
从而使kubernetes集群正常工作
in order for kubernetes cluster to function properly

603
00:26:26,400 --> 00:26:28,400
但现在的问题是你将如何
but now the question is how do you

604
00:26:28,400 --> 00:26:30,159
与这个集群交互
interact with this cluster

605
00:26:30,159 --> 00:26:33,200
你该如何决定哪个节点的
how do you decide on which node a new

606
00:26:33,200 --> 00:26:37,200
应用程序pod或数据库pod应该被调用
application pod or database pod should be scheduled or

607
00:26:37,200 --> 00:26:40,480
或者如果一个pod死亡了，哪个进程可以
if a replica pod dies what process

608
00:26:40,480 --> 00:26:42,159
监控它，然后
actually monitors it and then

609
00:26:42,159 --> 00:26:44,640
重新安排或者重新启动
reschedules it or restarts it again or

610
00:26:44,640 --> 00:26:46,000
抑或添加另一个新的服务器
when we add another

611
00:26:46,000 --> 00:26:49,120
如何让他加入集群
server how does it join the cluster to become

612
00:26:49,120 --> 00:26:51,039
成为另一个节点，并获取
another node and get parts and other

613
00:26:51,039 --> 00:26:52,960
在上面创建的组件的信息
components created on it

614
00:26:52,960 --> 00:26:55,120
答案是所有这些管理工作
and the answer is all these managing

615
00:26:55,120 --> 00:27:00,000
都是由master节点完成的
processes are done by master nodes

616
00:27:00,000 --> 00:27:02,480
所以master服务器或者说master节点
so master servers or masternodes have

617
00:27:02,480 --> 00:27:03,679
在内部是有完全不同的
completely different

618
00:27:03,679 --> 00:27:06,640
运行的进程的
processes running inside and these are

619
00:27:06,640 --> 00:27:09,520
每个master节点有四个进程要运行
four processes that run on every masternode

620
00:27:09,520 --> 00:27:14,559
来控制集群状态和worker节点
that control the cluster state and the worker nodes as well

621
00:27:14,559 --> 00:27:17,760
第一个服务是api服务器
so the first service is api server

622
00:27:17,760 --> 00:27:21,919
所以当你作为一个用户想要部署一个新的应用程序
so when you as a user want to deploy a new application

623
00:27:21,919 --> 00:27:24,559
到kubernetes集群中，您可以通过一些客户端
in a kubernetes cluster you interact

624
00:27:24,559 --> 00:27:27,039
与api服务器进行交互
with the api server using some client it

625
00:27:27,039 --> 00:27:28,320
它可以是图形界面
could be a ui

626
00:27:28,320 --> 00:27:29,840
就像kubernetes dashboard一样
like kubernetes dashboard could be

627
00:27:29,840 --> 00:27:31,760
可以是命令行工具，如kubelet（这里口误，应是kubectl）
command line tool like cubelet

628
00:27:31,760 --> 00:27:34,960
或者kubernetes提供的代码api
or a kubernetes api so api server

629
00:27:34,960 --> 00:27:38,399
api服务器就像一个集群网关
is like a cluster gateway

630
00:27:38,399 --> 00:27:41,520
获取任何更新到集群的初始请求
which gets the initial request of any

631
00:27:41,520 --> 00:27:44,559
甚至集群的查询
updates into the cluster or even the queries

632
00:27:44,559 --> 00:27:48,559
它也作为一个看门人
from the cluster and it also acts as a gatekeeper

633
00:27:48,559 --> 00:27:51,200
进行身份验证以确保
for authentication to make sure that

634
00:27:51,200 --> 00:27:54,080
只有经过认证和授权的请求 requests
only authenticated and authorized

635
00:27:54,080 --> 00:27:56,799
能够进入集群，这意味着
get through to the cluster that means

636
00:27:56,799 --> 00:27:59,279
当你想调度新的pod
whenever you want to schedule new pods

637
00:27:59,279 --> 00:28:01,360
部署新的应用程序
deploy new applications create new

638
00:28:01,360 --> 00:28:03,360
创建新的服务或任何其他组件时
service or any other components

639
00:28:03,360 --> 00:28:07,360
您必须与master节点上的api服务器进行通信
you have to talk to the api server on the master node

640
00:28:07,360 --> 00:28:11,520
然后api服务器会验证你的请求
and the api server then validate your request

641
00:28:11,520 --> 00:28:13,919
如果一切都好，它就会
and if everything is fine then it will

642
00:28:13,919 --> 00:28:15,360
转发你的要求
forward your request

643
00:28:15,360 --> 00:28:19,039
到其它进程，从而
to other processes in order to

644
00:28:19,039 --> 00:28:20,880
调度pod或创建这个
schedule the pod or create this

645
00:28:20,880 --> 00:28:22,480
您要求的组件
component that you requested

646
00:28:22,480 --> 00:28:25,679
如果你想查询状态
and also if you want to query the status of your

647
00:28:25,679 --> 00:28:28,720
如部署或集群运行状况等
deployment or the cluster health etc you

648
00:28:28,720 --> 00:28:30,080
你可以向api服务器发出请求
make a request to the api

649
00:28:30,080 --> 00:28:32,640
它将向您响应
server and it gives you the response

650
00:28:32,640 --> 00:28:34,880
这对安全有好处，因为你只能通过
which is good for security because you just have

651
00:28:34,880 --> 00:28:37,360
一个进入集群的入口点查询
one entry point into the cluster another

652
00:28:37,360 --> 00:28:39,679
另一个重要进程是调度器
master process is a scheduler so as i

653
00:28:39,679 --> 00:28:41,520
就像我之前提到的
mentioned if you

654
00:28:41,520 --> 00:28:44,480
如果你向api服务器发送一个请求来调度
send an api server a request to schedule

655
00:28:44,480 --> 00:28:45,440
一个新的pod
a new pod

656
00:28:45,440 --> 00:28:49,200
api服务器验证了你的请求后
api server after it validates your request

657
00:28:49,200 --> 00:28:50,960
会将它移交给调度器
will actually hand it over to the

658
00:28:50,960 --> 00:28:53,120
接着
scheduler in order to

659
00:28:53,120 --> 00:28:55,440
启动众多worker节点中的
start that application pod on one of the

660
00:28:55,440 --> 00:28:56,720
一个应用程序pod
worker nodes

661
00:28:56,720 --> 00:28:58,640
当然，这不是随机的
and of course instead of just randomly

662
00:28:58,640 --> 00:29:00,480
不会随机分配给任何节点
assigning it to any node

663
00:29:00,480 --> 00:29:03,760
调度器有完善的智能的
schedule has this whole intelligent

664
00:29:03,760 --> 00:29:07,840
决定采用哪个worker的方法
way of deciding on which specific worker node

665
00:29:07,840 --> 00:29:11,279
来决定调度下一个pod
the next pod will be scheduled or next

666
00:29:11,279 --> 00:29:13,919
或下一个组件
component will be scheduled so first it

667
00:29:13,919 --> 00:29:15,600
首先它会看你的请求
will look at your request

668
00:29:15,600 --> 00:29:18,559
看看您想要调度的应用程序
and see how much resources the

669
00:29:18,559 --> 00:29:20,559
需要多少资源
application that you want to schedule

670
00:29:20,559 --> 00:29:23,120
需要多少cpu多少内存
will need how much cpu how much ram

671
00:29:23,120 --> 00:29:25,679
然后它会看
and then it it's going to look at and

672
00:29:25,679 --> 00:29:27,760
worker节点
it's going to go through the worker nodes

673
00:29:27,760 --> 00:29:30,480
并查看各自的可用资源
and see the available resources on each

674
00:29:30,480 --> 00:29:31,360
其中的一个
one of them

675
00:29:31,360 --> 00:29:34,799
如果这个节点
and if it says that one node

676
00:29:34,799 --> 00:29:38,159
最不忙或者
is the least busy or has the most

677
00:29:38,159 --> 00:29:39,600
可用资源最多
resources available

678
00:29:39,600 --> 00:29:42,799
新的部分就会安排在这个节点上
it will schedule the new part on that node

679
00:29:42,799 --> 00:29:44,480
这里重要的一点是
an important point here is that

680
00:29:44,480 --> 00:29:46,720
调度器只是决定
scheduler just decides

681
00:29:46,720 --> 00:29:49,360
新的pod将在哪个节点上被调度
on which node a new pod will be

682
00:29:49,360 --> 00:29:51,840
实际上执行调度操作
scheduled the process that actually

683
00:29:51,840 --> 00:29:54,159
和启动相应带容器的pod
does the scheduling that actually starts

684
00:29:54,159 --> 00:29:56,080
的进程
that pod with a container

685
00:29:56,080 --> 00:29:58,720
则是kubelet，它从调度器
is the cubelet so it gets the request

686
00:29:58,720 --> 00:29:59,919
获得请求
from the scheduler

687
00:29:59,919 --> 00:30:03,600
并在该节点上执行该请求
and executes that request on that node

688
00:30:03,600 --> 00:30:06,640
下一个组件是controller manager
the next component is controller manager

689
00:30:06,640 --> 00:30:09,440
它另一个关键的组件
which is another crucial component

690
00:30:09,440 --> 00:30:11,039
因为当
because what happens when

691
00:30:11,039 --> 00:30:15,120
某一个节点上的部分崩溃了，必须有一种方法能够
parts die on any node there must be a way to

692
00:30:15,120 --> 00:30:18,720
检测到节点死亡
detect that the nodes died and then reschedule

693
00:30:18,720 --> 00:30:21,279
然后尽快重新调度
those parts as soon as possible so what

694
00:30:21,279 --> 00:30:22,640
所以Controller manager的工作就是
controller manager does

695
00:30:22,640 --> 00:30:26,640
检测状态的变化
is detect state changes like

696
00:30:26,640 --> 00:30:29,520
比如pod的崩溃
crashing of pods for example so when

697
00:30:29,520 --> 00:30:30,640
所以当pod死了
pods die

698
00:30:30,640 --> 00:30:33,039
Controller manager检测并
controller manager detects that and

699
00:30:33,039 --> 00:30:35,200
试图尽快恢复
tries to recover

700
00:30:35,200 --> 00:30:37,919
集群状态
the cluster state as soon as possible

701
00:30:37,919 --> 00:30:38,799
因此
and for that

702
00:30:38,799 --> 00:30:40,799
它向调度程序发出请求
it makes a request for the scheduler to

703
00:30:40,799 --> 00:30:42,640
重新调度那些死去的部分
reschedule those dead parts

704
00:30:42,640 --> 00:30:44,480
刚刚提到的流程也会重新发生
and the same cycle happens here where

705
00:30:44,480 --> 00:30:48,960
调度器根据资源计算决定
the scheduler decides based on the resource calculation

706
00:30:48,960 --> 00:30:53,279
哪些工作节点应该重新启动
which worker nodes should restart those spots again

707
00:30:53,279 --> 00:30:56,240
并向相应的对象发出请求
and makes requests to the corresponding

708
00:30:56,240 --> 00:30:57,600
在那些worker节点的
cubelets on those

709
00:30:57,600 --> 00:31:00,640
kubelet实际重新启动pod
worker nodes to actually restart the pods

710
00:31:00,640 --> 00:31:04,080
最后一个主进程是etcd
and finally the last master process is

711
00:31:04,080 --> 00:31:08,480
etcd是一个集群状态的键值存储
etcd which is a key value store of a cluster state

712
00:31:08,480 --> 00:31:11,919
你可以把它想象成一个集群大脑
you can think of it as a cluster brain actually

713
00:31:11,919 --> 00:31:15,039
也就是说集群的每一次变化
which means that every change in the cluster

714
00:31:15,039 --> 00:31:17,039
例如，当一个新的pod被调度
for example when a new pod gets

715
00:31:17,039 --> 00:31:18,799
当一个pod死亡
scheduled when a pod dies

716
00:31:18,799 --> 00:31:21,440
所有这些更改都会被保存
all of these changes get saved or

717
00:31:21,440 --> 00:31:23,919
更新到这个etcd键值存储区
updated into this key value store

718
00:31:23,919 --> 00:31:26,640
为什么说etcd
of etcd and the reason why at cd store

719
00:31:26,640 --> 00:31:28,000
是一个集群大脑
is a cluster brain

720
00:31:28,000 --> 00:31:31,120
是因为所有的这些机制
is because all of this mechanism with

721
00:31:31,120 --> 00:31:34,559
调度器，Controller manager等等都需要数据
scheduler controller manager etc works because

722
00:31:34,559 --> 00:31:38,159
才能工作，比如说
of its data so for example

723
00:31:38,159 --> 00:31:41,120
调度器如何知道在每个工作节点上
how does scheduler know what resources

724
00:31:41,120 --> 00:31:44,559
哪些资源是可用的
are available on on each worker node or how does

725
00:31:44,559 --> 00:31:46,159
Controller manager如何知道
controller manager know that

726
00:31:46,159 --> 00:31:48,480
集群状态以某种方式发生了改变
a cluster state changed in some way for

727
00:31:48,480 --> 00:31:50,159
比如pod死亡
example pods died

728
00:31:50,159 --> 00:31:52,960
或者kubelet重启了新的pod
or that cubelet restarted new pods upon

729
00:31:52,960 --> 00:31:54,720
在响应了调度器的请求后
the request of a scheduler

730
00:31:54,720 --> 00:31:57,679
或者当你向api服务器发出查询请求时
or when you make a query request to api

731
00:31:57,679 --> 00:31:59,760
想要了解关于集群运行状况
server about the cluster health

732
00:31:59,760 --> 00:32:01,519
或者你的应用程序的
or for example your application

733
00:32:01,519 --> 00:32:02,880
部署状态时
deployment state

734
00:32:02,880 --> 00:32:07,120
api服务器从哪里获得所有这些状态
where does api server get all this state information from

735
00:32:07,120 --> 00:32:10,320
所有这些信息都存储在etcd
so all of this information is stored in etcd

736
00:32:10,320 --> 00:32:14,159
那些没有存储在etcd键值存储中的内容
cluster what is not stored in the etcd key value store

737
00:32:14,159 --> 00:32:17,039
就是实际的应用程序数据
is the actual application data for

738
00:32:17,039 --> 00:32:18,399
举个例子，如果你有
example if you have a

739
00:32:18,399 --> 00:32:21,919
数据库应用程序运行在一个集群上
database application running inside of a cluster

740
00:32:21,919 --> 00:32:25,039
数据将被存储在其他地方
the data will be stored somewhere else

741
00:32:25,039 --> 00:32:28,080
而不是在etcd，这里只有
not in the etcd this is just a cluster state

742
00:32:28,080 --> 00:32:31,039
给master进程的
information which is used for master

743
00:32:31,039 --> 00:32:33,120
用于和worker进程通信的
processes to communicate with them work

744
00:32:33,120 --> 00:32:36,640
集群状态信息，反之亦然
processes and vice versa so now you

745
00:32:36,640 --> 00:32:38,480
所以你已经知道master进程
probably already see that master

746
00:32:38,480 --> 00:32:40,799
对于集群操作
processes are absolutely crucial

747
00:32:40,799 --> 00:32:44,320
是至关重要的，特别是etcd存储
for the cluster operation especially the etcd

748
00:32:44,320 --> 00:32:48,000
其中包含一些必须被可靠存储或复制的数据
store which contains some data must be reliably stored

749
00:32:48,000 --> 00:32:51,600
所以在实践中kubernetes集群
or replicated so in practice kubernetes cluster

750
00:32:51,600 --> 00:32:54,480
通常是由多个master组成
is usually made up of multiple masters

751
00:32:54,480 --> 00:32:56,080
其中每个master节点
where each masternode

752
00:32:56,080 --> 00:32:58,960
运行它的主进程
runs its master processes where of

753
00:32:58,960 --> 00:33:00,880
当然，api服务器是负载均衡的
course the api server is

754
00:33:00,880 --> 00:33:03,679
而且etcd在所有master节点间
load balanced and the etcd store forms a

755
00:33:03,679 --> 00:33:09,360
构成分布式存储
distributed storage across all the master nodes

756
00:33:09,360 --> 00:33:12,720
现在我们学习了运行在master节点和worker节点上
so now that we saw what processes run

757
00:33:12,720 --> 00:33:15,440
的进程
on worker nodes and masternodes let's

758
00:33:15,440 --> 00:33:17,120
我们再来看一下
actually have a look at a

759
00:33:17,120 --> 00:33:19,840
一个真实的集群设置案例
realistic example of a cluster setup so

760
00:33:19,840 --> 00:33:21,039
在一个非常小的集群
in a very small

761
00:33:21,039 --> 00:33:24,080
你可能有两个master节点
cluster you would probably have two masternodes

762
00:33:24,080 --> 00:33:26,880
还有三个worker节点
and three worker nodes also to note here

763
00:33:26,880 --> 00:33:29,200
需要注意的是，master节点和worker节点的
the hardware resources of master

764
00:33:29,200 --> 00:33:31,679
主机硬件资源实际上是不同的
and node servers actually differ the

765
00:33:31,679 --> 00:33:34,000
master进程更重要，但是
master processes are more important but

766
00:33:34,000 --> 00:33:35,039
他们实际上有
they actually have

767
00:33:35,039 --> 00:33:37,919
更少的工作负荷，所以他们需要的资源也更少
less load of work so they need less

768
00:33:37,919 --> 00:33:40,480
如cpu ram和存储器
resources like cpu ram and storage

769
00:33:40,480 --> 00:33:42,720
而worker节点执行实际的任务
whereas the worker nodes do the actual

770
00:33:42,720 --> 00:33:44,240
运行包含有容器的pod
job of running those

771
00:33:44,240 --> 00:33:46,799
因此
pods with containers inside therefore

772
00:33:46,799 --> 00:33:48,320
他们需要更多的资源
they need more resources

773
00:33:48,320 --> 00:33:50,799
对着你的应用程序的复杂性以及
and as your application complexity and

774
00:33:50,799 --> 00:33:53,440
对资源的需求增加
its demand of resources increases

775
00:33:53,440 --> 00:33:56,960
你可以需要添加更多的master和worker服务器
you may actually add more master and node

776
00:33:56,960 --> 00:34:00,000
到您的集群，因此
servers to your cluster and thus

777
00:34:00,000 --> 00:34:03,200
形成了更强大、更稳健的集群
forming a more powerful and robust cluster

778
00:34:03,200 --> 00:34:06,960
以满足您的应用程序资源需求
to meet your application resource requirements

779
00:34:06,960 --> 00:34:09,280
在现有的kubernetes集群中
so in an existing kubernetes cluster you

780
00:34:09,280 --> 00:34:11,839
添加新的master和worker服务器
can actually add new master or node

781
00:34:11,839 --> 00:34:13,280
是很容易的
servers pretty easily

782
00:34:13,280 --> 00:34:15,359
如果你想添加一个master服务器
so if you want to add a master server

783
00:34:15,359 --> 00:34:16,720
你只需要一台裸机
you just get a new bare

784
00:34:16,720 --> 00:34:18,879
你安装所有的master进程
server you install all the master

785
00:34:18,879 --> 00:34:20,720
并将其添加到
processes on it and add it to the

786
00:34:20,720 --> 00:34:21,919
kubernetes集群
kubernetes cluster

787
00:34:21,919 --> 00:34:25,280
如果需要两个worker节点，也可以这样做
same way if you need two worker nodes you get

788
00:34:25,280 --> 00:34:28,320
找两台裸机，安装所有的worker进程
bare servers you install all the worker

789
00:34:28,320 --> 00:34:31,119
如容器运行时
node processes like container runtime

790
00:34:31,119 --> 00:34:32,800
kubelet和kube proxy
kubelet and kube proxy on it

791
00:34:32,800 --> 00:34:34,720
并将其添加到kubernetes集群中
and add it to the kubernetes cluster

792
00:34:34,720 --> 00:34:37,440
就是这样，这样你就可以
that's it and this way you can infinitely

793
00:34:37,440 --> 00:34:40,639
无限增加你的kubernetes集群的
increase the power and resources of your

794
00:34:40,639 --> 00:34:42,000
能力和资源
kubernetes cluster

795
00:34:42,000 --> 00:34:44,240
随着您的副本的复杂性和
as your replication complexity and its

796
00:34:44,240 --> 00:34:47,000
对资源需求的增加
resource demand increases

797
00:34:50,159 --> 00:34:52,240
在这个视频中，我将向你们展示
so in this video i'm going to show you

798
00:34:52,240 --> 00:34:54,399
什么是Minikube和Kubectl
what miniKube and Kubectl are

799
00:34:54,399 --> 00:34:57,200
以及如何建立它们，首先
and how to set them up so first of all

800
00:34:57,200 --> 00:34:58,320
让我们看看什么是Minikube
let's see what is

801
00:34:58,320 --> 00:35:02,720
在kubernetes的世界里
mini cube usually in kubernetes world

802
00:35:02,720 --> 00:35:04,480
当你设置一个产品的集群时
when you are setting up a production

803
00:35:04,480 --> 00:35:06,720
它看起来是这样的
cluster it will look something like this

804
00:35:06,720 --> 00:35:09,599
你会有多个Master
so you would have multiple masters

805
00:35:09,599 --> 00:35:12,160
在生产场景中至少有两个
at least two in a production setting and

806
00:35:12,160 --> 00:35:14,480
您将有多个worker节点
you would have multiple worker nodes

807
00:35:14,480 --> 00:35:17,359
master节点和worker节点
and master nodes and the worker nodes have

808
00:35:17,359 --> 00:35:19,760
各司其职
their own separate responsibility

809
00:35:19,760 --> 00:35:21,440
就像你在图表上看到的
so as you see on the diagram you would

810
00:35:21,440 --> 00:35:23,200
会有分离的
have actual separate

811
00:35:23,200 --> 00:35:26,960
虚拟机或物理机各代表一个node
virtual or physical machines that each represent

812
00:35:26,960 --> 00:35:29,839
现在如果你想在本地环境里
a node now if you want to test something

813
00:35:29,839 --> 00:35:31,760
测试一些东西
on your local environment

814
00:35:31,760 --> 00:35:33,920
或者如果你想快速尝试一些东西
or if you want to try something out very

815
00:35:33,920 --> 00:35:35,280
举例来说
quickly for example

816
00:35:35,280 --> 00:35:39,200
部署了新的应用程序或组件
deploying new application or new components

817
00:35:39,200 --> 00:35:40,720
你想要在本地机器测试
and you want to test it on your local

818
00:35:40,720 --> 00:35:43,359
显然要设置一个集群
machine obviously setting up a cluster

819
00:35:43,359 --> 00:35:44,000
像这样
like this

820
00:35:44,000 --> 00:35:46,320
会很困难
will be pretty difficult or maybe even

821
00:35:46,320 --> 00:35:48,800
如果你没有足够的资源，甚至是不可能的事情
impossible if you don't have enough resources

822
00:35:48,800 --> 00:35:52,000
资源如内存和cpu等等
like memory and cpu etc and exactly for

823
00:35:52,000 --> 00:35:53,520
为解决这一问题
the use case

824
00:35:53,520 --> 00:35:55,680
有一个开源工具
there's this open source tool that is

825
00:35:55,680 --> 00:35:58,320
叫做Minikube
called a mini cube so what a mini cube is

826
00:35:58,320 --> 00:36:01,359
它就是可以一个节点上部署集群
is basically one node cluster where

827
00:36:01,359 --> 00:36:04,880
通过它可以在一个节点上部署master进程和worker进程
the master processes and the worker processes

828
00:36:04,880 --> 00:36:08,320
使两者都运行在一个节点上，而这个节点将
both run on one node and this node will

829
00:36:08,320 --> 00:36:11,599
有一个预装的docker容器运行时
have a docker container runtime pre-installed

830
00:36:11,599 --> 00:36:13,119
这样你就能在该节点上运行
so you will be able to run the

831
00:36:13,119 --> 00:36:16,079
容器或带容器的pod
containers or the pods with containers

832
00:36:16,079 --> 00:36:17,760
而其在你的笔记本电脑上的运行方式
on this node and the way it's going to

833
00:36:17,760 --> 00:36:19,68
是通过
run on your laptop is through

834
00:36:19,680 --> 00:36:23,680
Virtualbox虚拟机或其他管理程序实现的
a virtual box or some other hypervisor

835
00:36:23,680 --> 00:36:26,000
所以基本上Minicube会创建一个
so basically minicube will create a

836
00:36:26,000 --> 00:36:27,040
virtual box

837
00:36:27,040 --> 00:36:30,240
在你的笔记本电脑上，你会看到节点
on your laptop and the node that you see here

838
00:36:30,240 --> 00:36:33,280
将在这个虚拟机中运行
as this node will run in that virtual box

839
00:36:33,280 --> 00:36:36,560
所以总结一下，minicube是一个单节点
so to summarize minicube is a one node

840
00:36:36,560 --> 00:36:37,839
kubernetes集群
kubernetes cluster

841
00:36:37,839 --> 00:36:40,960
在你笔记本电脑的Virtual Box里运行
that runs in a virtual box on your laptop which

842
00:36:40,960 --> 00:36:42,560
可以用于在本地
you can use for testing

843
00:36:42,560 --> 00:36:45,359
测试kubernetes的配置，所以现在
kubernetes on your local setup so now

844
00:36:45,359 --> 00:36:47,520
您已经建立了一个集群或者说微型集群
that you've set up a cluster

845
00:36:47,520 --> 00:36:50,000
在你的笔记本电脑或个人电脑上
or a mini cluster on your laptop or pc

846
00:36:50,000 --> 00:36:51,200
即本地机器上
on your local machine

847
00:36:51,200 --> 00:36:53,119
你需要一些与集群交互的方法
you need some way to interact with a

848
00:36:53,119 --> 00:36:55,359
从而创建
cluster so you want to create

849
00:36:55,359 --> 00:36:59,040
组件、配置等等
components configure it etc and that's where

850
00:36:59,040 --> 00:37:03,280
这就需要kubectl登场了
cubectl comes in the picture

851
00:37:03,280 --> 00:37:05,839
现在有了这个虚拟节点
so now that you have this virtual node

852
00:37:05,839 --> 00:37:07,119
在本地机器上
on your local machine

853
00:37:07,119 --> 00:37:10,560
这代表你需要一些方式
that represents mini cube you need some way to

854
00:37:10,560 --> 00:37:12,400
和集群交互，所以你需要在节点上
interact with that cluster so you need a

855
00:37:12,400 --> 00:37:14,240
创建pod
way to create pods

856
00:37:14,240 --> 00:37:16,480
和其他kubernetes组件的方法
and other kubernetes components on the

857
00:37:16,480 --> 00:37:18,000
可以用kubectl
node and the way to do it

858
00:37:18,000 --> 00:37:21,359
kubectl是k8s集群的命令行工具
is using cubectl which is a command line tool

859
00:37:21,359 --> 00:37:23,680
让我们看看如何
for kubernetes cluster so let's see how

860
00:37:23,680 --> 00:37:24,800
使用它
it actually works

861
00:37:24,800 --> 00:37:27,200
记住，我们说过，minikube同时运行两种进程
remember we said that minicube runs both

862
00:37:27,200 --> 00:37:30,560
master和worker进程，其中一个master进程
master and work processes so one of the master

863
00:37:30,560 --> 00:37:31,520
被称为
processes called

864
00:37:31,520 --> 00:37:34,480
api服务器实际上是指向kubernetes集群的
api server is actually the main entry

865
00:37:34,480 --> 00:37:36,560
主要入口点，如果
point into the kubernetes cluster so if

866
00:37:36,560 --> 00:37:37,280
你想在
you want to do

867
00:37:37,280 --> 00:37:39,040
kubernetes里做任何事情都可以
anything in the kubernetes if you want

868
00:37:39,040 --> 00:37:40,560
要配置任何内容
to configure anything create

869
00:37:40,560 --> 00:37:44,000
创建任何组件，你必须先与api服务器交互
any component you first have to talk to the api server

870
00:37:44,000 --> 00:37:46,079
与api服务器交互可以有
and the way to talk to the api server is

871
00:37:46,079 --> 00:37:47,359
多种不同的方式
through different clients so you can

872
00:37:47,359 --> 00:37:49,520
可以用一个像控制面板一样的ui
have a ui like a dashboard

873
00:37:49,520 --> 00:37:52,640
也可以使用kubernetes api与它对话
you can talk to it using kubernetes api or

874
00:37:52,640 --> 00:37:55,839
也可以用kubectl这样的命令行工具
a command line tool which is cubectl

875
00:37:55,839 --> 00:37:58,000
kubectl实际上是
and cubectl is actually the most

876
00:37:58,000 --> 00:38:00,560
三种方式中最强大的一个
powerful of all the three clients

877
00:38:00,560 --> 00:38:04,000
因为使用kubectl你基本上可以做任何事
because with cubecdl you can basically do anything

878
00:38:04,000 --> 00:38:05,599
在kubernetes中
in the kubernetes that you want and

879
00:38:05,599 --> 00:38:07,200
在本视频教程中
throughout this video tutorials

880
00:38:07,200 --> 00:38:09,839
我们将主要使用kubectl
we're going to be using cube ctl mostly

881
00:38:09,839 --> 00:38:11,359
所以一旦kubectl
so once the cube ctl

882
00:38:11,359 --> 00:38:13,680
向api服务器提交命令
submits commands to the api server to

883
00:38:13,680 --> 00:38:16,640
创建组件、删除组件等
create components delete components etc

884
00:38:16,640 --> 00:38:19,920
minikube节点上的worker进程
the work processes on minicube node

885
00:38:19,920 --> 00:38:21,920
会实际执行
will actually make it happen so they

886
00:38:21,920 --> 00:38:24,480
执行命令
will be actually executing the commands

887
00:38:24,480 --> 00:38:27,119
从而创造组件，摧毁组件、
to create the parts to destroy the parts

888
00:38:27,119 --> 00:38:28,960
创造Service等等
to create services etc

889
00:38:28,960 --> 00:38:31,359
这就是Minikube的设置，以及
so this is the mini cube setup and this

890
00:38:31,359 --> 00:38:34,800
kubectl与集群交互的方式
is how cube ctl is used to interact with the cluster

891
00:38:34,800 --> 00:38:36,880
这里需要注意的重要一点是
an important thing to note here is that

892
00:38:36,880 --> 00:38:39,599
kubectl不仅仅适用于minikube集群
kubectl isn't just for minikube cluster

893
00:38:39,599 --> 00:38:42,480
如果你有一个云集群或混合集群
if you have a cloud cluster or a hybrid

894
00:38:42,480 --> 00:38:44,240
kubectl都可以拿来
cluster whatever cube ctl

895
00:38:44,240 --> 00:38:48,000
用于同任何类型的集群
is the tool to use to interact with

896
00:38:48,000 --> 00:38:50,480
进行交互
any type of kubernetes cluster setup so

897
00:38:50,480 --> 00:38:51,839
这是需要注意的一点
that's important to note here

898
00:38:51,839 --> 00:38:54,880
现在我们知道了Minikube和kubectl是什么
so now that we know what minicube and cubectl are

899
00:38:54,880 --> 00:38:59,119
让我们实际安装它们来进行实战
let's actually install them to see them in practice

900
00:38:59,119 --> 00:39:01,200
我正在使用mac所以
i'm using mac so the installation

901
00:39:01,200 --> 00:39:03,040
安装过程可能会更容易
process will probably be easier

902
00:39:03,040 --> 00:39:04,800
但是我要把安装指南的链接
but i'm going to put the links to the

903
00:39:04,800 --> 00:39:07,119
放到视频下方的简介中
installation guides in the description

904
00:39:07,119 --> 00:39:08,960
所以你可以跟着他们
so you can actually follow them to

905
00:39:08,960 --> 00:39:11,200
在您的操作系统上安装它
install it on your operating system

906
00:39:11,200 --> 00:39:13,440
这里需要注意的一点是
just one thing to note here is that

907
00:39:13,440 --> 00:39:14,720
minikube

908
00:39:14,720 --> 00:39:16,640
需要虚拟化，因为我们
needs a virtualization because as we

909
00:39:16,640 --> 00:39:18,000
提到它会运行
mentioned it's going to run

910
00:39:18,000 --> 00:39:22,720
虚拟机或者虚拟机监控程序
in a virtual box setup or some hypervisor

911
00:39:22,720 --> 00:39:24,960
所以您需要安装某种类型的
so you will need to install some type of

912
00:39:24,960 --> 00:39:26,800
hypervisor，可以是virtualbox
hypervisor it could be virtualbox

913
00:39:26,800 --> 00:39:28,720
我要安装一个虚拟机管理工具，但是
i'm gonna install a hyperkit but it's

914
00:39:28,720 --> 00:39:30,480
要根据这些指令
gonna be in those step-by-step

915
00:39:30,480 --> 00:39:31,680
一步步来
instructions as well

916
00:39:31,680 --> 00:39:36,480
我来告诉你们怎么安装到mac上
so i'm gonna show you how to install it on a mac

917
00:39:36,480 --> 00:39:39,200
我有一个MacOS mojave，所以我要
so i have a mac os mojave so i'm gonna

918
00:39:39,200 --> 00:39:40,800
演示如何安装
show you how to install

919
00:39:40,800 --> 00:39:43,359
这个macos版本的minikube，我
mini cube on this macos version and i'm

920
00:39:43,359 --> 00:39:45,599
我要用brew来安装它
going to be using brew to install it

921
00:39:45,599 --> 00:39:49,119
更新
so we're going to update

922
00:39:49,119 --> 00:39:54,160
首先，我要安装
and the first thing is that i'm going to install

923
00:39:54,160 --> 00:39:57,440
叫hyperkit的管理程序
a hypervisor hyper kit

924
00:39:57,440 --> 00:40:01,040
我要使用到hyperkit
so i'm going to go with the hyperkit

925
00:40:01,040 --> 00:40:06,240
继续，安装它
go ahead and install it

926
00:40:06,240 --> 00:40:08,800
我之前已经安装好了
i already had it install it so with you

927
00:40:08,800 --> 00:40:10,640
如果你是第一次做这件事
if you're doing it for the first time it

928
00:40:10,640 --> 00:40:14,160
可能需要更久，因为它要下载所有的
might take uh longer because it has to download all

929
00:40:14,160 --> 00:40:15,599
这些依赖关系
these dependencies and stuff

930
00:40:15,599 --> 00:40:22,880
现在我要安装Minikube
and now i'm gonna install mini cube

931
00:40:22,880 --> 00:40:26,560
minicube有一个kubectl
and here's the thing minicube has kubectl

932
00:40:26,560 --> 00:40:30,079
作为依赖，所以当我执行这条指令时
as a dependency so when i execute this

933
00:40:30,079 --> 00:40:34,240
它也会安装kubectl
it's going to install cube ctl as well

934
00:40:34,240 --> 00:40:38,720
所以我不需要单独安装它
so i don't need to install it separately

935
00:40:38,720 --> 00:40:41,839
我们看这里
so let's see here

936
00:40:41,839 --> 00:40:43,599
安装minikube的依赖项
installing dependencies for mini cube

937
00:40:43,599 --> 00:40:45,040
这是嗯
which is um

938
00:40:45,040 --> 00:40:48,480
kubernetes cli，这就是kubectl
kubernetes cli this is cube ctl

939
00:40:48,480 --> 00:40:51,599
因为我之前已经安装好了
again because i already had it installed before

940
00:40:51,599 --> 00:40:53,040
它还有一个本地副本
it still has a local copy of the

941
00:40:53,040 --> 00:40:54,720
这就是为什么安装得
dependencies that's why it's

942
00:40:54,720 --> 00:40:58,000
非常快，如果你是第一次做
pretty fast it might take longer

943
00:40:58,000 --> 00:40:59,760
可能需要更长的时间
if you're doing it for the first time so

944
00:40:59,760 --> 00:41:01,440
那么现在所有的东西都安装好了
now that everything is installed let's

945
00:41:01,440 --> 00:41:03,200
让我们检查一下命令
actually check the commands

946
00:41:03,200 --> 00:41:06,880
kubectl命令应该可以工作
so cubectl command should be working

947
00:41:06,880 --> 00:41:08,640
所以我得到了这个命令列表
so i get this list of the commands with

948
00:41:08,640 --> 00:41:10,240
所以
cubectl so it's

949
00:41:10,240 --> 00:41:13,359
在那里和minikube应该也能正常工作
there and minicube should be working as well

950
00:41:13,359 --> 00:41:15,280
如你所见，minikube是和这个命令行工具配套的
and as you see minicube comes with this

951
00:41:15,280 --> 00:41:16,880
安装非常简单
command line tool which is

952
00:41:16,880 --> 00:41:19,440
只需要一个命令
pretty simple so with one command it's

953
00:41:19,440 --> 00:41:20,000
能够把
going to bring

954
00:41:20,000 --> 00:41:24,079
整个kubernetes集群塞进一个节点里
up the whole kubernetes cluster in this one node

955
00:41:24,079 --> 00:41:27,119
然后你可以用它来做一些事情
setup and then you can do stuff with it

956
00:41:27,119 --> 00:41:29,440
你可以停止或删除它
and you can just stop it or delete it

957
00:41:29,440 --> 00:41:32,160
这很简单，现在我们把
it's pretty easy so now that we have

958
00:41:32,160 --> 00:41:33,119
两个都安装了
both installed

959
00:41:33,119 --> 00:41:34,480
命令就在这里
and the commands are there let's

960
00:41:34,480 --> 00:41:37,440
让我们创建一个Minikube得k8s集群
actually create a mini cube kubernetes cluster

961
00:41:37,440 --> 00:41:40,400
正如你看到的，这里有一个启动命令
and as you see there is a start command

962
00:41:40,400 --> 00:41:42,079
我们把这些清空
let's actually clear this

963
00:41:42,079 --> 00:41:44,079
这就是我们如何启动一个
so this is how we're going to start a

964
00:41:44,079 --> 00:41:45,520
kubernetes集群
kubernetes cluster

965
00:41:45,520 --> 00:41:48,720
执行minikube start，这里需要
q mini cube start and here is where the

966
00:41:48,720 --> 00:41:51,359
一个安装好的管理程序
hypervisor installed comes in because

967
00:41:51,359 --> 00:41:52,319
因为minikube
since mini cube

968
00:41:52,319 --> 00:41:54,480
需要在虚拟环境中运行
needs to run in virtual environment

969
00:41:54,480 --> 00:41:55,359
我们要
we're gonna

970
00:41:55,359 --> 00:41:59,040
告诉minikube哪个管理程序
tell minicube which hypervisor

971
00:41:59,040 --> 00:42:01,839
应该用于启动集群
it should use to start a cluster so for

972
00:42:01,839 --> 00:42:03,920
所以我们会指定一个选项
that we're going to specify an option

973
00:42:03,920 --> 00:42:07,040
即vm-driver
which is vm driver

974
00:42:07,040 --> 00:42:09,680
这里我要设置之前安装的
and here i'm going to set the hyperkit

975
00:42:09,680 --> 00:42:10,720
hyperkit作为管理程序
that i installed

976
00:42:10,720 --> 00:42:14,480
所以我告诉minikube请使用hyperkit
so i'm telling minicube please use hyperkit

977
00:42:14,480 --> 00:42:17,280
来启动这个虚拟minikube集群
hypervisor to start this virtual mini

978
00:42:17,280 --> 00:42:19,760
当我执行这条命令时
cube cluster so when i execute this

979
00:42:19,760 --> 00:42:22,319
它会再次下载一些东西
it's gonna download some stuff so again

980
00:42:22,319 --> 00:42:23,119
第一次的话
it may take

981
00:42:23,119 --> 00:42:25,359
可能需要
a little bit longer if you're doing it

982
00:42:25,359 --> 00:42:28,880
更长一点的时间
for the first time

983
00:42:28,880 --> 00:42:31,920
正如我提到的，minikube有预装的docker运行时
and as i mentioned minicube has docker

984
00:42:31,920 --> 00:42:33,760
和docker守护进程
runtime or docker daemon

985
00:42:33,760 --> 00:42:36,880
即使你没有安装docker
pre-installed so even if you don't have docker

986
00:42:36,880 --> 00:42:39,440
在你的机器上它仍然可以工作，所以
on your machine it's still gonna work so

987
00:42:39,440 --> 00:42:40,480
你可以
you would be able to

988
00:42:40,480 --> 00:42:42,960
在里面创建容器，因为它
create containers inside because it

989
00:42:42,960 --> 00:42:44,800
已经包含docker，这是一个
already contains docker which is a

990
00:42:44,800 --> 00:42:45,920
很好的东西
pretty good thing

991
00:42:45,920 --> 00:42:48,960
即使你之前没有安装过docker
uh if you don't have docker already installed so

992
00:42:48,960 --> 00:42:51,040
好的现在提示kubectl配置为
done cube ctl is now configured to use

993
00:42:51,040 --> 00:42:52,640
使用minikube，这意味着
mini cube which means

994
00:42:52,640 --> 00:42:57,200
已经完成了minikube和kubectl的配置
the mini cube cluster is set up and kubectl command

995
00:42:57,200 --> 00:42:59,599
它是用来与
which is meant to interact with the

996
00:42:59,599 --> 00:43:01,440
kubernetes集群进行交互的
kubernetes clusters

997
00:43:01,440 --> 00:43:04,480
与那个minikube集群相连
is also connected with that mini cube cluster

998
00:43:04,480 --> 00:43:07,599
也就是说如果我
which means if i

999
00:43:07,599 --> 00:43:11,119
写kubectl get nodes会收到
do cube ctl get nodes which just gets me

1000
00:43:11,119 --> 00:43:15,280
k8s节点的状态
a status of the notes of the kubernetes 04,480

1001
00:43:15,280 --> 00:43:18,560
它会告诉我这个minikube节点
it's going to tell me that the mini cube node

1002
00:43:18,560 --> 00:43:22,319
已经准备好了，如你所见这是唯一的节点
is ready and as you see it's the only node

1003
00:43:22,319 --> 00:43:24,079
它的作用是master，因为它
and it has a master role because it

1004
00:43:24,079 --> 00:43:26,880
显然需要运行master进程
obviously has to run the master processes

1005
00:43:26,880 --> 00:43:31,119
我也可以得到minikube的状态
and i can also get the status with minicube

1006
00:43:31,119 --> 00:43:34,400
执行minikube status，使我看到主机
executing minicube status so i see host

1007
00:43:34,400 --> 00:43:35,359
正在运行
is running

1008
00:43:35,359 --> 00:43:39,680
kubelet是一种Service
cubelet which is a service that actually runs the parts

1009
00:43:39,680 --> 00:43:42,560
使用容器运行时，现在运行中
using container runtime is running so

1010
00:43:42,560 --> 00:43:44,079
基本上一切都在运行
basically everything is running

1011
00:43:44,079 --> 00:43:45,359
顺便说一下，如果你想了解
and by the way if you want to see

1012
00:43:45,359 --> 00:43:48,240
更详细的kubernetes架构
kubernetes architecture in more detail

1013
00:43:48,240 --> 00:43:50,160
并进一步理解master和worker
and to understand how master

1014
00:43:50,160 --> 00:43:52,079
实际上如何工作的
and worker nodes actually work and what

1015
00:43:52,079 --> 00:43:54,079
以及所有这些进程都是什么
all these processes are

1016
00:43:54,079 --> 00:43:56,400
我有一个单独的视频
i have a separate video that covers

1017
00:43:56,400 --> 00:43:58,240
介绍kubernetes架构，你可以
kubernetes architecture so you can check

1018
00:43:58,240 --> 00:43:59,920
点击链接学习
it out on this link

1019
00:43:59,920 --> 00:44:02,160
我们也可以检查我们安装的
and we can also check which version of

1020
00:44:02,160 --> 00:44:03,839
是哪个版本的k8s
kubernetes we have

1021
00:44:03,839 --> 00:44:06,240
通常是
installed and usually it's going to be

1022
00:44:06,240 --> 00:44:07,680
最新版本
the latest version

1023
00:44:07,680 --> 00:44:09,599
通过kubectl version命令，你可以
so with cube ctl version you actually

1024
00:44:09,599 --> 00:44:11,280
知道客户端版本
know what the client version of

1025
00:44:11,280 --> 00:44:13,119
以及k8s的服务器版本
kubernetes is and what the server

1026
00:44:13,119 --> 00:44:14,720
都是多少
version of kubernetes is

1027
00:44:14,720 --> 00:44:18,960
这里我们用的是1.17
and here we see we're using 1.17

1028
00:44:18,960 --> 00:44:21,280
这就是在minikube集群中运行的
and that's the kubernetes version that

1029
00:44:21,280 --> 00:44:23,280
kubernetes的版本
is running in the mini cube cluster

1030
00:44:23,280 --> 00:44:25,280
所以如果你在输出中同时看到客户端版本和
so if you see both client version and

1031
00:44:25,280 --> 00:44:27,040
服务器版本
server version in the output it means

1032
00:44:27,040 --> 00:44:28,240
这意味着minikube
that mini cube

1033
00:44:28,240 --> 00:44:30,880
已经被正确安装了
is correctly installed so from this

1034
00:44:30,880 --> 00:44:31,680
所以此后
point on

1035
00:44:31,680 --> 00:44:33,119
我们将会
we're going to be interacting with the

1036
00:44:33,119 --> 00:44:35,520
使用kubectl与minikube集群进行交互
mini cube cluster using cubectl

1037
00:44:35,520 --> 00:44:37,520
minicube作为命令行工具
command line tool so minicube is

1038
00:44:37,520 --> 00:44:39,200
基本上只是针对启动
basically just for the startup

1039
00:44:39,200 --> 00:44:41,520
和删除集群时使用的，但是
and for deleting the cluster but

1040
00:44:41,520 --> 00:44:43,599
其他的配置
everything else configuring

1041
00:44:43,599 --> 00:44:45,680
我们将通过kubectl来执行
we're going to be doing through cubectl

1042
00:44:45,680 --> 00:44:47,920
我所执行的所有这些命令
and all these commands that i executed here

1043
00:44:47,920 --> 00:44:49,599
我会把它们放到一个列表里
i'm going to put them in a list in the

1044
00:44:49,599 --> 00:44:53,000
写在注释部分，这样你就可以复制了
comment section so you can actually copy them

1045
00:44:54,720 --> 00:44:56,800
在这段视频中，我将向你们展示一些
in this video i'm gonna show you some

1046
00:44:56,800 --> 00:44:58,640
基本kubectl命令
basic kubectl commands

1047
00:44:58,640 --> 00:45:05,200
以及如何在minikube中创建和调试pod
and how to create and debug pods in minicube

1048
00:45:05,200 --> 00:45:08,079
现在我们已经安装了minikube和kubectl
so now we have a mini cube cluster and

1049
00:45:08,079 --> 00:45:10,640
一旦集群被设置好
kube ctl installed and once the cluster

1050
00:45:10,640 --> 00:45:12,960
你要用kubectl
is set up you're going to be using

1051
00:45:12,960 --> 00:45:16,319
来做集群中的任何事情
cubectl to basically do anything in the cluster

1052
00:45:16,319 --> 00:45:18,560
比如创建组件，获取状态信息等等
to create components uh to get the

1053
00:45:18,560 --> 00:45:21,280
首先
status etc so first thing

1054
00:45:21,280 --> 00:45:25,200
我们只需要获取节点的状态
we are gonna just get the status of the nodes

1055
00:45:25,200 --> 00:45:28,400
我们看到有一个节点
so we see that there is one node which

1056
00:45:28,400 --> 00:45:29,839
是一个master
is a master

1057
00:45:29,839 --> 00:45:31,599
所有的事都要在那个节点上运行
and everything is gonna run on that node

1058
00:45:31,599 --> 00:45:33,520
因为它是minikube
because it's a mini cube

1059
00:45:33,520 --> 00:45:36,720
嗯，用kubectl，我可以检查pod
um so with kubectl i'll get i can check

1060
00:45:36,720 --> 00:45:39,280
我没有pod，这就是为什么显示
the pods and i don't have any that's why

1061
00:45:39,280 --> 00:45:40,480
没有资源
no resources

1062
00:45:40,480 --> 00:45:43,599
我可以检查service
i can check the services

1063
00:45:43,599 --> 00:45:46,640
get services

1064
00:45:46,640 --> 00:45:49,280
我只有一个默认service
and i just have one default service and

1065
00:45:49,280 --> 00:45:49,920
所以
so on so

1066
00:45:49,920 --> 00:45:52,880
用这个kubectl get，我可以列出任何
this kubectl get i can list any

1067
00:45:52,880 --> 00:45:54,960
kubernetes组件
kubernetes components

1068
00:45:54,960 --> 00:45:57,520
既然我们没有任何部分
so now since we don't have any parts

1069
00:45:57,520 --> 00:45:58,880
我们要创建一个
we're going to create one

1070
00:45:58,880 --> 00:46:01,119
创建kubernetes组件
and to create kubernetes components

1071
00:46:01,119 --> 00:46:01,920
可以用
there is

1072
00:46:01,920 --> 00:46:05,359
kubectl create命令
a kubectl create command

1073
00:46:05,359 --> 00:46:09,359
如果我在kubectl create后面输入help选项
so if i do help on that kubectl

1074
00:46:09,359 --> 00:46:13,280
我可以看到它的可用命令
create command i can see available commands for it

1075
00:46:13,280 --> 00:46:16,240
所以我可以创建所有这些组件
so i can create all these components

1076
00:46:16,240 --> 00:46:17,760
使用kubectl create
using cube ctl create

1077
00:46:17,760 --> 00:46:20,880
但列表里没有pod，因为
but there is no pod on the list because

1078
00:46:20,880 --> 00:46:23,599
在kubernetes的世界里
in kubernetes world the way it works is

1079
00:46:23,599 --> 00:46:24,480
pod是
that the pod

1080
00:46:24,480 --> 00:46:26,720
kubernetes集群的最小单位
is the smallest unit of the kubernetes

1081
00:46:26,720 --> 00:46:28,319
但通常
cluster but usually

1082
00:46:28,319 --> 00:46:31,520
实际上你并不是在创造pod
in practice you're not creating pots or

1083
00:46:31,520 --> 00:46:33,760
你不是直接和pod打交道
you're not working with the pods directly

1084
00:46:33,760 --> 00:46:35,680
在pod之上有一个抽象层
there is an abstraction layer over the

1085
00:46:35,680 --> 00:46:37,280
叫做Deployment
pots that is called

1086
00:46:37,280 --> 00:46:41,280
这就是我们要创建的
deployment so this is what we are going to be creating

1087
00:46:41,280 --> 00:46:42,800
所以需要
and that's going to create the parts

1088
00:46:42,800 --> 00:46:44,880
kubectl create deployment命令
underneath and this is a usage

1089
00:46:44,880 --> 00:46:47,920
来创建
of kubectl create deployment

1090
00:46:47,920 --> 00:46:49,839
还需要给出一个名字
so i need to give a name of the

1091
00:46:49,839 --> 00:46:52,079
然后提供一些选项
deployment and then provide some options

1092
00:46:52,079 --> 00:46:53,520
这个选择就是
and the option that is

1093
00:46:53,520 --> 00:46:56,880
需要的映像，因为pod
required is the image because the pod

1094
00:46:56,880 --> 00:46:58,560
需要基于某些
needs to be created based on certain

1095
00:46:58,560 --> 00:46:59,520
某些镜像
some image

1096
00:46:59,520 --> 00:47:01,839
或者某个容器的图像，让我们
or some container image so let's

1097
00:47:01,839 --> 00:47:03,680
继续，创建一个nginx的deployment
actually go ahead and create

1098
00:47:03,680 --> 00:47:07,599
所以输入kubectl create deployment
nginx deployment so cubectl

1099
00:47:07,599 --> 00:47:15,760
我们命名为nginx-depl
create deployment we let's call it nginx deployment um

1100
00:47:15,760 --> 00:47:19,119
image = nginx，它会从dockerhub
image equals nginx it's just going to

1101
00:47:19,119 --> 00:47:23,280
下载最新的nginx镜像
go ahead and download the latest nginx image from

1102
00:47:23,280 --> 00:47:25,440
这就是它做的事情
docker hub that's how it's going to work

1103
00:47:25,440 --> 00:47:27,440
当我执行这个的时候
so when i execute this

1104
00:47:27,440 --> 00:47:30,880
你可以看到nginx-depl已被创建
you see deployment nginx-depl

1105
00:47:30,880 --> 00:47:40,240
现在如果我写kubectl get deployment
created so now if i do kubectl get deployment

1106
00:47:40,240 --> 00:47:41,920
你看，我有一个deployment被创建了
you see that i have one deployment

1107
00:47:41,920 --> 00:47:44,079
它的状态是
created i have a status here

1108
00:47:44,079 --> 00:47:47,440
还没准备好，所以
which says it's not ready yet so

1109
00:47:47,440 --> 00:47:51,119
如果我写kubectl get pod
if i do kube ctl get pod

1110
00:47:51,119 --> 00:47:54,240
你看，现在我有一个pod
you see that now i have a pod which has

1111
00:47:54,240 --> 00:47:57,040
前缀是部署的名
a prefix of the deployment and some random

1112
00:47:57,040 --> 00:47:59,920
后面跟着随机的标签，它说正在创建容器
hash here and it says container creating

1113
00:47:59,920 --> 00:48:02,480
也就是它还没有准备好
so it's not ready yet

1114
00:48:02,480 --> 00:48:06,240
那么我再输入一次，它现在在运行
so if i do it again it's running and

1115
00:48:06,240 --> 00:48:08,400
操作方法就是
the way it works here is that when i

1116
00:48:08,400 --> 00:48:10,319
创建一个deployment
create a deployment

1117
00:48:10,319 --> 00:48:13,200
deployment有为了创建pod所需的
deployment has all the information or

1118
00:48:13,200 --> 00:48:14,559
所有的信息或者蓝图
the blueprint

1119
00:48:14,559 --> 00:48:16,880
这是
for creating the pod the for the this is

1120
00:48:16,880 --> 00:48:19,359
极简的或最基本的
the minimalistic or the most basic

1121
00:48:19,359 --> 00:48:21,599
deployment的配置
configuration for a deployment we're

1122
00:48:21,599 --> 00:48:22,800
我们只写了名字和镜像
just saying the name

1123
00:48:22,800 --> 00:48:26,720
剩下的按默认设置
and the image that's it the rest is just defaults

1124
00:48:26,720 --> 00:48:29,200
在deployment和pod之间
and between deployment and pod there

1125
00:48:29,200 --> 00:48:30,640
有另一个层
is another layer

1126
00:48:30,640 --> 00:48:34,319
由k8s的deployment自动管理
which is automatically managed by kubernetes

1127
00:48:34,319 --> 00:48:38,079
称为ReplicaSet，如果我这样写
deployment called replica set so if i do

1128
00:48:38,079 --> 00:48:41,920
kubectl get replicaset

1129
00:48:41,920 --> 00:48:45,280
replica和set一起写
written together you see i have

1130
00:48:45,280 --> 00:48:48,880
此时我有一个nginx-depl的ReplicaSet的标签
an nginx depl replica set

1131
00:48:48,880 --> 00:48:52,160
它还给了我一个状态信息
hash and it just gives me a state

1132
00:48:52,160 --> 00:48:55,680
如果你注意到pod的名字
and if you notice here the pod name

1133
00:48:55,680 --> 00:48:58,880
前缀是
has a prefix of

1134
00:48:58,880 --> 00:49:02,000
deployment名和ReplicaSet的id
deployment and the replica sets id and

1135
00:49:02,000 --> 00:49:02,640
然后是
then its

1136
00:49:02,640 --> 00:49:06,800
它自己的id，这就是pod的名称组成
own id so this is how the pod name is made up

1137
00:49:06,800 --> 00:49:09,599
ReplicaSet基本上是
and the replica set basically is

1138
00:49:09,599 --> 00:49:11,359
用于管理一个pod的副本
managing the replicas

1139
00:49:11,359 --> 00:49:14,880
在实践中你不必
of a pod you in practice will never

1140
00:49:14,880 --> 00:49:17,760
以任何方式
have to create replica set or delete a

1141
00:49:17,760 --> 00:49:20,800
创建或删除或更新一个ReplicaSet
replica set or update in any way

1142
00:49:20,800 --> 00:49:21,920
你将直接和deployment打交道
you're going to be working with

1143
00:49:21,920 --> 00:49:24,160
这会更加方便
deployments directly which is

1144
00:49:24,160 --> 00:49:26,000
因为在deployment里
more convenient because in deployment

1145
00:49:26,000 --> 00:49:28,800
您可以完整配置pod蓝图
you can configure the pod blueprint

1146
00:49:28,800 --> 00:49:31,119
你可以说你想要pod
completely you can say how many replicas

1147
00:49:31,119 --> 00:49:32,559
有多少个副本
of the pod you want

1148
00:49:32,559 --> 00:49:33,920
你也可以完成其他的配置
and you can do the rest of the

1149
00:49:33,920 --> 00:49:36,720
通过这条命令
configuration there here with this command

1150
00:49:36,720 --> 00:49:40,480
我们刚刚创建了一个pod，一个副本
we just created one pod or one replica

1151
00:49:40,480 --> 00:49:43,760
但如果你想要nginx部分有两个副本
but if you wanted to have two replicas of the

1152
00:49:43,760 --> 00:49:46,800
我们可以提供额外的选项
nginx part we can just provide as

1153
00:49:46,800 --> 00:49:50,400
这就是这些层是如何工作的
additional options so this is how the layers work

1154
00:49:50,400 --> 00:49:53,440
首先你要有deployment
first you have the deployment

1155
00:49:53,440 --> 00:49:56,559
deployment管理一个ReplicaSet
the deployment manages a replica set a

1156
00:49:56,559 --> 00:49:59,119
replica set管理所有pod的副本
replica set manages all the replicas

1157
00:49:59,119 --> 00:50:02,480
pod是
of that pod and the pod is

1158
00:50:02,480 --> 00:50:05,520
一个容器的抽象
again an abstraction of a container

1159
00:50:05,520 --> 00:50:07,839
deployment之下的一切
and everything below the deployment

1160
00:50:07,839 --> 00:50:10,319
应该由kubernetes自动管理
should be managed automatically by kubernetes

1161
00:50:10,319 --> 00:50:12,240
你不需要担心任何问题
you don't have to worry about any of

1162
00:50:12,240 --> 00:50:14,400
比如它要用的图像
it for example the image

1163
00:50:14,400 --> 00:50:17,839
我可以直接把它编辑进deployment里
that it uses i will have to edit that in

1164
00:50:17,839 --> 00:50:20,400
而不是在pod
the deployment directly and not in the pod

1165
00:50:20,400 --> 00:50:22,640
我们现在就开始吧
so let's go ahead and do that right away

1166
00:50:22,640 --> 00:50:23,599
我要这么做
so i'm going to do

1167
00:50:23,599 --> 00:50:27,520
kubectl edit deployment

1168
00:50:27,520 --> 00:50:32,960
提供名字nginx
and i'm going to provide the name nginx

1169
00:50:32,960 --> 00:50:35,280
我们得到一个自动生成的
and we get an auto-generated

1170
00:50:35,280 --> 00:50:37,280
deployment的配置文件
configuration file of the deployment

1171
00:50:37,280 --> 00:50:38,880
因为在我们刚刚给出的命令行中
because in the command line we just gave

1172
00:50:38,880 --> 00:50:41,440
其他选项都是默认选项
two options everything else is default

1173
00:50:41,440 --> 00:50:44,319
由kubernetes自动生成
and auto generated by kubernetes

1174
00:50:44,319 --> 00:50:45,920
你不需要理解这个
and you don't have to understand this

1175
00:50:45,920 --> 00:50:48,000
但是我会一个单独的视频
now but i'm going to make a separate video

1176
00:50:48,000 --> 00:50:50,319
将配置文件结构
where i break down the configuration

1177
00:50:50,319 --> 00:50:52,720
并分析配置文件的语法
file and the syntax

1178
00:50:52,720 --> 00:50:55,040
现在让我们
of the configuration file for now let's

1179
00:50:55,040 --> 00:50:56,000
继续
just go ahead

1180
00:50:56,000 --> 00:50:59,680
滚动到这个image
and scroll to the image which is

1181
00:50:59,680 --> 00:51:01,839
下面的某个地方
somewhere down below

1182
00:51:01,839 --> 00:51:08,960
假设我想修改版本为1.16
and let's say i want to fixate the version to 1.16 and

1183
00:51:08,960 --> 00:51:12,640
保存更改
save that change

1184
00:51:12,640 --> 00:51:15,760
正如你看到的deployment被编辑了
and as you see deployment was edited and

1185
00:51:15,760 --> 00:51:16,960
现在当我这么做的时候
now when i do

1186
00:51:16,960 --> 00:51:20,800
kubectl get pod

1187
00:51:20,800 --> 00:51:23,920
我看到那个旧的pod被终止了
i see that the old pod so

1188
00:51:23,920 --> 00:51:28,319
而另一个pod
this one here is terminating and another one

1189
00:51:28,319 --> 00:51:31,359
在25秒前被启动
started 25 seconds ago so

1190
00:51:31,359 --> 00:51:34,960
如果我再做一次，旧的部分就消失了
if i do it again the old part is gone

1191
00:51:34,960 --> 00:51:39,040
这个新的是用一个新的镜像创建的
and the new one got created with a new image

1192
00:51:39,040 --> 00:51:45,599
如果我输入kubectl get replicaset
and if i do if i get replica set

1193
00:51:45,599 --> 00:51:49,280
我看到旧的已经没有东西了
i see that the old one has no parts in it

1194
00:51:49,280 --> 00:51:51,920
新的刚刚被创建了
and a new one has been created as well

1195
00:51:51,920 --> 00:51:52,559
所以
so

1196
00:51:52,559 --> 00:51:56,240
我们刚刚编辑了deployment的配置
we just edited the deployment configuration

1197
00:51:56,240 --> 00:51:59,119
而在它下面的东西
and everything else below that got

1198
00:51:59,119 --> 00:52:01,200
也就自动更新了
automatically updated

1199
00:52:01,200 --> 00:52:03,119
这就是kubernetes的魔力
and that's the magic of kubernetes and

1200
00:52:03,119 --> 00:52:07,520
这就是它的工作原理
that's how it works

1201
00:52:07,520 --> 00:52:11,760
另一个非常实用的命令是kubectl logs
another very practical command is kubectl logs

1202
00:52:11,760 --> 00:52:13,760
它基本上可以展示
which basically shows you what the

1203
00:52:13,760 --> 00:52:16,160
在pod中运行的应用程序
application running inside the pod

1204
00:52:16,160 --> 00:52:19,359
记录的东西，如果我写kubectl logs
actually logged so if i do cube ctrl

1205
00:52:19,359 --> 00:52:22,800
它需要pod的名字
logs and i will need the pod name

1206
00:52:22,800 --> 00:52:26,720
我什么都拿不到，因为
for this um i will get nothing because

1207
00:52:26,720 --> 00:52:28,559
nginx没有记录任何东西，所以让我们
nginx didn't log anything so let's

1208
00:52:28,559 --> 00:52:29,680
用mongodb创建
actually create

1209
00:52:29,680 --> 00:52:33,359
另一个deployment
another deployment

1210
00:52:33,359 --> 00:52:38,000
给它命名为mongo-depl
from mongodb so let's call it deployment

1211
00:52:38,000 --> 00:52:41,520
指定镜像为mongo
and the image and the image will be

1212
00:52:41,520 --> 00:52:48,720
输入kubectl get ppod
on go so let's see ctrl

1213
00:52:48,720 --> 00:52:51,760
所以现在我有mongodb的deployment
pod so now i have the mongodb deployment

1214
00:52:51,760 --> 00:52:52,720
正在被创建
creating

1215
00:52:52,720 --> 00:52:56,640
继续，log一下
so let's go ahead and log that

1216
00:52:56,640 --> 00:52:59,359
这里的情况表示pod被创建了
this status here means that pod was

1217
00:52:59,359 --> 00:53:00,960
但是里面的容器
created but the container

1218
00:53:00,960 --> 00:53:04,079
还没有运转
inside the pod isn't running yet

1219
00:53:04,079 --> 00:53:07,200
当我试图log的时候
and when i try to log obviously

1220
00:53:07,200 --> 00:53:09,280
告诉我没有容器运行
tells me there is no container running

1221
00:53:09,280 --> 00:53:11,359
所以不会显示任何日志
so it can't show me any logs

1222
00:53:11,359 --> 00:53:15,520
让我们现在再来看看状态
so let's get the status again at this point if i'm

1223
00:53:15,520 --> 00:53:17,920
看到容器还没有启动
seeing that container isn't starting i

1224
00:53:17,920 --> 00:53:18,880
我可以
can actually

1225
00:53:18,880 --> 00:53:22,720
通过kube describe pod获取一些附加信息
get some additional information by kubectl describe


1226
00:53:22,720 --> 00:53:27,040
pod的名字写在这里
pod and the pod name which here shows me

1227
00:53:27,040 --> 00:53:30,480
现在它告诉我pod内发生了什么变化
what state changes happened inside the pod

1228
00:53:30,480 --> 00:53:32,559
它拉取镜像
so it pulled the image created the

1229
00:53:32,559 --> 00:53:34,800
创建并启动了一个容器
container and started container

1230
00:53:34,800 --> 00:53:37,920
再来kubectl get pod
so kubectl get pod it should be

1231
00:53:37,920 --> 00:53:39,200
应该已经运行起来了
running already

1232
00:53:39,200 --> 00:53:44,960
现在我们打印日志kubectl logs
so now let's log it cubectl logs

1233
00:53:44,960 --> 00:53:46,960
这里是log输出
and here we see the log output so it

1234
00:53:46,960 --> 00:53:48,800
花了一点时间
took a little bit

1235
00:53:48,800 --> 00:53:52,800
但这就是mongodb应用程序容器
but this is what the mongodb application container

1236
00:53:52,800 --> 00:53:54,720
实际在pod里的日志信息
actually logged inside the pod and

1237
00:53:54,720 --> 00:53:56,480
显然如果
obviously if

1238
00:53:56,480 --> 00:53:58,960
容器出了点问题
container has some problems it's going

1239
00:53:58,960 --> 00:54:00,400
为了帮助调试
to help with debugging

1240
00:54:00,400 --> 00:54:03,760
可以看看这个应用程序打印了什么
to see what the application is actually printing

1241
00:54:03,760 --> 00:54:09,359
我们把它清除掉，再来get pod
so let's clear that and get the pods again

1242
00:54:09,359 --> 00:54:13,040
另一个非常有用的命令是
so another very useful command when

1243
00:54:13,040 --> 00:54:15,119
用于当某些东西不工作时进行调试
debugging when something is not working

1244
00:54:15,119 --> 00:54:16,079
或者当你只想
or you just want to

1245
00:54:16,079 --> 00:54:19,839
看看pod里发生了什么时，所执行的命令
check what's going on inside the pod is

1246
00:54:19,839 --> 00:54:22,960
kubectl exec

1247
00:54:22,960 --> 00:54:24,720
基本上它所做的就是
so basically what it does is that it

1248
00:54:24,720 --> 00:54:29,680
获取mongodb应用程序容器的终端
gets the terminal of that mongodb application container

1249
00:54:29,680 --> 00:54:33,280
可以用it表示让kubectl exec
so if i do kubectl exec interactive

1250
00:54:33,280 --> 00:54:34,319
获取交互式终端
terminal that's what

1251
00:54:34,319 --> 00:54:39,520
需要pod的名称
i t stands for i will need the pod name

1252
00:54:39,520 --> 00:54:42,880
破折号
dash dash

1253
00:54:42,880 --> 00:54:46,319
通过这个命令，我得到
so so with this command i get the

1254
00:54:46,319 --> 00:54:48,880
mongodb应用容器的终端
terminal of the mongodb application container

1255
00:54:48,880 --> 00:54:50,880
你们可以看到，我在
and as you see here i am inside the

1256
00:54:50,880 --> 00:54:52,079
mongodb的容器里
container of mongodb

1257
00:54:52,079 --> 00:54:54,720
作为一个根用户，所以我在一个完全
as a root user so i'm in a completely

1258
00:54:54,720 --> 00:54:56,319
不同的设置中
different setting now

1259
00:54:56,319 --> 00:54:58,240
就像我说的，这在调试
and as i said this is useful in

1260
00:54:58,240 --> 00:55:00,319
或者当你想
debugging or when you want to

1261
00:55:00,319 --> 00:55:02,480
测试或尝试一些东西时会很有用
test something or try something you can

1262
00:55:02,480 --> 00:55:04,640
进入容器并获取终端
enter the container or get the terminal

1263
00:55:04,640 --> 00:55:08,000
并在里面执行一些命令
and execute some commands inside there

1264
00:55:08,000 --> 00:55:12,400
我们可以再次退出
so we can exit that again

1265
00:55:12,400 --> 00:55:19,599
当然，使用kubectl我可以删除pod
and of course with cubectl i can delete the pods so if i do

1266
00:55:19,599 --> 00:55:22,799
get deployment

1267
00:55:22,799 --> 00:55:26,319
哎呀deployment拼错了
let me spell that so it keeps it here deployment

1268
00:55:26,319 --> 00:55:28,960
可以看到有两个，如果我
i see that i have two of them and if i

1269
00:55:28,960 --> 00:55:29,680
输入kubectl get pod
do kubectl

1270
00:55:29,680 --> 00:55:33,280
我还是有两个
get pod and replica set i have also two of them

1271
00:55:33,280 --> 00:55:36,079
假设我想消掉
so let's say if i wanted to get rid of

1272
00:55:36,079 --> 00:55:37,040
所有的pod
all the pods

1273
00:55:37,040 --> 00:55:40,720
及其副本，就需要删除deployment
replica sets underneath i will have to delete

1274
00:55:40,720 --> 00:55:44,480
所以输入delete deployment
the deployment so delete

1275
00:55:44,480 --> 00:55:46,640
还必须提供
deployment and i'll have to provide the

1276
00:55:46,640 --> 00:55:48,240
deployment的名称
name of the deployment

1277
00:55:48,240 --> 00:55:53,200
让我们删除mongodb
i'm gonna delete let's delete mongodb

1278
00:55:53,200 --> 00:55:55,680
删除它，再输入
delete it and now if i'm gonna say

1279
00:55:55,680 --> 00:55:57,280
kubectl get pod

1280
00:55:57,280 --> 00:56:00,640
这部分应该终止了，如果我
the part should be terminating and if i do

1281
00:56:00,640 --> 00:56:04,079
输入get replicaset
get replica set the

1282
00:56:04,079 --> 00:56:07,520
mongodb的replicaset也消失了
mongodb replica set is gone as well and

1283
00:56:07,520 --> 00:56:08,720
如果我
the same if i

1284
00:56:08,720 --> 00:56:12,160
删除nginx-depl的deployment
do delete deployment

1285
00:56:12,160 --> 00:56:16,960
并执行get replicaset
nginx-depl and do the replica set

1286
00:56:16,960 --> 00:56:20,240
看，一切都消失了
see everything gone so all the crud

1287
00:56:20,240 --> 00:56:23,119
所有的操作如创建、删除、更新等
operations create delete update etc

1288
00:56:23,119 --> 00:56:25,040
都发生在deployment级别
happens on the deployment level and

1289
00:56:25,040 --> 00:56:26,160
该层之下的一切
everything underneath

1290
00:56:26,160 --> 00:56:28,480
都在自动进行
just follows automatically and the

1291
00:56:28,480 --> 00:56:30,000
我们可以用类似的方式创造
similar way we can create

1292
00:56:30,000 --> 00:56:31,680
其他协调资源，如
other coordinates resources like

1293
00:56:31,680 --> 00:56:33,440
Service等
services etc

1294
00:56:33,440 --> 00:56:35,599
然而，当你注意到我们
however as you notice when we're

1295
00:56:35,599 --> 00:56:39,040
创建kubernetes组件，例如
creating kubernetes components like deployment

1296
00:56:39,040 --> 00:56:42,160
使用kubectl create deployment创建deployment时
using cubectl create deployment

1297
00:56:42,160 --> 00:56:46,079
哦我总是拼错
um and i misspelled it all the time

1298
00:56:46,079 --> 00:56:49,119
你必须在命令行中提供所有这些选项
you'll have to provide all these options on the command line

1299
00:56:49,119 --> 00:56:51,119
所以你得写名字，然后
so you'll have to say the name and

1300
00:56:51,119 --> 00:56:52,240
你必须
you'll have to

1301
00:56:52,240 --> 00:56:54,559
指定镜像，接下来可能还有
specify the image and then you have this

1302
00:56:54,559 --> 00:56:55,359
选项一
option one

1303
00:56:55,359 --> 00:56:58,400
选项二等等
option two uh etc

1304
00:56:58,400 --> 00:57:00,240
在deployment或者pod中
and there could be a lot of things that

1305
00:57:00,240 --> 00:57:01,599
可能会有很多
you want to configure

1306
00:57:01,599 --> 00:57:04,480
您想要配置的东西
in a deployment or in a pod and

1307
00:57:04,480 --> 00:57:05,200
很明显
obviously

1308
00:57:05,200 --> 00:57:07,839
把这些都写到命令行
it will be impractical to write that all

1309
00:57:07,839 --> 00:57:09,599
是不实际的
out on a command line

1310
00:57:09,599 --> 00:57:12,640
因此在实践中你通常
so because of that in practice you would

1311
00:57:12,640 --> 00:57:15,839
会使用kubernetes配置文件
usually work with kubernetes configuration files

1312
00:57:15,839 --> 00:57:18,559
这意味着您正在创建什么组件
meaning what component you're creating

1313
00:57:18,559 --> 00:57:20,880
组件的名称是什么
what the name of the component is

1314
00:57:20,880 --> 00:57:24,880
它是基于什么镜像像和任何其他选项
what image is it based off and any other options

1315
00:57:24,880 --> 00:57:28,720
都可以聚集在一个配置文件中
they're all gathered in a configuration file

1316
00:57:28,720 --> 00:57:32,400
你只要让kubectl执行那个配置文件就行了
and you just tell kubectl to execute

1317
00:57:32,400 --> 00:57:35,839
你可以
that configuration file and the way you do it is

1318
00:57:35,839 --> 00:57:39,200
使用kubectl apply命令
using cubectl apply command

1319
00:57:39,200 --> 00:57:42,000
apply将配置文件作为参数
and apply basically takes the file the

1320
00:57:42,000 --> 00:57:44,319
来获取文件
configuration file as a parameter

1321
00:57:44,319 --> 00:57:47,040
然后按里面你写的内容执行
and does whatever you have written there

1322
00:57:47,040 --> 00:57:47,680
所以
so

1323
00:57:47,680 --> 00:57:50,799
apply接受一个名为-f的选项
apply takes an option called minus f

1324
00:57:50,799 --> 00:57:54,720
那代表文件名，在这里你要写
that stands for file and here you would say

1325
00:57:54,720 --> 00:57:57,839
文件的名称
the name of the file so this will be the config

1326
00:57:57,839 --> 00:58:01,040
config-file.yaml
file dot yaml this is the format

1327
00:58:01,040 --> 00:58:03,839
yaml是格式你经常会用到的
that you're usually gonna use for

1328
00:58:03,839 --> 00:58:05,280
配置文件的格式
configuration files

1329
00:58:05,280 --> 00:58:07,440
这个命令将会执行
and this is the command that executes

1330
00:58:07,440 --> 00:58:10,160
配置文件中的内容
whatever is in the configuration file

1331
00:58:10,160 --> 00:58:13,520
我们来调用配置文件
so let's actually call the configuration file

1332
00:58:13,520 --> 00:58:17,920
假设其为nginx-deployment.yaml
i don't know nginx deployment

1333
00:58:17,920 --> 00:58:20,880
我们继续创建一个非常
and let's go ahead and create a very

1334
00:58:20,880 --> 00:58:23,200
简单的基础的配置文件
simplistic super basic

1335
00:58:23,200 --> 00:58:27,599
nginx-deployment
uh nginx deployment file so here i'm

1336
00:58:27,599 --> 00:58:34,880
创建该文件
create that file

1337
00:58:34,880 --> 00:58:37,920
这就是给deployment的基本设置
so this is the basic configuration

1338
00:58:37,920 --> 00:58:41,680
在其中我可以指定
for the deployment so here i'm just specifying

1339
00:58:41,680 --> 00:58:43,119
我想指定的东西，比如我想创造一个deployment
what i want to create i want to create a

1340
00:58:43,119 --> 00:58:46,400
指定deployment的名称
deployment the name of that deployment

1341
00:58:46,400 --> 00:58:49,280
你现在可以忽略这些标签
you can ignore these labels uh right now

1342
00:58:49,280 --> 00:58:50,240
呃
uh

1343
00:58:50,240 --> 00:58:54,079
我想要创建多少个pod的副本
how many replicas of the pods i want to create

1344
00:58:54,079 --> 00:58:56,720
这一部分的template
and this plug right here the template

1345
00:58:56,720 --> 00:58:58,400
和spec
and specification

1346
00:58:58,400 --> 00:59:01,119
就是pod的蓝图
is a blueprint for the pods so

1347
00:59:01,119 --> 00:59:03,520
这里是给deployment指定的内容
specification for the deployment

1348
00:59:03,520 --> 00:59:06,640
这里是给pod指定的内容
and specification for a pod and here

1349
00:59:06,640 --> 00:59:09,040
这里表示我们想要在pod里有一个
we're just saying that we want one container

1350
00:59:09,040 --> 00:59:12,480
基于nginx镜像的容器
inside of the pod with nginx

1351
00:59:12,480 --> 00:59:16,000
我们要把它绑定到端口80
image and we are going to bind that on port 80.

1352
00:59:16,000 --> 00:59:19,040
这就是我们的配置文件
so this is going to be our configuration file

1353
00:59:19,040 --> 00:59:22,079
一旦我们有了它，我们就可以应用它
and once we have that we can apply that

1354
00:59:22,079 --> 00:59:25,359
来进行配置
configuration

1355
00:59:25,359 --> 00:59:29,520
所以
so

1356
00:59:29,520 --> 00:59:33,280
deployment创建好了，现在如果我执行get pod
so deployment created so now if i get

1357
00:59:33,280 --> 00:59:36,799
可以看到nginx的deployment和pod
pod i see that nginx deployment

1358
00:59:36,799 --> 00:59:39,920
已经创建，并且正在运行
pod was created and it's running

1359
00:59:39,920 --> 00:59:43,200
可以看到deployment在52秒前被创建
and let's also see the deployment was created

1360
00:59:43,200 --> 00:59:46,400
现在如果我想
52 seconds ago and now if i wanted to

1361
00:59:46,400 --> 00:59:47,359
在这个deployment中改变一些东西
change something

1362
00:59:47,359 --> 00:59:49,839
我实际上可以改变
in that deployment i can actually change

1363
00:59:49,839 --> 00:59:52,880
我的本地配置文件
my local configuration

1364
00:59:52,880 --> 00:59:55,680
例如，我想要两个副本
for example i wanted two replicas

1365
00:59:55,680 --> 00:59:59,119
而不是一个
instead of one

1366
00:59:59,119 --> 01:00:02,880
我可以应用它
i can apply that

1367
01:00:02,880 --> 01:00:06,960
再一次
again

1368
01:00:06,960 --> 01:00:10,480
nginx部署已配置
deployment nginx deployment configured and

1369
01:00:10,480 --> 01:00:13,359
你可以看到这里的不同之处在于
as you see the difference here is that

1370
01:00:13,359 --> 01:00:15,680
kubernetes可以检测nginx的deployment是否存在
kubernetes can detect if the nginx

1371
01:00:15,680 --> 01:00:17,520
若还不存在，它将会
deployment doesn't exist yet it's going

1372
01:00:17,520 --> 01:00:19,119
创建一个
to create one

1373
01:00:19,119 --> 01:00:24,559
但如果它已经存在，我再apply一次配置文件
but if it already exists and i apply the configuration file again

1374
01:00:24,559 --> 01:00:27,119
它会知道它应该更新
it's going to know that it should update

1375
01:00:27,119 --> 01:00:29,280
而不是创建一个新的
it instead of creating a new one

1376
01:00:29,280 --> 01:00:32,720
所以如果我get deployment
so if i do get deployment

1377
01:00:32,720 --> 01:00:36,640
还是旧的deployment
i see this is the old one or the old deployment

1378
01:00:36,640 --> 01:00:39,440
如果我写kubectl get pod，我就能看到
and if i do kubectl get pod i see

1379
01:00:39,440 --> 01:00:41,280
旧的那个还在那儿
the old one is still there

1380
01:00:41,280 --> 01:00:43,520
一个新的被创建了，因为我
and a new one got created because i

1381
01:00:43,520 --> 01:00:45,200
增加了副本个数
increased the replica count

1382
01:00:45,200 --> 01:00:47,280
也就是说有了kubectl apply，你就可以
which means that with cube ctl apply you

1383
01:00:47,280 --> 01:00:48,319
同时创造
can both create

1384
01:00:48,319 --> 01:00:51,280
并更新组件，显然你
and update a component and obviously you

1385
01:00:51,280 --> 01:00:53,040
还能通过kubctl设置
can do kubectl with

1386
01:00:53,040 --> 01:00:56,480
诸如Service volumes这样的任何其他
services volumes any other

1387
01:00:56,480 --> 01:00:59,760
kubernetes组件，就像我们对deployment做的一样
kubernetes components just like we did it with the deployment

1388
01:00:59,760 --> 01:01:01,119
那么在下个视频中
so in the next video i'm going to break

1389
01:01:01,119 --> 01:01:02,799
我将解构配置文件的语法
down the syntax of the configuration

1390
01:01:02,799 --> 01:01:03,839
将会非常符合逻辑
file which is

1391
01:01:03,839 --> 01:01:07,119
也很易于理解
pretty logical and simple actually to understand

1392
01:01:07,119 --> 01:01:08,319
我会解释所有的
and i'm going to explain all the

1393
01:01:08,319 --> 01:01:10,319
不同的属性和它们的含义
different attributes and what they mean

1394
01:01:10,319 --> 01:01:12,640
这样您就可以为不同组件
so you can write your own configuration

1395
01:01:12,640 --> 01:01:14,480
编写自己的配置文件
files for different components

1396
01:01:14,480 --> 01:01:18,480
总结一下，我们已经学了一些kubectl命令
so to summarize we've looked at a couple of kubectl commands

1397
01:01:18,480 --> 01:01:21,280
在这个视频中，我们看到了如何创建一个组件
in this video we saw how to create a

1398
01:01:21,280 --> 01:01:23,119
比如deployment
component like deployment

1399
01:01:23,119 --> 01:01:26,559
如何编辑和删除它，我们看到了如何获取
how to edit it and delete it we saw how to get

1400
01:01:26,559 --> 01:01:30,720
deployment和ReplicaSet这些组件的状态等等
status of parts deployments replica sets

1401
01:01:30,720 --> 01:01:33,839
我们也能获取控制台的日志输出
etc we also logged on the console whatever

1402
01:01:33,839 --> 01:01:37,599
无论pod中的应用程序是否正在写入控制台
application is writing it to the console in the pod

1403
01:01:37,599 --> 01:01:39,760
我们看到了如何利用kubectl exec获取
and we saw how to get a terminal of a

1404
01:01:39,760 --> 01:01:41,920
运行中的容器的终端
running container using kubectl

1405
01:01:41,920 --> 01:01:45,119
最后我们看到了如何使用
exec and finally we saw how to use

1406
01:01:45,119 --> 01:01:47,680
一个kubernetes配置文件来
a kubernetes configuration file to

1407
01:01:47,680 --> 01:01:48,480
创建和
create and

1408
01:01:48,480 --> 01:01:52,160
更新组件
update components using the cube ctl

1409
01:01:52,160 --> 01:01:53,200
通过使用kubectl apply命令
apply command

1410
01:01:53,200 --> 01:01:55,760
最后但同样重要的是我们学习了
and last but not least we saw kubectl

1411
01:01:55,760 --> 01:01:57,200
kubectl describe命令
describe command

1412
01:01:57,200 --> 01:01:58,720
如果一个pod中的容器还没有启动
which will when a container isn't

1413
01:01:58,720 --> 01:02:00,319
你想要一些额外的关于pod的故障排除信息
starting in a pod and you want to get

1414
01:02:00,319 --> 01:02:04,000
可以使用该命令
some additional troubleshooting information about the pod

1415
01:02:07,760 --> 01:02:09,520
在这个视频中，我将向你们展示
in this video i'm going to show you the

1416
01:02:09,520 --> 01:02:13,359
kubernetes配置文件的语法和内容
syntax and the contents of kubernetes configuration file

1417
01:02:13,359 --> 01:02:15,839
它是在kubernetes集群中创建和配置组件
which is the main tool for creating and

1418
01:02:15,839 --> 01:02:18,720
的主要工具
configuring components in kubernetes cluster

1419
01:02:18,720 --> 01:02:21,039
如果您见过大型配置文件
if you've seen large configuration files

1420
01:02:21,039 --> 01:02:21,839
似乎
it might seem

1421
01:02:21,839 --> 01:02:24,319
令人望而生畏，但实际上
overwhelming but in reality it's pretty

1422
01:02:24,319 --> 01:02:25,039
它很简单
simple and

1423
01:02:25,039 --> 01:02:28,240
很符合直觉，结构逻辑性也很好
intuitive and also very logically structured

1424
01:02:28,240 --> 01:02:33,760
让我们一步一步来
so let's go through it step by step

1425
01:02:33,760 --> 01:02:36,559
这里我有一个例子，分别有
so here i have examples of a deployment

1426
01:02:36,559 --> 01:02:39,039
deployment和service的配置文件
and service configuration files

1427
01:02:39,039 --> 01:02:42,400
首先需要说的是
side by side so the first thing is that

1428
01:02:42,400 --> 01:02:45,920
kubernetes中的每个配置文件都由三部分组成
every configuration file in kubernetes has

1429
01:02:45,920 --> 01:02:48,960
第一部分是
three parts the first part is where the

1430
01:02:48,960 --> 01:02:50,799
您正在创建的组件的
metadata of that

1431
01:02:50,799 --> 01:02:54,240
元数据
component that you're creating resides

1432
01:02:54,240 --> 01:02:58,640
其中一个元数据显然是组件本身的名称
in one of the metadata is obviously name of the component itself

1433
01:02:58,640 --> 01:03:02,240
配置文件的第二部分
the second part in the configuration file is

1434
01:03:02,240 --> 01:03:04,799
是每个组件的特别说明(specification)
specification so each component's

1435
01:03:04,799 --> 01:03:06,160
所以每个配置文件
configuration file

1436
01:03:06,160 --> 01:03:08,160
都会有一个spec块
will have a specification where you

1437
01:03:08,160 --> 01:03:09,200
基本上是
basically put

1438
01:03:09,200 --> 01:03:12,799
所有你想给这个组件apply的
every kind of configuration that you want to apply

1439
01:03:12,799 --> 01:03:16,079
配置
for that component um

1440
01:03:16,079 --> 01:03:18,079
如您所见，这里的前两行
the first two lines here as you see is 

1441
01:03:18,079 --> 01:03:19,839
在声明
just declaring

1442
01:03:19,839 --> 01:03:22,240
想要创造什么组件
what you want to create here we are

1443
01:03:22,240 --> 01:03:23,440
这里创建的是deployment
creating deployment

1444
01:03:23,440 --> 01:03:26,000
这里创建的是service
and here we're creating a service and

1445
01:03:26,000 --> 01:03:27,119
这里是
this is basically

1446
01:03:27,119 --> 01:03:29,119
你需要每个组件
you have to look up for each component

1447
01:03:29,119 --> 01:03:31,359
指定一个不同的api版本
there's a different api version

1448
01:03:31,359 --> 01:03:34,319
现在在spec部分
so now inside of the specification part

1449
01:03:34,319 --> 01:03:35,520
很明显
obviously

1450
01:03:35,520 --> 01:03:38,559
spec块的属性
the attributes will be

1451
01:03:38,559 --> 01:03:42,799
因组件类型而异
specific to the kind of a component that you're creating

1452
01:03:42,799 --> 01:03:46,400
所以deployment将有它自己的属性
so deployment will have its own attributes

1453
01:03:46,400 --> 01:03:48,799
只适用于deployment
that only apply for deployment and the

1454
01:03:48,799 --> 01:03:51,039
Service也有它自己的东西
service will have its own stuff

1455
01:03:51,039 --> 01:03:53,280
但是我之前说过，配置文件
but i said there are three parts of a

1456
01:03:53,280 --> 01:03:54,799
有三个部分
configuration file

1457
01:03:54,799 --> 01:03:58,559
我们现在只看到元数据和spec
and we just see metadata and the specification

1458
01:03:58,559 --> 01:04:01,920
那么第三部分在哪里
so where's the third part so the third part

1459
01:04:01,920 --> 01:04:04,799
第三部分将会是一种状态，但它是
will be a status but it's going to be

1460
01:04:04,799 --> 01:04:06,559
自动生成的
automatically generated and

1461
01:04:06,559 --> 01:04:10,480
由kubernetes添加，所以它的工作方式是
added by kubernetes so the way it works is that

1462
01:04:10,480 --> 01:04:13,200
kubernetes总是比较
kubernetes will always compare what is

1463
01:04:13,200 --> 01:04:14,400
理想的状态
the desired state

1464
01:04:14,400 --> 01:04:18,160
和实际的该组件的状态
and what is the actual state or the status of that component

1465
01:04:18,160 --> 01:04:21,760
如果当前状态和期望的状态不匹配
and if the status and desired state do not match

1466
01:04:21,760 --> 01:04:23,599
kubernetes知道有些东西
then kubernetes knows there is something

1467
01:04:23,599 --> 01:04:24,880
需要被修复
to be fixed there

1468
01:04:24,880 --> 01:04:27,359
所以它会试图修复它
so it's going to try to fix it and this

1469
01:04:27,359 --> 01:04:32,400
这是kubernetes提供的基础的自我修复特性
is the basis of the self-healing feature that kubernetes provides

1470
01:04:32,400 --> 01:04:35,200
例如，这里您指定您想要
for example here you specify you want

1471
01:04:35,200 --> 01:04:36,400
nginx-deployment有两个副本
two replicas

1472
01:04:36,400 --> 01:04:40,559
所以当你apply
of nginx deployment so when you apply this

1473
01:04:40,559 --> 01:04:42,400
即当您使用此配置文件
when you actually create the deployment

1474
01:04:42,400 --> 01:04:43,920
实际创建deployment时
using this configuration file

1475
01:04:43,920 --> 01:04:47,039
kubernetes将会在这里添加
that's what apply means kubernetes will add here

1476
01:04:47,039 --> 01:04:50,400
你的deployment的状态
the status of your deployment and it will

1477
01:04:50,400 --> 01:04:53,359
并持续更新状态
update that state continuously so for

1478
01:04:53,359 --> 01:04:54,000
举例来说
example if

1479
01:04:54,000 --> 01:04:57,039
在某个时间的状态说，只有一个副本
a status at some point will say just one

1480
01:04:57,039 --> 01:04:58,319
正在运行
replica is running

1481
01:04:58,319 --> 01:05:02,960
然后kubernetes会比较这个状态与spec之间的差别
then kubernetes will compare that status with the specification

1482
01:05:02,960 --> 01:05:05,359
我们就知道这里有问题了
and we'll know there is a problem there

1483
01:05:05,359 --> 01:05:07,280
需要创建另一个副本
another replica needs to be created

1484
01:05:07,280 --> 01:05:11,119
另一个有趣的问题是
sap now another interesting question here is

1485
01:05:11,119 --> 01:05:13,200
kubernetes从哪里得到
where does kubernetes actually get the

1486
01:05:13,200 --> 01:05:14,240
状态数据
status data

1487
01:05:14,240 --> 01:05:18,079
从而自动添加并不断更新
to automatically add here or update continuously

1488
01:05:18,079 --> 01:05:20,880
这个信息来自于etcd
that information comes from the etcd

1489
01:05:20,880 --> 01:05:22,000
记得是我们说过的集群大脑
remember the cluster

1490
01:05:22,000 --> 01:05:24,559
master进程之一
brain one of the master processes that

1491
01:05:24,559 --> 01:05:25,920
它实际上来
actually stores

1492
01:05:25,920 --> 01:05:29,200
存储集群数据
the cluster data so etcd holds

1493
01:05:29,200 --> 01:05:32,480
所以etcd随时保留
at any time the current status of

1494
01:05:32,480 --> 01:05:35,119
任何组件的当前状态
any kubernetes component and that's

1495
01:05:35,119 --> 01:05:40,880
而它就是状态信息的来源
where the status information comes from

1496
01:05:40,880 --> 01:05:42,799
正如你看到
so as you see the format of the

1497
01:05:42,799 --> 01:05:44,480
配置文件是yaml
configuration files is

1498
01:05:44,480 --> 01:05:48,559
也是文件扩展名
yaml that's why the extension here and

1499
01:05:48,559 --> 01:05:50,240
一般来说它是很直观
generally it's pretty straightforward to

1500
01:05:50,240 --> 01:05:52,559
非常简单的格式
understand it's a very simple format

1501
01:05:52,559 --> 01:05:56,400
但是yaml对缩排非常严格
but yaml is very strict about the indentations

1502
01:05:56,400 --> 01:05:59,119
举个例子，如果你有
so for example if you have something

1503
01:05:59,119 --> 01:06:00,640
错误地缩排
wrongly indented here

1504
01:06:00,640 --> 01:06:03,760
你的文件将无效
your file will be invalid um so what i

1505
01:06:03,760 --> 01:06:05,920
尤其是如果我有一个
do especially if i have a configuration

1506
01:06:05,920 --> 01:06:07,920
有200行的配置文件
file that has 200 lines

1507
01:06:07,920 --> 01:06:11,200
很长很难办
it's pretty long um i usually use

1508
01:06:11,200 --> 01:06:14,240
我通常会找yaml在线验证网站
some yaml online validator to see where

1509
01:06:14,240 --> 01:06:16,319
来看看语法有没有什么问题
i need to fix that

1510
01:06:16,319 --> 01:06:18,640
但除对缩排严格之外，它就很简单了
but other than that it's pretty simple

1511
01:06:18,640 --> 01:06:20,400
另一点需要说的是
um another thing is

1512
01:06:20,400 --> 01:06:24,240
你应该把这些配置文件放在哪里
where do you actually store those configuration files

1513
01:06:24,240 --> 01:06:27,680
通常的做法是将它们和你的代码一起储存
a usual practice is to store them with your code

1514
01:06:27,680 --> 01:06:31,200
因为deployment和service
because since the deployment and service is

1515
01:06:31,200 --> 01:06:33,680
将会被apply到你的应用中
going to be applied to your application

1516
01:06:33,680 --> 01:06:35,520
在你的应用程序代码中
it's a good practice to store these

1517
01:06:35,520 --> 01:06:36,880
储存这些配置文件
configuration files

1518
01:06:36,880 --> 01:06:39,200
是一个很好的习惯
in your application code so usually it

1519
01:06:39,200 --> 01:06:40,319
所以通常它会
will be part of

1520
01:06:40,319 --> 01:06:43,760
作为整套基础代码的一部分
the whole infrastructure as a code concept

1521
01:06:43,760 --> 01:06:46,079
或者您也可以拥有自己的git仓库
or you can also have its own git

1522
01:06:46,079 --> 01:06:50,880
专门用于保存配置文件
repository just for the configuration files

1523
01:06:50,880 --> 01:06:52,880
在之前的视频中我给你们看过
so in the previous video i showed you

1524
01:06:52,880 --> 01:06:57,520
deployment管理在其之下的部分
that deployments manage the parts that are below them so

1525
01:06:57,520 --> 01:06:58,720
每当你
whenever you

1526
01:06:58,720 --> 01:07:00,559
编辑一些deployment内的内容
edit something in a deployment it kind

1527
01:07:00,559 --> 01:07:01,760
会级联到
of cascades down

1528
01:07:01,760 --> 01:07:04,319
它管理的所有pod
down to all the pods that it manages and

1529
01:07:04,319 --> 01:07:05,920
每当你
whenever you

1530
01:07:05,920 --> 01:07:08,480
想要创造一些pod
want to create some pods you would

1531
01:07:08,480 --> 01:07:10,079
你实际上会创建一个deployment
actually create a deployment

1532
01:07:10,079 --> 01:07:12,319
剩下的就交给它了
and it will take care of the rest so how

1533
01:07:12,319 --> 01:07:14,480
这一切是怎么做到的
does this happen or where is this

1534
01:07:14,480 --> 01:07:17,440
你又要在配置文件的哪里定义所有东西呢
whole thing defined in the configuration

1535
01:07:17,440 --> 01:07:18,480
所以在这里
so here in the

1536
01:07:18,480 --> 01:07:20,720
deployment中的spec部分
specification part of a deployment you

1537
01:07:20,720 --> 01:07:22,640
你会看到一个template字块
see a template

1538
01:07:22,640 --> 01:07:26,240
如果我展开它，你会看到template
and if i expand it you see the template

1539
01:07:26,240 --> 01:07:29,839
也有自己的元数据和spec
also has its own metadata and specification

1540
01:07:29,839 --> 01:07:34,960
它基本上是一个配置文件中的配置文件
so it's basically a config file inside of a config file

1541
01:07:34,960 --> 01:07:39,920
之所以这么做是因为
and the reason for it is that this configuration

1542
01:07:39,920 --> 01:07:44,559
这个配置文件也会被应用于pod，所以pod应该有它自己的配置
applies to a pod so pod should have its own configuration

1543
01:07:44,559 --> 01:07:47,839
在deployment的配置文件中
inside of deployments configuration file

1544
01:07:47,839 --> 01:07:51,440
所有的deployment都是要这样被定义的
and that's how all the deployments will be defined and this

1545
01:07:51,440 --> 01:07:54,079
这是一个pod的蓝图，里面有
is going to be the blueprint for a pod

1546
01:07:54,079 --> 01:07:56,160
比如它应该基于哪个镜像
like which image it should be based

1547
01:07:56,160 --> 01:07:59,119
它应该打开哪个端口
on which port it should open what is

1548
01:07:59,119 --> 01:08:05,520
它的容器名称是什么等等
going to be the name of the container etc

1549
01:08:05,520 --> 01:08:08,960
建立联系的方式是通过使用
so the way the connection is established is using

1550
01:08:08,960 --> 01:08:12,319
标签(label)和选择器(selector)
labels and selectors so

1551
01:08:12,319 --> 01:08:16,400
如您所见，元数据部分包含labels
as you see metadata part contains the labels

1552
01:08:16,400 --> 01:08:20,000
spec部分包含selectors
and the specification part contains selectors

1553
01:08:20,000 --> 01:08:23,520
非常简单
it's pretty simple in a metadata you

1554
01:08:23,520 --> 01:08:27,440
你要给deploy这样的组件或者pod
give components like deployment

1555
01:08:27,440 --> 01:08:30,480
提供键值对，它可以是
or pod a key value pair and it could be

1556
01:08:30,480 --> 01:08:32,159
任何键值对
any key value pair that

1557
01:08:32,159 --> 01:08:36,000
在这个例子中，我们有app:nginx
you think of in this case we have app nginx

1558
01:08:36,000 --> 01:08:40,400
这个标签就粘在组件上面
and that label just sticks to that component

1559
01:08:40,400 --> 01:08:43,839
所以我们使用这个有app:nginx标签的蓝图
so we give parts created

1560
01:08:43,839 --> 01:08:47,600
创造了组件
using this blueprint labeled app nginx

1561
01:08:47,600 --> 01:08:52,480
然后我们告诉deployment连接或者匹配
and we tell the deployment to connect or to match

1562
01:08:52,480 --> 01:08:55,920
所有有标签app:nginx的组件
all the labels with app

1563
01:08:55,920 --> 01:08:59,440
以建立连接
nginx to create that connection

1564
01:08:59,440 --> 01:09:01,600
这样deployment就知道是哪一部分
so this way deployment will know which

1565
01:09:01,600 --> 01:09:03,279
属于它
parts belong to it

1566
01:09:03,279 --> 01:09:07,199
现在deployment有了自己的标签app:nginx
now deployment has its own label app nginx

1567
01:09:07,199 --> 01:09:11,359
这两个标签被service的selector所使用
and these two labels are used by the service

1568
01:09:11,359 --> 01:09:14,640
在service的spec部分
selector so in the specification of a service

1569
01:09:14,640 --> 01:09:16,719
我们定义了一个selector
we define a selector which basically

1570
01:09:16,719 --> 01:09:22,080
以建立Service与
makes a connection between the service and

1571
01:09:22,080 --> 01:09:25,120
deployment或其中的一部分的连接
the deployment or its parts because

1572
01:09:25,120 --> 01:09:26,480
service必须知道
service must know

1573
01:09:26,480 --> 01:09:30,000
哪些pod是被注册以供其使用的
which pods are kind of registered with it

1574
01:09:30,000 --> 01:09:32,640
哪些pod属于这个service
so which pods belong to that service and

1575
01:09:32,640 --> 01:09:33,759
该连接
that connection

1576
01:09:33,759 --> 01:09:36,799
是通过selector和label完成的
is made through the selector

1577
01:09:36,799 --> 01:09:40,400
后面的demo我们会看到这一点
of the label and we're going to see that in a

1578
01:09:40,400 --> 01:09:42,319
这是另一个
demo so another thing that must be

1579
01:09:42,319 --> 01:09:44,319
service和pod必须配置的是
configured in the service and

1580
01:09:44,319 --> 01:09:48,480
端口
pod is the ports so

1581
01:09:48,480 --> 01:09:52,319
如果我展开这个，我就会看到
if i expand this i see that service has

1582
01:09:52,319 --> 01:09:56,400
service有其端口配置
its ports configuration and

1583
01:09:56,400 --> 01:09:58,640
pod里的容器
the container inside of a pod is

1584
01:09:58,640 --> 01:10:00,080
很明显,运行
obviously running

1585
01:10:00,080 --> 01:10:04,480
或者需要正确地运行它的端口
or needs to run its port right so how this is configured

1586
01:10:04,480 --> 01:10:07,679
service有一个port
is basically service has a port

1587
01:10:07,679 --> 01:10:10,800
也就是service自身
where the service itself is

1588
01:10:10,800 --> 01:10:13,600
可以在哪个端口被访问，如果其它服务
um accessible at so if other service

1589
01:10:13,600 --> 01:10:14,960
发送请求到
sends a request to

1590
01:10:14,960 --> 01:10:18,800
nginx-service，需要发送到端口80
nginx service here it needs to send it on port 80

1591
01:10:18,800 --> 01:10:22,560
但是service需要知道转发请求到哪个pod
but the service needs to know to which pod it should

1592
01:10:22,560 --> 01:10:26,000
也需知道哪个pod的端口正在监听
forward the request but also at which port

1593
01:10:26,000 --> 01:10:30,080
这就是targetPort的意义
is that port listening and that is the target port

1594
01:10:30,080 --> 01:10:33,760
所以这个应该和容器端口匹配
so this one should match the container port

1595
01:10:33,760 --> 01:10:36,960
这样我们就完成了deployment和service的
and with that we have our deployment and service

1596
01:10:36,960 --> 01:10:40,239
基本配置
basic configurations done and

1597
01:10:40,239 --> 01:10:42,880
这里要注意
to note here most of these attributes

1598
01:10:42,880 --> 01:10:44,080
你在这里看到的这两部分
that you see here in both

1599
01:10:44,080 --> 01:10:46,880
属性中的大多数实际上
parts are required so this will actually

1600
01:10:46,880 --> 01:10:48,320
是最低的
be the minimum

1601
01:10:48,320 --> 01:10:50,960
用于deployment和service的配置
configuration for deployment and service

1602
01:10:50,960 --> 01:10:53,840
一旦我们拿到那些文件
so once we have those files

1603
01:10:53,840 --> 01:10:57,520
让我们apply它们或用它们创建组件
let's actually apply them or create components

1604
01:10:57,520 --> 01:11:01,600
让我们移步控制台
using that so let's head over to the console

1605
01:11:01,600 --> 01:11:05,440
这里我要创建deployment和service
and here i'm going to create both

1606
01:11:05,440 --> 01:11:14,880
所以kubectl apply nginx-deployment
deployment and service so kubectl apply nginx-deployment

1607
01:11:14,880 --> 01:11:19,040
创建好了，然后是nginx-service
created and nginx service

1608
01:11:19,040 --> 01:11:22,800
现在如果我get pod
so now if i get the pods i see

1609
01:11:22,800 --> 01:11:25,040
看到两个副本正在运行，因为
two replicas are running because that's

1610
01:11:25,040 --> 01:11:26,719
那就是我们定义的
how we define it here

1611
01:11:26,719 --> 01:11:30,880
我们也有我们的service
and we have our service as well

1612
01:11:30,880 --> 01:11:33,520
也就是nginx-service
which is nginx service this is a

1613
01:11:33,520 --> 01:11:36,000
这是默认service，它总是在那里
default service it's always there

1614
01:11:36,000 --> 01:11:38,640
这是我们创建的
this is the one we created and it's

1615
01:11:38,640 --> 01:11:40,000
它在监听端口80
listening on port

1616
01:11:40,000 --> 01:11:43,199
正如我们指定的
80 as we specified now

1617
01:11:43,199 --> 01:11:46,800
现在我们如何验证该service
how can we validate that the service um

1618
01:11:46,800 --> 01:11:51,280
可以转发请求到正确的port呢
has the right ports that it forwards the

1619
01:11:51,280 --> 01:11:55,679
我们可以用kubectl describe service
requests to we can do it using kubectl describe

1620
01:11:55,679 --> 01:12:01,280
接着是service的名称
service and the service name

1621
01:12:01,280 --> 01:12:05,440
这里你可以看到端点
and here you see the endpoints

1622
01:12:05,440 --> 01:12:09,920
你在这里可以找到所有状态信息
where you have all this status information here

1623
01:12:09,920 --> 01:12:11,440
就像我们在配置中定义的那些
like the things that we define in the

1624
01:12:11,440 --> 01:12:12,960
比如selector是app:nginx等等
configuration like app

1625
01:12:12,960 --> 01:12:16,880
我们有定义的targetPort
selector etc we have the target port

1626
01:12:16,880 --> 01:12:18,400
我们也有端点
that we define and we have the end

1627
01:12:18,400 --> 01:12:24,320
这个必须是请求被转发到的
points here and this must be the ip addresses

1628
01:12:24,320 --> 01:12:27,760
pod的ip地址
and ports of the pods

1629
01:12:27,760 --> 01:12:31,120
和端口
that the service must forward

1630
01:12:31,120 --> 01:12:33,520
所以我们怎么知道
the requests to so how do we know that

1631
01:12:33,520 --> 01:12:36,480
这些ip地址是正确的呢
these are the ip addresses of the right parts

1632
01:12:36,480 --> 01:12:39,360
因为kubectl get pod是不可能
because with kubectl get pod you don't

1633
01:12:39,360 --> 01:12:40,960
得到这个信息的
get this information

1634
01:12:40,960 --> 01:12:43,199
所以我们的方法
so the way we do it or where we find

1635
01:12:43,199 --> 01:12:44,880
就是使用
that out is using

1636
01:12:44,880 --> 01:12:48,320
get pod，然后-o用于输出
get pod and then you do dash o which is for

1637
01:12:48,320 --> 01:12:52,239
然后我们需要更多的信息
output and then we want more information

1638
01:12:52,239 --> 01:12:56,800
所以 -o wide，我们看到了
so o wide and here we see

1639
01:12:56,800 --> 01:12:59,040
这里有更多列，我们有名字
more columns here so we have the name

1640
01:12:59,040 --> 01:13:00,480
和状态等等
and status ready

1641
01:13:00,480 --> 01:13:04,640
我们也有ip地址
etc but we also have the ip address so here

1642
01:13:04,640 --> 01:13:07,760
这就是指定的端点ip地址
is the ip address endpoint specified here

1643
01:13:07,760 --> 01:13:10,960
这是另一个，我们知道
and this is the other one so we know

1644
01:13:10,960 --> 01:13:13,600
service有正确的端点
that the service has right endpoints so

1645
01:13:13,600 --> 01:13:15,199
现在我们来看看
now let's see

1646
01:13:15,199 --> 01:13:17,040
配置文件的第三部分
the third part of the configuration file

1647
01:13:17,040 --> 01:13:21,199
即kubernetes自动生成的状态
which is a status that kubernetes automatically generated

1648
01:13:21,199 --> 01:13:22,480
我们可以
and the way to do it

1649
01:13:22,480 --> 01:13:27,920
用get nginx-deployment
is we can get the deployment

1650
01:13:27,920 --> 01:13:32,000
以yaml格式
nginx deployment in a yaml format

1651
01:13:32,000 --> 01:13:34,159
所以当我执行这个命令的时候
so when i execute this command i will

1652
01:13:34,159 --> 01:13:36,239
会获取结果或
get the resulting or the updated

1653
01:13:36,239 --> 01:13:38,560
我的deployment的配置的更新
configuration of my deployment which

1654
01:13:38,560 --> 01:13:40,320
即驻留在etcd中的内容
actually resides in the

1655
01:13:40,320 --> 01:13:44,239
因为etcd存储
etcd because etcd stores the status of

1656
01:13:44,239 --> 01:13:47,760
整个集群包括每一个组件的状态，所以
the whole cluster including every component so

1657
01:13:47,760 --> 01:13:50,800
如果我这样做，我将在我的控制台得到yaml输出
um if i do this i'll get the yaml output

1658
01:13:50,800 --> 01:13:53,360
但我想要它在文件中
in my console but i want it in the file

1659
01:13:53,360 --> 01:13:56,719
所以我要把它存到
so i'm gonna save it into um

1660
01:13:56,719 --> 01:14:06,960
nginx deployment result

1661
01:14:06,960 --> 01:14:09,679
我要把它保存在那里
and i'm going to save it there and i'm

1662
01:14:09,679 --> 01:14:12,640
在我的编辑器紧邻原始文件，打开它
going to open it in my editor next to the original one

1663
01:14:12,640 --> 01:14:16,080
正如你看到的，很多东西都被添加了
so as you see a lot of stuff has been added

1664
01:14:16,080 --> 01:14:19,840
让我们看看状态部分
but let's just see the status part so all this

1665
01:14:19,840 --> 01:14:23,280
所有这些都是被不断通过kubernetes
is automatically added and updated

1666
01:14:23,280 --> 01:14:24,960
自动添加和更新的
constantly by kubernetes

1667
01:14:24,960 --> 01:14:27,840
它表示有多少个副本正在运行
so it says how many replicas are running

1668
01:14:27,840 --> 01:14:30,080
这些副本的状态如何
what the state of those replicas

1669
01:14:30,080 --> 01:14:33,120
还有一些其他的信息，这部分
and some other information so this part

1670
01:14:33,120 --> 01:14:35,600
在调试时也会有帮助
can also be helpful when debugging

1671
01:14:35,600 --> 01:14:40,080
这就是状态信息，但如果你注意到
so there's a status but also if you noticed

1672
01:14:40,080 --> 01:14:42,560
元数据和规范部分中
other stuff has been added in the

1673
01:14:42,560 --> 01:14:45,280
还被添加了其他的东西
metadata and specification part as well

1674
01:14:45,280 --> 01:14:48,640
例如，创建时间戳
so for example uh creation timestamp

1675
01:14:48,640 --> 01:14:51,440
即组件是什么时候创建的
when was the component created is

1676
01:14:51,440 --> 01:14:53,280
是kubernetes自动添加的
automatically added by kubernetes

1677
01:14:53,280 --> 01:14:55,040
元数据
because it is a metadata

1678
01:14:55,040 --> 01:14:57,280
还有一些独特的id等，你不需要
some unique id etc you don't have to

1679
01:14:57,280 --> 01:14:58,400
关心它
care about it

1680
01:14:58,400 --> 01:15:00,560
在spec部分，它只是
and in the specification part it just

1681
01:15:00,560 --> 01:15:03,040
增加了一些默认值
adds some defaults

1682
01:15:03,040 --> 01:15:06,640
但是你不需要
for that component but again you don't have to

1683
01:15:06,640 --> 01:15:08,159
关心或理解其中的大部分
care or understand most of these

1684
01:15:08,159 --> 01:15:10,400
这里有一点需要注意
attributes but one thing to note here

1685
01:15:10,400 --> 01:15:14,480
比如你想要复制
is that if you for example want to copy

1686
01:15:14,480 --> 01:15:17,600
您已经有的deployment
a deployment that you already have using

1687
01:15:17,600 --> 01:15:21,440
嗯，也许自动脚本会
um maybe automated scripts you will have to

1688
01:15:21,440 --> 01:15:24,480
把生成的东西中的大部分
remove and get rid of most of this

1689
01:15:24,480 --> 01:15:25,679
都去掉
generated stuff

1690
01:15:25,679 --> 01:15:28,480
所以你必须首先清理这一deployment的
so you have to clean that deployment

1691
01:15:28,480 --> 01:15:30,960
配置文件
configuration file first

1692
01:15:30,960 --> 01:15:32,880
然后你可以用这样的蓝图配置
and then you can create another

1693
01:15:32,880 --> 01:15:34,320
创建另一个deployment
deployment from that

1694
01:15:34,320 --> 01:15:38,080
这就是本视频的内容
blueprint configuration so that's it with this video

1695
01:15:38,080 --> 01:15:40,480
所以从现在开始我们要
so from now on we're gonna be working

1696
01:15:40,480 --> 01:15:42,320
用配置文件工作了
with the configuration files so for

1697
01:15:42,320 --> 01:15:43,920
比如如果我想删除
example if i want to delete the

1698
01:15:43,920 --> 01:15:45,440
deployment和service
deployment and the service

1699
01:15:45,440 --> 01:15:49,600
我可以用那个配置文件
i can do it using that file um configuration file as well

1700
01:15:49,600 --> 01:15:59,199
使用delete
using delete and

1701
01:15:59,199 --> 01:16:02,239
这样的话，我们的deployment就没了
like this the deployment will be gone

1702
01:16:02,239 --> 01:16:07,840
我也可以对service做同样的事
and i can do the same for service

1703
01:16:07,840 --> 01:16:11,679
好的，使用kubectl apply和kubectl delete
all right so using kubectl apply and kubectl delete

1704
01:16:11,679 --> 01:16:17,000
你就基本上可以与配置文件配合工作了
you can basically work with the configuration files

1705
01:16:19,440 --> 01:16:22,719
在这个视频中，我们将部署两个应用程序
in this video we're gonna deploy two applications

1706
01:16:22,719 --> 01:16:26,159
我选择了mongodb和MongoExpress这两个
mongodb and express and i chose these two

1707
01:16:26,159 --> 01:16:29,360
因为它很好地验证了典型的
because it demonstrates really well a typical

1708
01:16:29,360 --> 01:16:32,480
web应用程序及其数据库的简单设置
simple setup of a web application and its database

1709
01:16:32,480 --> 01:16:36,239
所以你可以把这个应用类比到你的任何类似的项目上
so you can apply this to any similar setup you have

1710
01:16:36,239 --> 01:16:40,320
我们来看看怎么做
so let's see how we're going to do this

1711
01:16:40,320 --> 01:16:43,440
首先我们将创建一个mongodb pod
so first we will create a mongodb pod

1712
01:16:43,440 --> 01:16:45,280
为了能和那个pod通信
and in order to talk to that pod we are

1713
01:16:45,280 --> 01:16:46,480
我们需要一个service
going to need a service

1714
01:16:46,480 --> 01:16:48,159
我们要创建一个内部service
and we're going to create an internal

1715
01:16:48,159 --> 01:16:50,400
也就是说
service which basically means that no

1716
01:16:50,400 --> 01:16:53,280
外部请求不允许被发送到pod
external requests are allowed to the pod

1717
01:16:53,280 --> 01:16:55,440
只有同一集群内的组件
only components inside the same cluster

1718
01:16:55,440 --> 01:16:56,400
可以和它通信
can talk to it

1719
01:16:56,400 --> 01:16:58,080
这就是我们想要的
and that's what we want then we're going

1720
01:16:58,080 --> 01:16:59,840
然后我们创建一个Mongo Express的deployment 
to create a express

1721
01:16:59,840 --> 01:17:02,159
我们需要
deployment one we're going to need a

1722
01:17:02,159 --> 01:17:04,400
mongodb数据库的url
database url of mongodb

1723
01:17:04,400 --> 01:17:06,800
这样Mongo Express就能连接上Mongodb
so that express can connect to it

1724
01:17:06,800 --> 01:17:08,320
第二个是凭证信息
and the second one is

1725
01:17:08,320 --> 01:17:10,400
如数据库的用户名和密码之类的
credentials so username and password of

1726
01:17:10,400 --> 01:17:13,040
以便它能够进行身份验证
the database so that it can authenticate

1727
01:17:13,040 --> 01:17:15,360
我们传递信息到Mongo Express所在deployment的方式是
so the way we can pass this information

1728
01:17:15,360 --> 01:17:18,640
通过环境变量调整
to express deployment is through its deployment

1729
01:17:18,640 --> 01:17:21,360
以及deployment的配置文件
configuration file through environmental

1730
01:17:21,360 --> 01:17:24,560
因为这就是应用程序配置的方式
variables because that's how the application is configured

1731
01:17:24,560 --> 01:17:26,719
我们会创建一个ConfigMap
so we're going to create a config map

1732
01:17:26,719 --> 01:17:28,800
其包含数据库url
that contains database url

1733
01:17:28,800 --> 01:17:31,040
我们要创造一个Secret
and we're going to create a secret that

1734
01:17:31,040 --> 01:17:32,800
包含的凭证信息
contains the credentials

1735
01:17:32,800 --> 01:17:36,400
在deployment的配置文件中我们会引用两者
and we're going to reference both inside of that deployment file

1736
01:17:36,400 --> 01:17:38,320
一旦我们建立好了，我们就
so once we have that set up we're going

1737
01:17:38,320 --> 01:17:41,040
需要express来被
to need express to be accessible

1738
01:17:41,040 --> 01:17:43,040
浏览器访问，为此
through browser in order to do that

1739
01:17:43,040 --> 01:17:45,600
我们要创建一个外部service
we're going to create an external service

1740
01:17:45,600 --> 01:17:48,719
这将允许外部请求
that will allow external requests to

1741
01:17:48,719 --> 01:17:51,760
与pod对话
talk to the pod so the url will be

1742
01:17:51,760 --> 01:17:55,280
url将是http + 节点的ip地址
http ip address of the node and

1743
01:17:55,280 --> 01:17:58,719
以及service的端口，因此有了这个设置
the service port so with this setup the request

1744
01:17:58,719 --> 01:18:00,800
请求的流程现在看起来是这样的
flow will now look like this so the

1745
01:18:00,800 --> 01:18:02,640
请求来自浏览器
request comes from the browser

1746
01:18:02,640 --> 01:18:06,000
给到express的外部service
and it goes to the external service of the express

1747
01:18:06,000 --> 01:18:09,360
然后将它转发给Express的pod
which will then forward it to the express pod

1748
01:18:09,360 --> 01:18:13,520
pod随后将连接到mongodb的内部service
the pod will then connect to internal service of mongodb

1749
01:18:13,520 --> 01:18:16,640
那是这里的数据库url
that's basically the database url here

1750
01:18:16,640 --> 01:18:20,560
然后它会转发给mongodb pod
and it will forward it then to mongodb pod where

1751
01:18:20,560 --> 01:18:24,800
在那里它将使用凭证信息验证请求
it will authenticate the request using the credentials

1752
01:18:24,800 --> 01:18:26,400
现在我们来创建这个整个设置
so now let's go and create this whole

1753
01:18:26,400 --> 01:18:30,000
使用kubernetes配置文件
setup using kubernetes configuration files

1754
01:18:30,000 --> 01:18:33,120
让我们进入主题
let's dive right into it and create the whole setup

1755
01:18:33,120 --> 01:18:36,400
首先，我有一个运行中的minikube集群
so first of all i have a mini cube cluster running if i do

1756
01:18:36,400 --> 01:18:39,760
如果我执行kubectl get all命令
cube ctl get all which basically gets me

1757
01:18:39,760 --> 01:18:43,040
会让我了解到集群中的所有组件
all the components that are inside the cluster

1758
01:18:43,040 --> 01:18:45,199
我只有一个默认的kubernetes service
i only have a default kubernetes service

1759
01:18:45,199 --> 01:18:47,280
所以集群是空的
so my cluster is empty

1760
01:18:47,280 --> 01:18:49,520
我要从头开始
and i'm starting from scratch so the

1761
01:18:49,520 --> 01:18:53,040
我们要做的第一件事是
first thing that i said we're gonna do is create a

1762
01:18:53,040 --> 01:18:55,679
创建mongodb的deployment
mongodb deployment

1763
01:18:55,679 --> 01:18:58,880
我通常用编辑器，所以
i usually create it in an editor so i'm

1764
01:18:58,880 --> 01:19:00,880
打开visual studio code
going to go to visual studio code

1765
01:19:00,880 --> 01:19:06,320
粘贴准备好的mongodb deployment文件
and paste a prepared deployment file there

1766
01:19:06,320 --> 01:19:09,520
看起来就是这样
for mongodb and this is how it's going to look like

1767
01:19:09,520 --> 01:19:13,679
那么类型是Deployment，还有一些元数据
so i have a deployment kind and i have some metadata

1768
01:19:13,679 --> 01:19:17,679
我就叫它mongodb-deployment吧
i'm just going to call it mongodb deployment

1769
01:19:17,679 --> 01:19:20,080
还有标签和选择器
labels and selectors in the previous

1770
01:19:20,080 --> 01:19:22,080
在前面的视频中我已经解释过了
video i already explained the syntax

1771
01:19:22,080 --> 01:19:26,239
k8s的yaml配置文件的语法了
of kubernetes yaml configuration file

1772
01:19:26,239 --> 01:19:28,960
如果你想知道所有这些属性是什么意思
so if you want to know what all these

1773
01:19:28,960 --> 01:19:31,360
你可以看看那个视频
attributes mean then you can check out that video

1774
01:19:31,360 --> 01:19:35,280
在template中有一些定义或者说蓝图
and here in the template i have a definition or blueprint

1775
01:19:35,280 --> 01:19:38,560
deployment基于此创建pod
for parts that this deployment gonna create

1776
01:19:38,560 --> 01:19:42,000
我要有一个副本
and i'm just gonna go with one replica

1777
01:19:42,000 --> 01:19:45,199
容器会被叫做mongodb
so the container is gonna be called mongodb

1778
01:19:45,199 --> 01:19:47,040
这就是我要用到的镜像
and this is the image that i'm gonna

1779
01:19:47,040 --> 01:19:48,800
让我们
take so let's actually go

1780
01:19:48,800 --> 01:19:57,520
去查看 mongodb镜像的配置
and check out the image configuration for mongodb so

1781
01:19:57,520 --> 01:20:01,280
这个镜像
and i see this image here

1782
01:20:01,280 --> 01:20:04,960
打开这个，我在找的是
let's open this and basically what i'm looking for

1783
01:20:04,960 --> 01:20:08,960
如何使用容器
is how to use that um container

1784
01:20:08,960 --> 01:20:12,400
也就是说它会开放哪些端口
meaning what ports it's going to open and what's

1785
01:20:12,400 --> 01:20:15,840
对它进行外部配置需要使用什么
external configuration it's going to take so

1786
01:20:15,840 --> 01:20:20,840
mongodb容器默认端口为27017
a default port of mongodb container is

1787
01:20:20,840 --> 01:20:24,960
我要用它
27017 so i'm going to use that

1788
01:20:24,960 --> 01:20:30,800
我们会用到环境变量
and we are going to use environmental variables the root

1789
01:20:30,800 --> 01:20:32,400
有root用户名和root密码
username and root password

1790
01:20:32,400 --> 01:20:35,600
所以我可以在容器启动时
so basically i can on the container startup

1791
01:20:35,600 --> 01:20:38,560
定义admin用户名和密码
define the admin username and password

1792
01:20:38,560 --> 01:20:41,360
让我们继续，来配置所有的
so let's go ahead and configure all of that

1793
01:20:41,360 --> 01:20:44,880
在配置文件中的内容
inside the configuration file so here

1794
01:20:44,880 --> 01:20:48,400
在这里image属性
below the image of mongodb so we're just gonna leave

1795
01:20:48,400 --> 01:20:51,600
只要留镜像名字就好，它会拉取最新的镜像
the name of the image and it's gonna pull the latest one

1796
01:20:51,600 --> 01:20:55,040
这也是我们想要的，我还要指定
and that's what we want so here i'm gonna specify

1797
01:20:55,040 --> 01:20:58,159
我要暴露什么端口
what port i want to expose so ports

1798
01:20:58,159 --> 01:21:07,040
所以加上ports属性，下面要有containerPort属性
that's the attribute name and container port

1799
01:21:07,040 --> 01:21:10,560
使用标准端口27017
and that's the standard port so i'm gonna leave it and

1800
01:21:10,560 --> 01:21:14,080
在这下面我会指定
below that i'm gonna specify those

1801
01:21:14,080 --> 01:21:18,000
两个环境变量，一个叫
two environmental variables so one is

1802
01:21:18,000 --> 01:21:21,280
让我们看看它叫什么
called let's see what it's called it's

1803
01:21:21,280 --> 01:21:24,639
它叫MONGO_INITDB_ROOT_USERNAME
mongodb root username and here

1804
01:21:24,639 --> 01:21:26,320
它对应的值
it's gonna be value so we're gonna

1805
01:21:26,320 --> 01:21:28,320
先留空
actually leave it blank for now

1806
01:21:28,320 --> 01:21:34,320
另一个叫做MONGO_INITDB_ROOT_PASSWORD
and the other one is called init root password and we're

1807
01:21:34,320 --> 01:21:38,719
它的值也留空
gonna leave that blank as well just value and

1808
01:21:38,719 --> 01:21:42,239
一旦我们有了这些值
once we have the values here um going to have

1809
01:21:42,239 --> 01:21:44,880
我们就有了一个mongodb的完整的deployment
a complete deployment for mongodb this

1810
01:21:44,880 --> 01:21:46,320
基本上就是我们所需要的
is basically all we need

1811
01:21:46,320 --> 01:21:49,040
现在注意，这是一个
now note that this is a configuration

1812
01:21:49,040 --> 01:21:51,760
将签入到存储库的配置文件
file that is going to be checked into a repository

1813
01:21:51,760 --> 01:21:55,840
通常你不会在该配置文件中写admin用户名和密码
so usually you wouldn't write admin username and password

1814
01:21:55,840 --> 01:21:59,760
而我们会
inside the configuration file so what we're going to do now

1815
01:21:59,760 --> 01:22:03,120
在要引用值的地方
is we're going to create a secret from where

1816
01:22:03,120 --> 01:22:06,560
创建一个secret
we will reference the values so

1817
01:22:06,560 --> 01:22:08,800
也就是说这个secret会在k8s中存活
meaning that the secret is going to live

1818
01:22:08,800 --> 01:22:12,239
而git仓库中没人可以访问它
in kubernetes and nobody will have access to it in a git

1819
01:22:12,239 --> 01:22:16,239
所以首先我们保存目前这个不完整的deployment文件
repository so we're going to save this incomplete

1820
01:22:16,239 --> 01:22:21,520
我们命名其为mongo.yaml
deployment file first of all so let's call it

1821
01:22:21,520 --> 01:22:28,639
并保存它
deployment or let's just call it yaml and save it

1822
01:22:28,639 --> 01:22:31,679
这样我们就可以高亮显示语法了
here so that we get the syntax highlight and now

1823
01:22:31,679 --> 01:22:33,760
现在在我们apply这个配置之前
before we apply this configuration we're

1824
01:22:33,760 --> 01:22:35,199
先创建secret
going to create the secret

1825
01:22:35,199 --> 01:22:40,239
root用户名和密码将被放在那里
where the root username and password will leave

1826
01:22:40,239 --> 01:22:42,639
我们来创建一个新文件
so let's create a new file and i'm going

1827
01:22:42,639 --> 01:22:44,800
粘贴secret的配置
to paste in the configuration of a

1828
01:22:44,800 --> 01:22:46,239
实际上很简单
secret which is actually

1829
01:22:46,239 --> 01:22:49,760
类型为Secret
pretty simple so we have a kind secret

1830
01:22:49,760 --> 01:22:51,760
然后我们有一个元数据
then we have a metadata which again is

1831
01:22:51,760 --> 01:22:53,679
仅仅是名字
just simply the name

1832
01:22:53,679 --> 01:22:55,840
我们称它为mongodb-secret
we're going to call it mongodb secret

1833
01:22:55,840 --> 01:23:00,159
type属性为Opaque，这是默认值也是最基本的
the type opec is actually a default type which is the most basic

1834
01:23:00,159 --> 01:23:03,199
键值对secret类型
key value secret type other types for example

1835
01:23:03,199 --> 01:23:06,719
其他类型，如tls certificates类型
include tls certificates so you can create a

1836
01:23:06,719 --> 01:23:10,000
可以用来创建一个指定tls证书的secret
secret specifically with the tls certificate type

1837
01:23:10,000 --> 01:23:12,480
还有其他几种类型，但大多情况下
and a couple of more types but mostly

1838
01:23:12,480 --> 01:23:14,239
你将使用默认的
you're going to use the default one

1839
01:23:14,239 --> 01:23:16,960
这些是实际的内容
and these are the actual contents so you

1840
01:23:16,960 --> 01:23:21,120
data属性下有一些键值对
have the data and here you have key value pairs

1841
01:23:21,120 --> 01:23:24,719
当然键是你定义的
um which of course are the names you come up with

1842
01:23:24,719 --> 01:23:27,520
我们会指定用户名
so we're gonna specify username or we

1843
01:23:27,520 --> 01:23:32,880
可以称之为mongo-root-username
can actually call it root

1844
01:23:32,880 --> 01:23:36,080
而下面的将其命名为mongo-root-password
username and we're going to call it

1845
01:23:36,080 --> 01:23:40,000
有件事需要说
root password and here's the thing the values

1846
01:23:40,000 --> 01:23:43,440
当我们创建一个secret时
in in this key value pairs

1847
01:23:43,440 --> 01:23:46,880
键值对中的值并不是纯文本
are not plain text so when we are creating a secret

1848
01:23:46,880 --> 01:23:49,920
该值必须经过base64编码
the value must be base64 encoded

1849
01:23:49,920 --> 01:23:53,360
最简单的转码方法是
so the way you can do that the simplest way is

1850
01:23:53,360 --> 01:23:56,880
到终端输入
go to your terminal so here i'm going to say echo

1851
01:23:56,880 --> 01:24:00,080
echo -n，后者是很重要的选项别忘了
minus n very important option don't leave it out

1852
01:24:00,080 --> 01:24:02,400
否则就没用了
otherwise it's not gonna work and here

1853
01:24:02,400 --> 01:24:05,360
然后向其中写一个纯文本值
i'm gonna put a plain text value that i want

1854
01:24:05,360 --> 01:24:08,560
这里我想用username
so i'm just gonna go with just username

1855
01:24:08,560 --> 01:24:12,239
当然可以是任何更安全的内容
whatever of course you can have something more

1856
01:24:12,239 --> 01:24:15,679
我要做base64编码
secretive here and i'm gonna

1857
01:24:15,679 --> 01:24:20,080
这里得到的值
base64 encoding and the value that i get here

1858
01:24:20,080 --> 01:24:24,560
复制到secret配置文件里，作为键值对的值
i'm gonna copy it into the secret configuration as a value

1859
01:24:24,560 --> 01:24:28,400
密码也是一样
and i'm gonna do the same with password so

1860
01:24:28,400 --> 01:24:30,080
我还是要简单点的密码
again i'm just gonna go with simple

1861
01:24:30,080 --> 01:24:33,760
显然你可以使用更安全的
password obviously you want to have something more secure

1862
01:24:33,760 --> 01:24:38,000
我要把它作为一个值复制到这里
and i'm gonna copy that as a value here

1863
01:24:38,000 --> 01:24:46,080
文件保存为secret.yaml
and save it is secret dot yaml

1864
01:24:46,080 --> 01:24:48,400
现在我们只写了配置文件
okay now we have only written

1865
01:24:48,400 --> 01:24:51,280
还没有在集群中创建任何东西
configuration files we haven't created anything yet

1866
01:24:51,280 --> 01:24:55,199
所以这只是准备工作
in the cluster so this is just preparation work

1867
01:24:55,199 --> 01:24:58,800
如果我们要在deployment里引用该secret
and we have to create secret before the deployment

1868
01:24:58,800 --> 01:25:00,880
就需要在创建deployment前创建secret
if we're gonna reference the secret

1869
01:25:00,880 --> 01:25:02,800
创建的顺序很重要
inside of this so the order

1870
01:25:02,800 --> 01:25:04,800
因为如果我
of creation matters because if i'm

1871
01:25:04,800 --> 01:25:07,840
创建一个deployment，它引用一个不存在的secret
creating a deployment that references a secret

1872
01:25:07,840 --> 01:25:10,960
我会得到一个报错
that doesn't exist yet i'm gonna get an error

1873
01:25:10,960 --> 01:25:13,199
所以也就启动不了
so it's not going to start since we have

1874
01:25:13,199 --> 01:25:15,120
既然有第一个组件
our first component let's actually go

1875
01:25:15,120 --> 01:25:18,639
让我们用配置文件创建我们的secret
ahead and create our secret from a configuration file

1876
01:25:18,639 --> 01:25:22,000
再次回到控制台
so again i'm going to go to my console

1877
01:25:22,000 --> 01:25:26,400
清空
let's actually clear all these and i'm gonna go

1878
01:25:26,400 --> 01:25:30,320
进入包含了所有这些配置文件的文件夹
into the folder where i'm creating all these configuration files

1879
01:25:30,320 --> 01:25:32,960
我这里它的名字为k8s-configuration
i called it kubernetes configuration and

1880
01:25:32,960 --> 01:25:35,040
这是我的两个文件
here i have both of my files

1881
01:25:35,040 --> 01:25:42,800
我要执行kubectl apply命令
so i'm do i'm gonna do cube ctl apply secret

1882
01:25:42,800 --> 01:25:46,480
secret被创建了，再执行kubectl get secret命令
and secret created so i'm gonna do kubectl

1883
01:25:46,480 --> 01:25:52,560
就会看到我刚刚创建的secret
get secret and i should see my secret has been created this is

1884
01:25:52,560 --> 01:25:54,080
这个是默认创建的东西
something created by default

1885
01:25:54,080 --> 01:25:57,920
采用另一种类型，这里是我们的secret
with a different type and this is our secret here

1886
01:25:57,920 --> 01:26:01,679
既然我们有了secret，就可以
so now that we have our secrets we can reference it

1887
01:26:01,679 --> 01:26:04,719
在我们的deployment的配置文件中引用它
inside of our deployment configuration file

1888
01:26:04,719 --> 01:26:08,400
所以我们回到该文件
so let's go back and this is how you reference

1889
01:26:08,400 --> 01:26:11,760
这就是你引用secret中键值数据的方式
contents specific key value data

1890
01:26:11,760 --> 01:26:18,480
不是在value赋值，而是说明value从哪里来，使用valueFrom
of secret so instead of value we're going to say value from

1891
01:26:18,480 --> 01:26:24,719
然后要用secretKeyRef属性，指定引用的secret
and then i'm going to do secret key ref or secret key reference

1892
01:26:24,719 --> 01:26:28,800
名字将是secret名字
and name is going to be the secret name

1893
01:26:28,800 --> 01:26:32,239
就是这一个
so this one here and

1894
01:26:32,239 --> 01:26:35,360
键是data属性中的键
key is going to be the key in the data

1895
01:26:35,360 --> 01:26:38,880
我想要这个键值对的值
i want the value of this key value pair

1896
01:26:38,880 --> 01:26:41,120
所以我想要data的这部分
so i want this part of the data so i'm

1897
01:26:41,120 --> 01:26:42,880
通过键引用它
going to reference it by key

1898
01:26:42,880 --> 01:26:44,960
你显然不需要记住
so you don't have to learn it by heart

1899
01:26:44,960 --> 01:26:47,920
所有的语法和属性名
obviously all the syntax and attribute names

1900
01:26:47,920 --> 01:26:50,400
重要的是你要知道
important thing here is that you know

1901
01:26:50,400 --> 01:26:52,480
大概如何引用它
approximately how to reference it

1902
01:26:52,480 --> 01:26:54,960
语法你可以随时
the actual syntax you can always look up

1903
01:26:54,960 --> 01:26:58,080
在谷歌或者之前的配置文件中查找
in google or maybe from previous configuration files

1904
01:26:58,080 --> 01:26:59,840
是的，这就是你引用它的方式
but yeah this is how you reference it

1905
01:26:59,840 --> 01:27:01,520
我们也要对密码做同样的事
and we're gonna do the same with

1906
01:27:01,520 --> 01:27:06,239
我要复制valueFrom
password so i'm gonna do from and i'm just gonna copy

1907
01:27:06,239 --> 01:27:09,840
和其余的内容
the rest here

1908
01:27:09,840 --> 01:27:13,040
记住，yaml对缩进是非常严格的
remember yaml is very strict with the indentation

1909
01:27:13,040 --> 01:27:16,639
这里有一个相同的secret，但是不同的key
here is the same secret but a different key so i'm gonna

1910
01:27:16,639 --> 01:27:21,520
我要在这里使用password作为key
use password key here and

1911
01:27:21,520 --> 01:27:25,040
就是这样
that will be it so now we have

1912
01:27:25,040 --> 01:27:26,960
现在我们从secret引用了
the root username and password

1913
01:27:26,960 --> 01:27:29,280
root用户名和密码
referenced from the secret

1914
01:27:29,280 --> 01:27:34,080
但配置文件里面没有具体的值
and no actual values inside the configuration file

1915
01:27:34,080 --> 01:27:35,679
这对安全有好处
which is good for security because you

1916
01:27:35,679 --> 01:27:37,280
因为你不希望你的凭证信息
don't want your credentials

1917
01:27:37,280 --> 01:27:40,639
出现在你的代码库中
in your code repository okay so

1918
01:27:40,639 --> 01:27:43,440
好的，我们的deployment文件已经准备好了
our deployment file is actually ready so

1919
01:27:43,440 --> 01:27:55,199
让我们apply一下，通过kubectl apply
let's apply that kubectl apply

1920
01:27:55,199 --> 01:27:58,400
而这次deployment就被创建了
and the deployment created meaning if i do

1921
01:27:58,400 --> 01:28:01,840
如果我执行get all命令
get all i should see the pod

1922
01:28:01,840 --> 01:28:05,280
可以看到pod启动了，然后是deployment和ReplicaSet
starting up the deployment and the replica set

1923
01:28:05,280 --> 01:28:12,080
所以让我们看看pod怎么样了
so let's actually check how pod is doing

1924
01:28:12,080 --> 01:28:16,159
容器创建中，那就watch一下
container creating so let's actually watch

1925
01:28:16,159 --> 01:28:18,719
可能需要一些时间来创建容器
it might take some time to create it if

1926
01:28:18,719 --> 01:28:20,800
如果花了很长时间
it takes long and if you want to

1927
01:28:20,800 --> 01:28:22,400
你想看看哪里是否有问题
see whether there is a problem there you

1928
01:28:22,400 --> 01:28:28,400
可以执行kubectl describe + pod的名称
can also do cube ctl describe pod and the pod name

1929
01:28:28,400 --> 01:28:31,520
至少我们知道一切正常
so at least we know nothing's wrong there

1930
01:28:31,520 --> 01:28:33,679
所以我们看到它在拉取镜像
so we see that it's just pulling the

1931
01:28:33,679 --> 01:28:35,120
这就是耗时久的原因
image so that's what it

1932
01:28:35,120 --> 01:28:38,880
我们再来看看
takes so long so let's see again

1933
01:28:38,880 --> 01:28:42,000
执行kubectl get pod命令，如你所见
cube ctl get pod and as you see

1934
01:28:42,000 --> 01:28:45,679
它正在运行，所以我们有了mongodb的deployment
it's running so we have mongodb deployment

1935
01:28:45,679 --> 01:28:48,800
还有端口，一个副本正在运行
and the port one replica of its part running

1936
01:28:48,800 --> 01:28:50,560
第二步，我们要
now the second step is we're gonna

1937
01:28:50,560 --> 01:28:52,480
创建内部service
create an internal service

1938
01:28:52,480 --> 01:28:55,360
这样其他组件或端口
so that other components or other ports

1939
01:28:55,360 --> 01:28:56,960
就可以和这个mongodb通话了
can talk to this mongodb

1940
01:28:56,960 --> 01:29:01,280
让我们继续创建service的配置
so let's go ahead and create service configuration

1941
01:29:01,280 --> 01:29:04,719
回到yaml文件，我们可以
so go back to yaml and here we can

1942
01:29:04,719 --> 01:29:09,199
要么创建一个单独的给secret用的文件（口误，应是service）
either create a separate yaml configuration file for secret or we

1943
01:29:09,199 --> 01:29:11,280
要么可以在同一个yaml文件中把service的内容包含进去
can also include it in the same one

1944
01:29:11,280 --> 01:29:13,679
所以实际上在yaml中
so in yaml you can actually put multiple

1945
01:29:13,679 --> 01:29:16,080
你可以放多个文档在一个文件中
documents in one file

1946
01:29:16,080 --> 01:29:18,719
如果我画三个破折号
so if i put three dashes that's

1947
01:29:18,719 --> 01:29:20,239
这是一个语法
basically a syntax

1948
01:29:20,239 --> 01:29:22,880
用于yaml中的文档分离
for document separation in yaml so i

1949
01:29:22,880 --> 01:29:24,560
从而可以开始写新文档
need new document is starting

1950
01:29:24,560 --> 01:29:27,600
我要把两个配置
so actually i'm gonna put both deployment and service

1951
01:29:27,600 --> 01:29:29,440
都写在在一个配置文件中
in one configuration file because they

1952
01:29:29,440 --> 01:29:31,199
因为它们通常属于彼此
usually belong together

1953
01:29:31,199 --> 01:29:35,840
这里我要粘贴service的配置
so here i'm gonna paste the service configuration

1954
01:29:35,840 --> 01:29:37,360
顺便说一下，我要把这些配置文件
and by the way i'm gonna put all these

1955
01:29:37,360 --> 01:29:40,000
都放进git仓库中
configuration files in git repository

1956
01:29:40,000 --> 01:29:44,400
本视频的简介中会有该仓库的链接
and link the repository in the description of this video

1957
01:29:44,400 --> 01:29:47,760
这就是mongodb的service
so this is a service for mongodb let's go through

1958
01:29:47,760 --> 01:29:51,760
让我们回顾一些属性，这是service的类型
some of the attributes here so it's the service kind

1959
01:29:51,760 --> 01:29:53,199
这是我们给它取得名字
just the name we're going to call it

1960
01:29:53,199 --> 01:29:55,520
然后是mongodb service的选择器
mongodb service selector

1961
01:29:55,520 --> 01:29:58,880
这一点很重要，因为我们想
this is an important one because we want this service to

1962
01:29:58,880 --> 01:30:02,080
让此service连接到正确的pod，为此
connect to the pod right and the way to do that

1963
01:30:02,080 --> 01:30:05,440
需要使用选择器和标签(label)
is using selector and

1964
01:30:05,440 --> 01:30:10,080
用这个deployment和pod有的标签
label so using this here the labels that deployment and

1965
01:30:10,080 --> 01:30:13,520
service可以找到
pod have service can find the parts

1966
01:30:13,520 --> 01:30:15,600
要依附的pod
that it's going to attach to all right

1967
01:30:15,600 --> 01:30:17,199
所以这里要有选择器
so we have the selector here

1968
01:30:17,199 --> 01:30:20,400
这里也是很重要的一部分
and this is important part where we

1969
01:30:20,400 --> 01:30:23,840
用于开放service的端口
expose service port so this is going to

1970
01:30:23,840 --> 01:30:25,120
这将是service的端口
be the service port

1971
01:30:25,120 --> 01:30:27,120
而这是容器的
and this is going to be the container

1972
01:30:27,120 --> 01:30:29,920
当我们开放了在这个地址的容器的端口
and since we exposed container port at

1973
01:30:29,920 --> 01:30:33,040
二者将匹配
this address right here these two have

1974
01:30:33,040 --> 01:30:35,199
因此targetPort属性是
to match so target port is

1975
01:30:35,199 --> 01:30:39,760
容器或pod的端口，这是service的端口
container or pod port and this is the service port

1976
01:30:39,760 --> 01:30:43,520
显然这两个可以是不同的
and obviously these two here can be different

1977
01:30:43,520 --> 01:30:46,239
但我还是想用相同的端口
but i'm gonna go with the same port and

1978
01:30:46,239 --> 01:30:47,360
基本上
that's basically it

1979
01:30:47,360 --> 01:30:49,600
这就是我们的service
that's our service so i'm gonna create

1980
01:30:49,600 --> 01:30:51,120
现在我要创建service
the service now

1981
01:30:51,120 --> 01:30:54,960
保存这个文件，然后回到控制台
so let's save this file and go back to my

1982
01:30:54,960 --> 01:30:59,520
我要在再apply一下
console and i'm gonna apply

1983
01:30:59,520 --> 01:31:02,560
刚才那个用于创建deployment的文件
the same file that i applied before to create

1984
01:31:02,560 --> 01:31:05,679
让我们看看会发生什么
deployment so let's see what happens see

1985
01:31:05,679 --> 01:31:07,920
现在既有deployment又有service
both deployment and service configuration

1986
01:31:07,920 --> 01:31:09,360
但我没有改变deployment
but it's going to know that i haven't

1987
01:31:09,360 --> 01:31:12,320
就像这里写的
changed the deployment that's what it means here

1988
01:31:12,320 --> 01:31:15,440
然后一个service被创建了
and a service is created so if i

1989
01:31:15,440 --> 01:31:20,239
如果我要编辑二者，我可以重新apply该文件
were to edit both for example i can reapply the file

1990
01:31:20,239 --> 01:31:22,400
deployment和service均会被修改
and deployment of service can be changed

1991
01:31:22,400 --> 01:31:23,440
所以我认为
so i think

1992
01:31:23,440 --> 01:31:27,840
使用本地配置文件是一种方便的编辑组件的方法
using local configuration files is a handy way to edit

1993
01:31:27,840 --> 01:31:29,920
现在我们
your components so now let's actually

1994
01:31:29,920 --> 01:31:36,239
用get service命令检查我们的service是否已经创建
check that our service was created get service

1995
01:31:36,239 --> 01:31:40,280
这就是我们的service，正在监听端口27017
and this is our service and it's listening at port

1996
01:31:40,280 --> 01:31:42,880
我在之前的一个视频中展示过这个
27017 and i showed it in one of the

1997
01:31:42,880 --> 01:31:44,880
但我们还能够
previous videos but we can actually

1998
01:31:44,880 --> 01:31:48,400
验证service是否连接到正确的pod
also validate that the service is attached to the correct

1999
01:31:48,400 --> 01:31:54,320
为此，我要执行
pod and to do that i'm gonna do describe

2000
01:31:54,320 --> 01:31:59,520
describe + service名的命令
service and i need the service name for this

2001
01:31:59,520 --> 01:32:02,800
这里我有一个端点(endpoint)
so here i have the endpoint which is an

2002
01:32:02,800 --> 01:32:06,400
是一个pod的ip地址和端口
ip address of a pod and the

2003
01:32:06,400 --> 01:32:09,600
应用程序在pod中监听该端口
port where the application inside the pod is

2004
01:32:09,600 --> 01:32:11,760
我们来检查一下
listening it so let's actually check

2005
01:32:11,760 --> 01:32:13,199
是否是正确的pod
that this is the right pod

2006
01:32:13,199 --> 01:32:16,880
虽说我们只有一个pod，但还是想验证
i mean we just have one but still so if i do get

2007
01:32:16,880 --> 01:32:20,639
执行get pod命令，想要额外输出，-o选项设置wide
pod and i want additional output

2008
01:32:20,639 --> 01:32:24,080
有一列包含了ip地址
to what i get by default one of the columns

2009
01:32:24,080 --> 01:32:28,320
就是这里
includes the ip address which is this one right here

2010
01:32:28,320 --> 01:32:37,360
所以172.17.0.6这是pod的ip地址
so 172.17.0.6 that's the pod ip address and this is

2011
01:32:37,360 --> 01:32:42,400
而这是pod中的应用程序在监听的端口
the port where the application inside the pod is listening at

2012
01:32:42,400 --> 01:32:44,480
所以一切都安排得很完美
so everything is set up perfectly

2013
01:32:44,480 --> 01:32:47,280
mongodb的deployment和service已完成创建
mongodb deployment and service has been created

2014
01:32:47,280 --> 01:32:49,520
顺便说一下，如果你想看
and by the way if you want to see all

2015
01:32:49,520 --> 01:32:52,639
一个应用的所有组件
the components for one

2016
01:32:52,639 --> 01:32:56,239
你也可以用kubectl get all命令显示它们
application you can also display them

2017
01:32:56,239 --> 01:33:00,400
这将显示所有组件
using cube ctl get all that will show all the components

2018
01:33:00,400 --> 01:33:07,280
你可以通过名字来筛选它们，所以输入mongodb
and you can filter them by name so mongodb

2019
01:33:07,280 --> 01:33:14,480
这里你可以看到service、deployment、replicaSet和pod
and here you see the service deployment replica set and the pod

2020
01:33:14,480 --> 01:33:18,480
所以当你执行get all
so when you do all the component type will be

2021
01:33:18,480 --> 01:33:22,159
首先映入眼帘的会是组件类型，这只是辅助信息
the first here okay that's uh just a side info

2022
01:33:22,159 --> 01:33:24,159
接下来我们要
so now the next step we're going to

2023
01:33:24,159 --> 01:33:27,199
创建Mongo Express的deployment和service
create express deployment and service

2024
01:33:27,199 --> 01:33:30,159
还有一个外部配置
and also an external configuration um

2025
01:33:30,159 --> 01:33:31,360
在那里我们要放置
where we're going to put

2026
01:33:31,360 --> 01:33:34,080
mongodb数据库的url
the database url for mongodb so let's go

2027
01:33:34,080 --> 01:33:35,440
继续
ahead and do it

2028
01:33:35,440 --> 01:33:38,880
清空，然后
so i'm going to clear that up and go and

2029
01:33:38,880 --> 01:33:40,400
创建一个新文件
create a new file

2030
01:33:40,400 --> 01:33:43,920
用于Mongo Express的deployment和service
for express deployment and service

2031
01:33:43,920 --> 01:33:49,120
这是Express的deployment的草稿
so this is the deployment draft of express

2032
01:33:49,120 --> 01:33:53,040
同样的，Express也配拥有姓名
same things here express that's the name

2033
01:33:53,040 --> 01:33:56,880
这是pod的定义，镜像名是mongo-express
and here we have the pod definition where the image

2034
01:33:56,880 --> 01:34:01,040
我们也来检查一下这个镜像
name is express let's actually go ahead and check that image

2035
01:34:01,040 --> 01:34:07,280
我们不需要这个网页，就是这个Express
as well we don't need this this is express

2036
01:34:07,280 --> 01:34:09,199
这就是mongo-express镜像的名字
and that's the name of the image mongo

2037
01:34:09,199 --> 01:34:12,159
我们来看看同样的数据
express and let's see the same data here

2038
01:34:12,159 --> 01:34:16,080
让我们看看Express应用程序的端口
let's see the port the express application

2039
01:34:16,080 --> 01:34:20,719
容器内部的会在端口8081启动
inside the container starts at is 8081

2040
01:34:20,719 --> 01:34:24,400
这些是一些环境问题变量
and these are some of the environmental

2041
01:34:24,400 --> 01:34:27,920
我们一般需要三个变量
variables so obviously we need three things for express

2042
01:34:27,920 --> 01:34:31,520
我们需要告诉它应该连接哪个数据库应用程序
we need to tell it which database application

2043
01:34:31,520 --> 01:34:33,600
显然我们需要
it should connect to so obviously we

2044
01:34:33,600 --> 01:34:35,520
告诉它mongodb的地址
need to tell it the mongodb

2045
01:34:35,520 --> 01:34:37,520
即连接到内部service的
address database address it should

2046
01:34:37,520 --> 01:34:39,600
数据库的地址
connect to the internal service

2047
01:34:39,600 --> 01:34:41,920
我们需要凭证信息
and we we're gonna need credentials so

2048
01:34:41,920 --> 01:34:44,320
这样mongodb可以验证连接
that mongodb can authenticate

2049
01:34:44,320 --> 01:34:48,159
相应的环境变量是
that connection and the environmental variables to do that

2050
01:34:48,159 --> 01:34:50,320
ADMINUSERNAME（管理员用户名）和PASSWORD
is going to be admin username admin

2051
01:34:50,320 --> 01:34:52,080
以及mongodb端点，即MONGODB_SERVER
password and the mongodb

2052
01:34:52,080 --> 01:34:54,320
这就是
endpoint will be this here so these

2053
01:34:54,320 --> 01:34:56,320
我们需要的三个环境变量
three environmental variables we need

2054
01:34:56,320 --> 01:34:59,760
继续
so let's go ahead and use that so first

2055
01:34:59,760 --> 01:35:02,320
我们首先要开放端口
we're going to open the port

2056
01:35:02,320 --> 01:35:08,480
输入containerPort属性
again container ports

2057
01:35:08,480 --> 01:35:12,080
为什么在pod内会有多个端口
and the reason why you have multiple ports is that inside of the pod

2058
01:35:12,080 --> 01:35:15,360
是因为你实际上可以开放多个端口
you can actually open multiple ports

2059
01:35:15,360 --> 01:35:19,760
这里也就是8081，现在我们
so that's going to be 8081 and now we're gonna

2060
01:35:19,760 --> 01:35:21,440
要添加环境变量以便连接
add the environment to variables for the

2061
01:35:21,440 --> 01:35:26,960
第一个是用户名
connectivity so the first one is the username

2062
01:35:26,960 --> 01:35:28,480
这显然要和定义在这里
and this is going to be obviously the

2063
01:35:28,480 --> 01:35:30,719
的用户名和密码
same username and password that we

2064
01:35:30,719 --> 01:35:33,920
一致
defined right here so what i'm going to

2065
01:35:33,920 --> 01:35:35,360
所以我要复制它们
do is i'm just going to copy them

2066
01:35:35,360 --> 01:35:38,560
因为它和我们从secret中读出的值
because it's really the same so the value from we're

2067
01:35:38,560 --> 01:35:40,400
是一样的
going to read it from the secret

2068
01:35:40,400 --> 01:35:48,000
粘贴到这里
that's already there so i'm gonna paste it here

2069
01:35:48,000 --> 01:35:52,960
第二个环境变量被称为ADMINPASSWORD
second environmental variable is called admin password

2070
01:35:52,960 --> 01:35:58,480
我也要从这里复制这个valueFrom
and i'm also gonna copy that from here

2071
01:35:58,480 --> 01:36:02,239
第三个
and the third one

2072
01:36:02,239 --> 01:36:05,520
将是数据库服务器(MONGODB_SERVER)
is going to be the database server and

2073
01:36:05,520 --> 01:36:07,040
因为它也是外部配置
since this is also an external

2074
01:36:07,040 --> 01:36:09,199
我们可以选择
configuration we can either

2075
01:36:09,199 --> 01:36:13,119
写value属性，然后直接在这里
do value here and we could write the mongodb server

2076
01:36:13,119 --> 01:36:16,159
写mongodb服务器的地址
address directly here or as i showed you

2077
01:36:16,159 --> 01:36:17,679
或者也可以像我在开头的图中所说的
in the diagram at the beginning we can

2078
01:36:17,679 --> 01:36:21,760
把它放进ConfigMap中，从而进行外部配置
put it in a config map which is an external configuration so

2079
01:36:21,760 --> 01:36:24,960
它是将内容集中存储到一个地方的
that it's centralized so it's stored in one place

2080
01:36:24,960 --> 01:36:28,159
其他组件也可以使用它
and also other components can also use it

2081
01:36:28,159 --> 01:36:30,239
举个例子，如果我有两个
so for example if i have two

2082
01:36:30,239 --> 01:36:32,480
使用mongodb数据库的应用程序
applications that are using mongodb

2083
01:36:32,480 --> 01:36:36,000
那我就可以引用
database then i can just reference

2084
01:36:36,000 --> 01:36:38,239
这个外部配置
that external configuration here and if

2085
01:36:38,239 --> 01:36:40,320
如果我必须在某个时候改变它
i have to change it at some point i just

2086
01:36:40,320 --> 01:36:43,520
只需更改一处，无需更新其它的东西
change it in one place and nothing else gets updated

2087
01:36:43,520 --> 01:36:47,600
因此，我们将保留这个不完整的
so because of that we're going to keep this incomplete

2088
01:36:47,600 --> 01:36:50,719
deployment的配置
deployment configuration and

2089
01:36:50,719 --> 01:36:52,960
并创建ConfigMap
we're going to create the config map

2090
01:36:52,960 --> 01:36:55,760
其中要包含mongodb服务器的地址
which will contain the mongodb server

2091
01:36:55,760 --> 01:36:58,080
我要创建一个新的文件
address so i'm going to create a new

2092
01:36:58,080 --> 01:36:59,760
让我们先保存这个
file let's actually save this

2093
01:36:59,760 --> 01:37:04,159
不完整的deployment，命名为mongo-express.yaml
incomplete deployment let's call it express

2094
01:37:04,159 --> 01:37:07,760
我们会在晚些时候回到这里
yaml and we're going to come back to it later

2095
01:37:07,760 --> 01:37:10,800
保存，现在我们需要一个ConfigMap
so save that now we need a

2096
01:37:10,800 --> 01:37:14,480
复制配置
config map here so i'm going to copy the configuration

2097
01:37:14,480 --> 01:37:18,480
这个也很简单，就像secret
and this is also pretty simple just like secret

2098
01:37:18,480 --> 01:37:22,159
类型是ConfigMap
you have the kind which is configmap

2099
01:37:22,159 --> 01:37:26,560
然后是名称，都是相同的格式
the name and the same construct see just like you saw here

2100
01:37:26,560 --> 01:37:30,960
data里是键值对，这里没有type属性
data which is key value pair it doesn't have a type

2101
01:37:30,960 --> 01:37:34,080
因为只有一种ConfigMap的type
because they're just one config map type and that's it

2102
01:37:34,080 --> 01:37:37,360
这里还有键值对
and here you again have key value pairs

2103
01:37:37,360 --> 01:37:40,480
所以数据库url和服务器名
so database url and server name

2104
01:37:40,480 --> 01:37:43,040
实际上是service的名称
is actually the name of the service it's

2105
01:37:43,040 --> 01:37:44,480
就这么简单
as simple as that

2106
01:37:44,480 --> 01:37:46,639
我们调用的service叫mongodb-service
so what do we call our service we called

2107
01:37:46,639 --> 01:37:48,960
所以我要复制这个service名
it mongodb service so i'm going to copy

2108
01:37:48,960 --> 01:37:51,520
它将是
the service name and that's going to be

2109
01:37:51,520 --> 01:37:54,239
数据库服务器url的值
the database server url

2110
01:37:54,239 --> 01:37:58,400
然后为了保持文件名的一致性
so i'm going to copy that and let's actually call it

2111
01:37:58,400 --> 01:38:02,880
保存文件为mongo-configmap.yaml
config map for consistency and save it

2112
01:38:02,880 --> 01:38:06,320
就像secret一样
and just like with secret the order of

2113
01:38:06,320 --> 01:38:09,520
执行或创建组件的顺序很重要
execution or creation matters so i have to have

2114
01:38:09,520 --> 01:38:12,639
必须先已经在集群中有一个ConfigMap
a config map already in the cluster so

2115
01:38:12,639 --> 01:38:14,800
然后才能引用它
that i can reference it

2116
01:38:14,800 --> 01:38:18,159
所以当我们写完配置
so when we're done i have to create the

2117
01:38:18,159 --> 01:38:20,000
我需要先创建ConfigMap
configmap first and then

2118
01:38:20,000 --> 01:38:22,880
然后再是deployment
the deployment so the way that i can

2119
01:38:22,880 --> 01:38:24,880
这样才能让deployment内部引用ConfigMap
reference the config map

2120
01:38:24,880 --> 01:38:29,199
和Secret非常类似
inside the deployment is very similar to secret

2121
01:38:29,199 --> 01:38:33,199
所以我要从secret复制整个内容
so i'm actually gonna copy the whole thing from secret

2122
01:38:33,199 --> 01:38:35,360
把它放在这里，唯一不同的是
put it here the only thing different

2123
01:38:35,360 --> 01:38:39,440
这部分不是secret
here is that instead of secret i'm gonna say

2124
01:38:39,440 --> 01:38:44,320
而是configMap，显然属性名都是驼峰编码
config map it's all camel case and

2125
01:38:44,320 --> 01:38:48,480
显然名字是configMap，我们这么给它命名的
obviously the name is gonna be config map that's what we

2126
01:38:48,480 --> 01:38:51,280
emmm就是这个名字
called it i think yes that's the name

2127
01:38:51,280 --> 01:38:53,440
我们来复制一下
let's actually copy it

2128
01:38:53,440 --> 01:38:57,679
接着，键是键值对中的key
and again the key is the key in the key value pair here

2129
01:38:57,679 --> 01:39:01,199
我们复制一下，现在我有了我们的
so let's copy that as well so now i have our

2130
01:39:01,199 --> 01:39:05,360
Mongo Express的deployment，这些都是标准的格式
express deployment these are just standard stuff

2131
01:39:05,360 --> 01:39:08,560
这就是pod的蓝图，或者说已有容器的配置
and this is where the pod blueprint or container

2132
01:39:08,560 --> 01:39:11,199
我们开放了端口8081
configuration exists we have exposed

2133
01:39:11,199 --> 01:39:13,600
这是标签为最新的镜像
port 8081 this is the image

2134
01:39:13,600 --> 01:39:16,400
这些是
with the latest tag and these are the

2135
01:39:16,400 --> 01:39:18,400
三个环境变量
three environmental variables

2136
01:39:18,400 --> 01:39:21,280
Mongo Express需要它们从而连接
that express needs to connect and

2137
01:39:21,280 --> 01:39:23,440
并验证mongodb
authenticate with mongodb

2138
01:39:23,440 --> 01:39:26,560
部署完成了，让我们继续
so deployment is done and let's go ahead and

2139
01:39:26,560 --> 01:39:32,320
先创建ConfigMap然后再创建deployment
create config map first and then express deployment

2140
01:39:32,320 --> 01:39:42,400
执行命令kubectl apply + ConfigMap
ctl apply config map and i'm going to do

2141
01:39:42,400 --> 01:39:50,000
接着执行命令kubectl apply创建Express
ctl apply express

2142
01:39:50,000 --> 01:39:53,360
我们来看看pod
and let's see the pod

2143
01:39:53,360 --> 01:39:56,960
容器创建中，看起来不错
so container creating looks good

2144
01:39:56,960 --> 01:40:00,560
再来看看pod
so let's see the pod and it's

2145
01:40:00,560 --> 01:40:04,400
运行中，我还想看看日志消息
running and i actually want to see the logs

2146
01:40:04,400 --> 01:40:09,360
所以我要执行kubectl logs命令
so i'm going to log the express

2147
01:40:09,360 --> 01:40:12,800
显示Express服务器启动了
and here you see that express server started and

2148
01:40:12,800 --> 01:40:15,920
并连接到数据库，现在是最后一步
database connected so now the final step

2149
01:40:15,920 --> 01:40:19,840
要能让浏览器访问到Express
is to access express from a browser

2150
01:40:19,840 --> 01:40:21,520
为了做到这一点
and in order to do that we are gonna

2151
01:40:21,520 --> 01:40:24,400
需要给Mongo Express配置外部service
need an external service for mongo express

2152
01:40:24,400 --> 01:40:27,440
让我们也来创建这个
so let's go ahead and create that one as well

2153
01:40:27,440 --> 01:40:30,960
清空，回到vscode
so let's clear this output go back to visual code

2154
01:40:30,960 --> 01:40:35,119
就像我们上次在deployment文件中做的那样
and as we did last time in the same file as the deployment

2155
01:40:35,119 --> 01:40:38,400
我要创建Express的service
i'm gonna create express service because

2156
01:40:38,400 --> 01:40:41,679
实际上，从来没有不带service的deployment
actually in practice you never have

2157
01:40:41,679 --> 01:40:44,480
所以把它们放在一起是很合理的
deployment without the service so it makes sense to

2158
01:40:44,480 --> 01:40:49,600
这就是Express的外部service
keep them together and this is express external service

2159
01:40:49,600 --> 01:40:53,199
这个配置现在看起来
and this configuration right now looks exactly same

2160
01:40:53,199 --> 01:40:57,360
和mongodb的service配置完全相同
as the db service configuration

2161
01:40:57,360 --> 01:41:00,239
甚至端口也是一样的
and even ports are the same like here i

2162
01:41:00,239 --> 01:41:03,040
比如这里开放了service的8081端口
have exposed service port at 8081

2163
01:41:03,040 --> 01:41:06,480
而targetPort就是容器监听的端口
and target port is where the container

2164
01:41:06,480 --> 01:41:10,000
为了创建这个外部service
port is listening so how do i make this

2165
01:41:10,000 --> 01:41:14,080
需要做两件事
external service is by doing two things

2166
01:41:14,080 --> 01:41:17,119
在spec部分
so in the specification section

2167
01:41:17,119 --> 01:41:20,159
我要在selector下面
so i'm gonna do it below the selector

2168
01:41:20,159 --> 01:41:23,360
输入一个类型
i'm gonna put a type

2169
01:41:23,360 --> 01:41:30,080
这个外部service的类型是负载均衡器(LoadBalancer)
and the type of this external service is load balancer

2170
01:41:30,080 --> 01:41:34,080
我认为这对外部service来说是个坏名字
which i think is a bad name for external service because

2171
01:41:34,080 --> 01:41:37,280
因为内部service也充当了负载均衡器
internal service also acts as a load

2172
01:41:37,280 --> 01:41:39,840
如果我有两个mongodb pod
balancer so if i had two mongodb pods

2173
01:41:39,840 --> 01:41:42,159
内部服务也将对这些pod来的请求
the internal service would also load

2174
01:41:42,159 --> 01:41:44,560
做负载均衡
balance the requests coming to these pods

2175
01:41:44,560 --> 01:41:47,760
所以我认为负载均衡器作为一个类型名
so i think the load balancer type name was

2176
01:41:47,760 --> 01:41:51,679
选得不是很好，因为它可能让人困惑
chosen not very well because it could be confusing

2177
01:41:51,679 --> 01:41:54,800
但是这种负载均衡器所做的主要是
but what this type load balancer does basically is it

2178
01:41:54,800 --> 01:41:58,159
通过为service分配外部可访问的ip地址
accepts external requests

2179
01:41:58,159 --> 01:42:01,679
接受外部请求
by assigning the service an external ip address

2180
01:42:01,679 --> 01:42:03,280
我们要做的另一件事
so another thing that we're going to do

2181
01:42:03,280 --> 01:42:05,280
使得这个service可被外部访问
here to make this

2182
01:42:05,280 --> 01:42:09,199
就是提供第三个端口
service external is right here we're going to provide

2183
01:42:09,199 --> 01:42:14,560
这将是nodePort属性
third port and this is going to be called node port

2184
01:42:14,560 --> 01:42:17,679
这基本上就是
and what this is basically is the

2185
01:42:17,679 --> 01:42:22,080
此外部ip地址要开放的端口
port where this external ip address will be open

2186
01:42:22,080 --> 01:42:26,000
浏览器也要通过此端口
so this will be the port that i'll have to put in the browser

2187
01:42:26,000 --> 01:42:29,040
访问service
to access this service and this node port

2188
01:42:29,040 --> 01:42:32,480
此端口实际上有一个范围，这个范围是
actually has a range and that range is

2189
01:42:32,480 --> 01:42:35,840
在30000到32767之间
between thirty thousand and thirty

2190
01:42:35,840 --> 01:42:38,880
所以不能
two thousand something so i can

2191
01:42:38,880 --> 01:42:41,199
给它分配和之前一样的端口
not give it the same port as here as i

2192
01:42:41,199 --> 01:42:43,840
必须在这个范围内
said it has to be between that range

2193
01:42:43,840 --> 01:42:46,639
所以我还是选30000吧
so i'm just going to go with the 30 000

2194
01:42:46,639 --> 01:42:50,880
这是在这个范围内的最小值
that's the minimum in that range and that would be it so this

2195
01:42:50,880 --> 01:42:54,480
这里的配置将创建一个外部service
configuration here will create an external service

2196
01:42:54,480 --> 01:42:57,520
继续，我来演示一下
let's go ahead and do it and i will show you

2197
01:42:57,520 --> 01:43:01,119
这些端口到底有什么不同
exactly how these ports differ from each other

2198
01:43:01,119 --> 01:43:10,000
所以我要apply一下Express的service
so i'm going to apply express so service created

2199
01:43:10,000 --> 01:43:14,320
如果执行get service命令
and if i do get service

2200
01:43:14,320 --> 01:43:18,639
可以看到mongodb的service先前被创建
i see that mongodb service that we created previously

2201
01:43:18,639 --> 01:43:22,080
类型为ClusterIP
has a type of cluster ip and the

2202
01:43:22,080 --> 01:43:24,080
我们刚刚创建的Express的service
express service that we just created

2203
01:43:24,080 --> 01:43:28,000
类型是之前明确定义的负载均衡器
is load balancer which is the type that we specifically defined

2204
01:43:28,000 --> 01:43:31,119
在内部服务中，我们没有具体指定任何类型
in internal service we didn't specify any type

2205
01:43:31,119 --> 01:43:35,119
因为ClusterIP
because cluster ip which is the same as

2206
01:43:35,119 --> 01:43:38,239
也就是内部service的类型，是默认的类型
internal service type is default so you

2207
01:43:38,239 --> 01:43:40,080
所以在创建内部Service时
don't have to define it when

2208
01:43:40,080 --> 01:43:42,480
不需要定义
you're creating internal service and the

2209
01:43:42,480 --> 01:43:44,480
不同之处在于
difference here is that

2210
01:43:44,480 --> 01:43:47,679
ClusterIP将为service提供
cluster ip will give the service

2211
01:43:47,679 --> 01:43:50,719
内部ip地址，即此ip地址
an internal ip address which is this one

2212
01:43:50,719 --> 01:43:54,000
这是一个service的内部ip地址
right here so this is an internal ip address

2213
01:43:54,000 --> 01:43:57,679
而负载均衡器也给
of the service and load balancer will also give

2214
01:43:57,679 --> 01:44:00,080
service提供内部ip地址
service an internal ip address but in

2215
01:44:00,080 --> 01:44:01,920
但除此之外，它还会
addition to that it will also

2216
01:44:01,920 --> 01:44:04,719
给service一个外部ip地址
give the service an external ip address

2217
01:44:04,719 --> 01:44:07,199
其中外部请求
where the external requests

2218
01:44:07,199 --> 01:44:09,360
会从这里来，这里在待机
will be coming from and here it says

2219
01:44:09,360 --> 01:44:11,600
因为我们在minikube里
pending because we're in mini cube and it

2220
01:44:11,600 --> 01:44:13,679
它和常规的k8s设置有一点不同
works a little bit differently in a

2221
01:44:13,679 --> 01:44:16,400
这里你也可以看到
regular kubernetes setup here you would also see

2222
01:44:16,400 --> 01:44:18,960
一个公共的ip地址
an actual ip address a public one and

2223
01:44:18,960 --> 01:44:21,199
这是另一个区别
this is another difference because

2224
01:44:21,199 --> 01:44:24,480
因为使用内部ip地址你会有
with internal ip address you just have

2225
01:44:24,480 --> 01:44:27,280
给该ip地址的端口
port for that ip address with both

2226
01:44:27,280 --> 01:44:29,760
而同时使用内部ip地址和外部ip地址
internal and external ip addresses you have

2227
01:44:29,760 --> 01:44:33,360
你也要有相应的两个端口，所以我们必须定义
ports for both of them and that's why we had to define

2228
01:44:33,360 --> 01:44:35,600
第三个端口，用于外部ip地址
third port which was for the external ip

2229
01:44:35,600 --> 01:44:37,520
如我所说，pending意味着
address as i said pending

2230
01:44:37,520 --> 01:44:41,199
它还没有外部ip地址
means that it doesn't have the external ip address yet

2231
01:44:41,199 --> 01:44:43,920
所以在minicube中做到这一点的方法是
so in minicube the way to do that is

2232
01:44:43,920 --> 01:44:45,199
使用命令
using the command

2233
01:44:45,199 --> 01:44:50,960
执行minikube service，我需要service的名称
mini cube service and i'm gonna need the name of the service

2234
01:44:50,960 --> 01:44:54,000
那么这个命令会给我的外部service
so this command will basically assign

2235
01:44:54,000 --> 01:44:56,960
分配一个公共ip地址
my external service a public ip address

2236
01:44:56,960 --> 01:44:58,560
我要执行这个
so i'm gonna execute this

2237
01:44:58,560 --> 01:45:03,280
浏览器窗口会打开，我会看到我的Mongo Express的页面
and the browser window will open and i will see my express

2238
01:45:03,280 --> 01:45:06,560
如果回到命令行
page so if i go back to the command line you see

2239
01:45:06,560 --> 01:45:11,040
可以看到这里给Express的service分配了一个url
that this command here assigned express service

2240
01:45:11,040 --> 01:45:13,679
其由公共ip地址
a url with a public ip address or with

2241
01:45:13,679 --> 01:45:16,239
或者说外部ip地址
an external ip address

2242
01:45:16,239 --> 01:45:20,159
与我们之前通过nodePort定义的端口组成
and the port which is what we defined in the node port

2243
01:45:20,159 --> 01:45:23,280
所以我基本上可以复制这个网址
so i can basically copy that command

2244
01:45:23,280 --> 01:45:26,000
和这个是一样的
which is the same as this one here

2245
01:45:26,000 --> 01:45:29,600
打开了Mongo Express的网页
and i get the page for express

2246
01:45:29,600 --> 01:45:31,360
现在有了这样的设置
so now with this setup the way it's

2247
01:45:31,360 --> 01:45:32,719
工作就会变成这样
going to work is that

2248
01:45:32,719 --> 01:45:35,760
当我在这里做改变的时候
when i make changes here for example i'm

2249
01:45:35,760 --> 01:45:41,280
比如我们想创建一个新的数据库叫Test-db
going to create a new database let's call it test db whatever

2250
01:45:41,280 --> 01:45:43,520
我将在后台建立一个请求
and i'm going to create a request what

2251
01:45:43,520 --> 01:45:48,560
请求会被发送到
just happened in background is that this request landed with

2252
01:45:48,560 --> 01:45:51,600
Mongo Express的外部service
the external service of express

2253
01:45:51,600 --> 01:45:55,199
然后转交给Mongo Express的pod
which then forwarded it to the express pod

2254
01:45:55,199 --> 01:45:58,320
pod连接到mongodb service
and the express part connected to the mongodb

2255
01:45:58,320 --> 01:46:01,440
是一个内部service
service and internal service and mongodb

2256
01:46:01,440 --> 01:46:03,760
然后，service转发该请求
service then forwarded that request

2257
01:46:03,760 --> 01:46:05,760
最后到达mongodb pod
finally to the mongodb pod

2258
01:46:05,760 --> 01:46:10,239
然后再往回走，就有了这样的变化
and then all the way back and we have the changes here

2259
01:46:10,239 --> 01:46:12,000
这就是如何部署一个简单的
so that's how you deploy a simple

2260
01:46:12,000 --> 01:46:19,040
kubernetes应用程序集群
application setup in a kubernetes cluster

2261
01:46:19,040 --> 01:46:20,960
在这集视频中，我们将讨论
in this video we're going to go through

2262
01:46:20,960 --> 01:46:23,360
命名空间的用法
the usages of a namespace

2263
01:46:23,360 --> 01:46:28,320
以及何时和如何使用命名空间的最佳实践
and the best practices of when and how to use a namespace

2264
01:46:28,320 --> 01:46:30,159
首先，kubernetes集群中的命名空间
first of all what is a namespace in

2265
01:46:30,159 --> 01:46:33,440
是什么，你可以在命名空间中组织资源
kubernetes in kubernetes cluster you can organize

2266
01:46:33,440 --> 01:46:36,400
这样您就可以在集群中
resources in namespaces so you can have

2267
01:46:36,400 --> 01:46:38,880
拥有多个命名空间
multiple namespaces in a cluster

2268
01:46:38,880 --> 01:46:40,880
您可以将命名空间看作
you can think of a namespace as a

2269
01:46:40,880 --> 01:46:44,480
在kubernetes集群中的虚拟集群
virtual cluster inside of a kubernetes cluster now when

2270
01:46:44,480 --> 01:46:46,080
创建一个集群
you create a cluster

2271
01:46:46,080 --> 01:46:49,760
kubernetes默认为您提供开箱即用的命名空间
by default kubernetes gives you namespaces

2272
01:46:49,760 --> 01:46:52,239
因此在命令行中
out of the box so in the command line if

2273
01:46:52,239 --> 01:46:54,719
我输入kubectctl get namespace
i type cubect ctl get namespaces

2274
01:46:54,719 --> 01:46:57,440
我看到了一份清单
i see a list of those out of the box

2275
01:46:57,440 --> 01:46:59,600
kubernetes提供的开箱即用的命名空间
namespaces that kubernetes offers

2276
01:46:59,600 --> 01:47:02,000
让我们一个一个的看一遍
and let's go through them one by one the

2277
01:47:02,000 --> 01:47:04,080
kubernetes-dashboard命名空间
kubernetes dashboard namespace

2278
01:47:04,080 --> 01:47:06,880
是在minikube中自动安装的
is shipped automatically in minicube so

2279
01:47:06,880 --> 01:47:08,480
这是minikube特有的
it's specific to mini cube

2280
01:47:08,480 --> 01:47:12,239
在一个标准集群中你不会有这个
installation you will not have this in a standard cluster

2281
01:47:12,239 --> 01:47:15,280
第一个是kube-system
the first one is cube system

2282
01:47:15,280 --> 01:47:18,560
kube-system命名空间不是给你用的
cube system namespace is not meant for

2283
01:47:18,560 --> 01:47:20,239
所以基本上你不应该
your use so basically you shouldn't

2284
01:47:20,239 --> 01:47:22,159
创建也不应该修改
create anything or shouldn't modify

2285
01:47:22,159 --> 01:47:25,199
kube-system命名空间中的任何内容
anything in cube system namespace the components

2286
01:47:25,199 --> 01:47:27,520
部署在这个命名空间中的是
that are deployed in the namespace are

2287
01:47:27,520 --> 01:47:29,280
系统进程
the system processes

2288
01:47:29,280 --> 01:47:32,400
他们来自master 管理进程
uh they're from master managing processes

2289
01:47:32,400 --> 01:47:35,520
或者kubectl等等，下一个是
or cubectl etc the next one is

2290
01:47:35,520 --> 01:47:38,639
kube-public，包含的
kube public and what kube public contains is

2291
01:47:38,639 --> 01:47:40,960
基本上是公开可访问的数据
basically the publicly accessible data

2292
01:47:40,960 --> 01:47:44,400
它有一个ConfigMap，包含
it has a config map that contains

2293
01:47:44,400 --> 01:47:46,960
可访问的集群信息
cluster information which is accessible

2294
01:47:46,960 --> 01:47:47,840
即使没有身份验证
even without

2295
01:47:47,840 --> 01:47:52,239
如果我在这里输入kubectl cluster-info
authentication so if i type here cube ctl cluster info

2296
01:47:52,239 --> 01:47:55,520
这是我得到的输出，一些信息
this is the output that i get through that

2297
01:47:55,520 --> 01:47:59,199
第三个是kube-node-lease
information and the third one is cube node lease

2298
01:47:59,199 --> 01:48:01,119
是最近才加入kubernetes的
which is actually a recent addition to

2299
01:48:01,119 --> 01:48:04,560
这个命名空间的目的是
kubernetes and the purpose of that namespace is that it

2300
01:48:04,560 --> 01:48:07,600
保存有关节点心跳的信息
holds information about the heartbeats of nodes so

2301
01:48:07,600 --> 01:48:10,800
每个节点基本上都有自己的对象
each node basically gets its own object

2302
01:48:10,800 --> 01:48:14,800
它包含了关于那个节点可用性的信息
that contains the information about that node's availability

2303
01:48:14,800 --> 01:48:18,480
第四个命名空间是默认命名空间
and the fourth namespace is the default namespace

2304
01:48:18,480 --> 01:48:20,320
默认命名空间就是
and default namespace is the one that

2305
01:48:20,320 --> 01:48:22,239
在还没有创建新的命名空间时
you're going to be using to create

2306
01:48:22,239 --> 01:48:24,480
你将会用它在一开始的时候
the resources at the beginning if you

2307
01:48:24,480 --> 01:48:26,800
创建资源
haven't created a new namespace

2308
01:48:26,800 --> 01:48:30,159
当然，您可以添加和创建新的命名空间
but of course you can add and create new namespaces

2309
01:48:30,159 --> 01:48:33,679
你可以用kubectl create namespace命名实现这个
and the way that you can do it is using kubectl

2310
01:48:33,679 --> 01:48:37,840
后面接上命名空间的名称
create namespace command with the name of the namespace

2311
01:48:37,840 --> 01:48:41,119
这样我就可以创建我的命名空间
so i can create my namespace

2312
01:48:41,119 --> 01:48:44,800
如果我使用kubectl get namespace，我就会看到
and if i do kubectl get namespaces i see

2313
01:48:44,800 --> 01:48:46,239
命名空间已经在我的清单上了
that in my list now

2314
01:48:46,239 --> 01:48:49,360
另一种创建命名空间的方法是
another way to create namespaces is

2315
01:48:49,360 --> 01:48:52,239
使用命名空间配置文件
using a namespace configuration file

2316
01:48:52,239 --> 01:48:53,280
我认为这是
which i think

2317
01:48:53,280 --> 01:48:55,199
创建命名空间的更好方法
is a better way to create namespaces

2318
01:48:55,199 --> 01:48:57,520
因为你可以在配置文件仓库中
because you also have a history

2319
01:48:57,520 --> 01:49:01,600
有关于在集群中创建了什么资源的
in your configuration file repository of what resources

2320
01:49:01,600 --> 01:49:04,080
历史记录
you created in the cluster okay so now

2321
01:49:04,080 --> 01:49:05,920
现在我们了解了命名空间是什么
we saw what namespaces are

2322
01:49:05,920 --> 01:49:08,880
你可以创造新的
and that you can create new ones and

2323
01:49:08,880 --> 01:49:11,280
kubernetes也提供了一些默认的
that kubernetes offer some of them by default

2324
01:49:11,280 --> 01:49:15,360
但问题是为什么需要命名空间
but the question is what is the need for namespaces

2325
01:49:15,360 --> 01:49:17,520
你应该何时创建它们
when should you create them and how you

2326
01:49:17,520 --> 01:49:19,440
如何使用它们
should use them and the first

2327
01:49:19,440 --> 01:49:23,040
第一个使用或创建自己的命名空间的用例如下
use case of using or creating your own namespaces

2328
01:49:23,040 --> 01:49:26,400
想象你只用
is the following imagine you have only

2329
01:49:26,400 --> 01:49:28,000
kubernetes提供的默认命名空间
default namespace which is provided

2330
01:49:28,000 --> 01:49:31,599
在默认名称空间中，你创建了所有你的资源
by kubernetes and you create all your resources

2331
01:49:31,599 --> 01:49:33,760
如果有一个
in that default namespace if you have a

2332
01:49:33,760 --> 01:49:35,040
复杂的应用程序
complex application

2333
01:49:35,040 --> 01:49:37,280
它有多个deployment
that has multiple deployments which

2334
01:49:37,280 --> 01:49:39,679
会创建许多pod的副本
create replicas of many pods

2335
01:49:39,679 --> 01:49:44,480
你还有很多资源，比如service和ConfigMap等等
and you have resources like services and config maps etc

2336
01:49:44,480 --> 01:49:46,480
很快您的默认命名空间
very soon your default namespace is

2337
01:49:46,480 --> 01:49:47,760
将充斥着
going to be filled with

2338
01:49:47,760 --> 01:49:49,679
不同的组件
different components and it will be

2339
01:49:49,679 --> 01:49:51,920
很难有一个对里面的东西的概览
really difficult to have an overview

2340
01:49:51,920 --> 01:49:54,480
尤其是我们有
of what's in there especially we have

2341
01:49:54,480 --> 01:49:57,040
多个用户在里面创建东西
multiple users creating stuff inside

2342
01:49:57,040 --> 01:50:00,719
所以这种情况下使用命名空间是更好的方法
so a better way to use namespaces in this case

2343
01:50:00,719 --> 01:50:04,880
将资源分组到不同命名空间中
is to group resources into namespaces so

2344
01:50:04,880 --> 01:50:07,679
例如，你可以有一个数据库命名空间
for example you can have a database namespace where

2345
01:50:07,679 --> 01:50:10,800
在那里部署你的数据库和它的所有需要的资源
you deploy your database and all its

2346
01:50:10,800 --> 01:50:14,639
你可以有一个监控命名空间
required resources and you can have a monitoring

2347
01:50:14,639 --> 01:50:17,119
在其中部署prometheus
namespace where you deploy the prometheus

2348
01:50:17,119 --> 01:50:18,880
和它需要的所有东西
and all the stuff that it needs

2349
01:50:18,880 --> 01:50:22,320
您还可以有elasticstack命名空间
you can also have elasticstack namespace where

2350
01:50:22,320 --> 01:50:26,320
部署ElasticSearch Kibana等等
all the  etc resources go

2351
01:50:26,320 --> 01:50:29,520
剩下的资源可以放在nginx-Ingress命名空间中
and you can have nginx ingress resources

2352
01:50:29,520 --> 01:50:32,560
这是对集群内的资源
so just one way of logically grouping your

2353
01:50:32,560 --> 01:50:35,440
进行逻辑分组的一种方式
resources inside of the cluster now

2354
01:50:35,440 --> 01:50:38,080
根据kubernetes官方文件
according to the official documentation

2355
01:50:38,080 --> 01:50:40,719
在项目较小，10个用户以下时
of kubernetes you shouldn't use

2356
01:50:40,719 --> 01:50:46,800
你不应该使用命名空间
namespaces if you have smaller projects and up to 10 users

2357
01:50:46,800 --> 01:50:50,159
我个人认为利用命名空间中对资源进行分组
i personally think that it's always good idea to

2358
01:50:50,159 --> 01:50:54,080
总是一种好的方法
group your resources in namespaces because

2359
01:50:54,080 --> 01:50:57,679
因为就像我说的，即使你有一个小项目，用户只有10个
as i said even if you have a small project and

2360
01:50:57,679 --> 01:51:00,639
对于你的应用程序
10 users you might still need some

2361
01:51:00,639 --> 01:51:02,000
你可能还需要一些额外资源
additional resources for your

2362
01:51:02,000 --> 01:51:04,320
就像日志系统
application like you know logging system

2363
01:51:04,320 --> 01:51:06,159
和监控系统
and monitoring system

2364
01:51:06,159 --> 01:51:08,800
即使使用最小的设置
and even with the minimum setup you can

2365
01:51:08,800 --> 01:51:09,679
你也已经
already get

2366
01:51:09,679 --> 01:51:13,280
把太多东西都扔进一个默认名称空间里了
too much to just throw everything in a default namespace

2367
01:51:13,280 --> 01:51:16,560
另一个需要用到命名空间的用例是
another use case where you will need to use namespaces

2368
01:51:16,560 --> 01:51:18,800
如果你有多个团队，想象一下
if you have multiple teams so imagine

2369
01:51:18,800 --> 01:51:20,320
这样的场景
the scenario you have

2370
01:51:20,320 --> 01:51:23,679
使用同一个集群的两个团队
two teams that use the same cluster

2371
01:51:23,679 --> 01:51:26,719
其中一个团队部署了一个应用程序
and one team deploys an application

2372
01:51:26,719 --> 01:51:27,760
被称为
which is called

2373
01:51:27,760 --> 01:51:29,920
my-app deployment，这是
my app deployment that's the name of the

2374
01:51:29,920 --> 01:51:31,360
他们创造的deployment的名字
deployment they create

2375
01:51:31,360 --> 01:51:34,880
这个deployment有它特定的配置
and that deployment has its certain configuration

2376
01:51:34,880 --> 01:51:38,239
如果另一队不小心弄了
now if another team had a deployment that

2377
01:51:38,239 --> 01:51:41,360
相同名字的deployment
accidentally had the same name but a

2378
01:51:41,360 --> 01:51:43,280
但是配置不同
different configuration

2379
01:51:43,280 --> 01:51:46,800
他们创造了deployment或apply了它
and they created the deployment or they applied it

2380
01:51:46,800 --> 01:51:50,880
他们会覆盖第一队的deployment
they would overwrite the first team's deployment

2381
01:51:50,880 --> 01:51:53,199
如果他们用的是
and if they're using for example a

2382
01:51:53,199 --> 01:51:56,800
jenkins或者其他自动部署的方式
jenkins or some automated way to deploy those

2383
01:51:56,800 --> 01:51:58,560
来创建或部署那个应用程序
that application or to create that

2384
01:51:58,560 --> 01:52:01,040
他们甚至都不会知道
deployment they wouldn't even know that

2385
01:52:01,040 --> 01:52:03,760
它们覆盖或破坏了另一个
they overwrote or disrupted another

2386
01:52:03,760 --> 01:52:05,040
团队的deployment
team's deployment

2387
01:52:05,040 --> 01:52:07,760
所以要避免再次发生这样的冲突
so to avoid such kind of conflicts again

2388
01:52:07,760 --> 01:52:08,400
您可以使用
you can use

2389
01:52:08,400 --> 01:52:11,599
命名空间，这样每个团队都可以
namespaces so that each team can

2390
01:52:11,599 --> 01:52:14,000
在它们自己的命名空间中工作
work in their own namespace without

2391
01:52:14,000 --> 01:52:15,440
以免破坏了另一个deployment
disrupting the other

2392
01:52:15,440 --> 01:52:18,639
使用命名空间的另一个用例是
another use case for using namespaces is

2393
01:52:18,639 --> 01:52:20,880
假设你有一个集群
let's say you have one cluster and you

2394
01:52:20,880 --> 01:52:21,840
你想要让
want to host

2395
01:52:21,840 --> 01:52:24,960
生产环境和开发环境
both staging and development environment

2396
01:52:24,960 --> 01:52:26,880
在同一集群中，这么做的原因是
in the same cluster and the reason for

2397
01:52:26,880 --> 01:52:29,440
举个例子，如果你在用
that is that for example if you're using

2398
01:52:29,440 --> 01:52:33,360
比如nginx控制器或者elasticstack
something like nginx controller or elasticstack

2399
01:52:33,360 --> 01:52:35,599
用于日志管理，您可以
used for logging for example you can

2400
01:52:35,599 --> 01:52:39,440
将它部署在一个集群中并让两种环境都使用它
deploy it in one cluster and use it for both environments

2401
01:52:39,440 --> 01:52:41,199
这样你就不用部署
in that way you don't have to deploy

2402
01:52:41,199 --> 01:52:43,280
这些公共资源两遍
these common resources

2403
01:52:43,280 --> 01:52:46,000
在两个不同的集群中各部署一遍
twice in two different clusters so now

2404
01:52:46,000 --> 01:52:47,520
所以现在生产环境
the staging can use

2405
01:52:47,520 --> 01:52:49,520
可以用这些资源
both resources as well as the

2406
01:52:49,520 --> 01:52:51,199
开发环境也可以
development environment

2407
01:52:51,199 --> 01:52:54,080
使用命名空间的另一个用例是
another use case for using namespaces is

2408
01:52:54,080 --> 01:52:56,719
当您的应用程序使用蓝绿部署方法时
when you use blue-green deployment for application

2409
01:52:56,719 --> 01:53:00,639
即在同一个集群中，你想要
which means that in the same cluster you want to have

2410
01:53:00,639 --> 01:53:03,760
产品有两个不同版本
two different versions of production

2411
01:53:03,760 --> 01:53:06,960
当前生产版本处于激活状态
so the one that is active that is in production now

2412
01:53:06,960 --> 01:53:09,199
另一个是版本是
and another one that is going to be the

2413
01:53:09,199 --> 01:53:10,480
下一个生产版本
next production version

2414
01:53:10,480 --> 01:53:12,400
应用程序的版本
the versions of the applications in

2415
01:53:12,400 --> 01:53:14,159
对应蓝色和绿色
those blue and green production

2416
01:53:14,159 --> 01:53:15,920
命名空间将有所不同
namespaces will be different

2417
01:53:15,920 --> 01:53:18,560
但是和我们之前看到的一样
however the same as we saw before in

2418
01:53:18,560 --> 01:53:20,239
生产环境和开发环境的例子
staging and development

2419
01:53:20,239 --> 01:53:22,880
命名空间可能需要使用
this namespaces might need to use the

2420
01:53:22,880 --> 01:53:24,480
相同的资源
same resources

2421
01:53:24,480 --> 01:53:28,560
比如nginx控制器或elasticstack
like again nginx controller or elasticstack

2422
01:53:28,560 --> 01:53:30,960
这样它们就可以同时使用
and this way again they can both use

2423
01:53:30,960 --> 01:53:32,000
这种常见的
this common

2424
01:53:32,000 --> 01:53:34,560
无需设置的共享资源
shared resources without having to set

2425
01:53:34,560 --> 01:53:36,080
而无需建立一个单独的集群
up a separate cluster

2426
01:53:36,080 --> 01:53:39,280
还有一个使用命名空间的用例是
so one more use case for using namespaces

2427
01:53:39,280 --> 01:53:42,400
是当你在与多个团队合作时
is to limit the resources and

2428
01:53:42,400 --> 01:53:46,719
限制对命名空间资源的访问
access to namespaces when you're working with multiple teams

2429
01:53:46,719 --> 01:53:48,719
再一次，我们有这样一种情形
so again we have a scenario where we

2430
01:53:48,719 --> 01:53:51,199
集群有两个团队在一起工作
have two teams working in the same cluster

2431
01:53:51,199 --> 01:53:52,960
每一个都有自己的命名空间
and each one of them has their own

2432
01:53:52,960 --> 01:53:56,239
在这种情形下你可以
namespace so what you can do in this scenario is that

2433
01:53:56,239 --> 01:53:59,119
只给其它团队访问权限
you can give the teams access to only

2434
01:53:59,119 --> 01:54:02,320
所以他们只能 
their namespace so they can only be able to

2435
01:54:02,320 --> 01:54:06,239
在他们自己的名称空间中创建更新删除资源
create updates delete resources in their own namespace

2436
01:54:06,239 --> 01:54:09,599
但是他们在另一个命名空间里什么也做不了
but they can't do anything in the other name spaces

2437
01:54:09,599 --> 01:54:12,000
在这种情况下，你可以限制或甚至
in this way you even restrict or even

2438
01:54:12,000 --> 01:54:14,159
最小化一个团队
minimize the risk of one team

2439
01:54:14,159 --> 01:54:17,920
意外干扰另一个团队工作的风险
accidentally interfering with another team's work

2440
01:54:17,920 --> 01:54:20,480
所以每个人都有自己的安全的
so each one has their own secured

2441
01:54:20,480 --> 01:54:22,639
孤立的环境
isolated environment additional thing

2442
01:54:22,639 --> 01:54:23,440
此外
that you can do

2443
01:54:23,440 --> 01:54:26,639
你能在命名空间级别上做的是
on a namespace level is limit the resources

2444
01:54:26,639 --> 01:54:28,639
限制每个命名空间使用的资源
that each namespace consumes because if

2445
01:54:28,639 --> 01:54:30,159
假设你有一个集群
you have a cluster with

2446
01:54:30,159 --> 01:54:33,360
想给每个团队分配有限的资源
limited resources you want to give each team

2447
01:54:33,360 --> 01:54:37,280
想让他们的应用程序共享资源
a share of resources for their application

2448
01:54:37,280 --> 01:54:41,040
假设有一个团队消耗了太多资源
so if one team let's say consumes too much resources

2449
01:54:41,040 --> 01:54:44,239
然后其他团队的资源最终会少得多
then other teams will eventually have much less

2450
01:54:44,239 --> 01:54:46,320
他们的应用可能也就无法调度
and their applications may not schedule

2451
01:54:46,320 --> 01:54:47,920
因为那样集群资源就会耗尽
because the cluster will run out of the

2452
01:54:47,920 --> 01:54:50,400
所以你能做的就是
resources so what you can do is that

2453
01:54:50,400 --> 01:54:53,679
给每个命名空间定义资源配额
per namespace you can define resource quotas that

2454
01:54:53,679 --> 01:54:57,360
限制一个命名空间可以用多少cpu ram存储资源
limit how much cpu ram storage resources

2455
01:54:57,360 --> 01:55:00,080
所以我希望
one namespace can use so i hope walking

2456
01:55:00,080 --> 01:55:01,840
通过这些场景帮助您
through these scenarios helped you

2457
01:55:01,840 --> 01:55:04,800
分析在哪些用例，以及
analyze in which use cases and how you

2458
01:55:04,800 --> 01:55:07,040
在您的具体项目中应该如何使用命名空间
should use namespaces in your specific

2459
01:55:07,040 --> 01:55:08,239
有几个
project there are several

2460
01:55:08,239 --> 01:55:10,400
你应该考虑的特征
characteristics that you should consider

2461
01:55:10,400 --> 01:55:13,760
在决定如何分组和如何使用命名空间之前
before deciding how to group and how to use namespaces

2462
01:55:13,760 --> 01:55:16,159
第一个是你无法从另一个名称空间
the first one is that you can't access

2463
01:55:16,159 --> 01:55:17,760
访问大部分资源
most of the resources

2464
01:55:17,760 --> 01:55:21,199
例如如果你有
from another namespace so for example if you have

2465
01:55:21,199 --> 01:55:24,560
项目a中的ConfigMap
a configuration map in project a namespace

2466
01:55:24,560 --> 01:55:28,159
引用数据库的service
that references the database service you can't

2467
01:55:28,159 --> 01:55:31,679
你不能在项目b中使用这个ConfigMap
use that config map in project b namespace

2468
01:55:31,679 --> 01:55:33,520
但相反，你必须在项目b创建
but instead you will have to create the

2469
01:55:33,520 --> 01:55:34,719
相同的ConfigMap
same config map

2470
01:55:34,719 --> 01:55:38,560
也引用数据库的service
that also references the database service so each

2471
01:55:38,560 --> 01:55:41,760
所以每个命名空间将定义或必须定义
namespace will define or must define

2472
01:55:41,760 --> 01:55:45,199
它自己的ConfigMap，即使它们引用相同的service
its own config map even if it's the same reference

2473
01:55:45,199 --> 01:55:47,679
这同样适用于secret
and the same applies to secret so for

2474
01:55:47,679 --> 01:55:48,480
举个例子
example if you have

2475
01:55:48,480 --> 01:55:51,119
如果你有共享service的凭据
credentials of a shared service you will

2476
01:55:51,119 --> 01:55:52,960
必须在每个需要该凭据的命名空间
have to create that secret in each

2477
01:55:52,960 --> 01:55:56,480
都创造那个secret
namespace where you are going to need that however

2478
01:55:56,480 --> 01:56:00,159
然而可以跨命名空间共享的资源
a resource that you can share across namespaces

2479
01:56:00,159 --> 01:56:03,520
只有service，这是我们在之前的幻灯片中看到的
is service and that's what we saw in the previous slide

2480
01:56:03,520 --> 01:56:06,560
所以在项目b命名空间中的ConfigMap
so config map in project b namespace

2481
01:56:06,560 --> 01:56:08,960
引用service
references service that is going to be

2482
01:56:08,960 --> 01:56:10,719
最终在pod中使用
used eventually in a pod

2483
01:56:10,719 --> 01:56:12,560
它的工作原理是
and the way it works is that in a

2484
01:56:12,560 --> 01:56:15,440
在configmap的定义中，数据库url
configmap definition the database url

2485
01:56:15,440 --> 01:56:18,480
是它的名字，即mysql-service加上
in addition to its name which is mysql service

2486
01:56:18,480 --> 01:56:21,920
命名空间的名称
will have namespace at the end so using

2487
01:56:21,920 --> 01:56:25,040
使用这个url你可以从另一个命名空间
that url you can actually access services

2488
01:56:25,040 --> 01:56:27,840
访问service
from other namespaces which is a very

2489
01:56:27,840 --> 01:56:29,040
这是一件非常实际的事情
practical thing

2490
01:56:29,040 --> 01:56:31,760
这就是你可以从另一个命名空间
and this is how you can actually use

2491
01:56:31,760 --> 01:56:33,040
使用共享资源
shared resources like

2492
01:56:33,040 --> 01:56:36,480
如elasticsearch或nginx等
elasticsearch or nginx from

2493
01:56:36,480 --> 01:56:38,480
的方法
other namespaces and one more

2494
01:56:38,480 --> 01:56:40,000
另一个特点是
characteristic is that

2495
01:56:40,000 --> 01:56:41,920
我们看到了大部分的组件资源
we saw that most of the components

2496
01:56:41,920 --> 01:56:43,840
可以在一个命名空间中被创建
resources can be created

2497
01:56:43,840 --> 01:56:46,320
但是k8s中还有一些组件
uh within a namespace but there are some

2498
01:56:46,320 --> 01:56:48,719
是不可以放在命名空间中的
components in kubernetes they're not

2499
01:56:48,719 --> 01:56:52,639
它们基本上
namespaced so to say um so basically they live

2500
01:56:52,639 --> 01:56:56,400
在整个集群中全局生存
just globally in the cluster and you can't

2501
01:56:56,400 --> 01:56:59,760
不能把他们隔离起来，或者把他们放在某个命名空间中
isolate them or put them in a certain namespace and

2502
01:56:59,760 --> 01:57:02,159
这类资源的例子有volume或
examples of such resources are volume or

2503
01:57:02,159 --> 01:57:03,599
可持久化volume以及
persistent volume and

2504
01:57:03,599 --> 01:57:06,080
节点，所以基本上当你创建volume
node so basically when you create the

2505
01:57:06,080 --> 01:57:07,760
它是可被整个集群访问的
volume it's going to be accessible

2506
01:57:07,760 --> 01:57:09,760
因为
throughout the whole cluster because

2507
01:57:09,760 --> 01:57:11,760
它不在命名空间中
it's not in a namespace

2508
01:57:11,760 --> 01:57:14,320
你可以列出没有绑定到名称空间
and you can actually list components

2509
01:57:14,320 --> 01:57:16,400
的组件
they're not bound to a namespace

2510
01:57:16,400 --> 01:57:20,639
通过使用kubectl api-resources命名
using a command cubectl api resources

2511
01:57:20,639 --> 01:57:24,159
命名空间选项为false，同样地
namespaced false and the same way you can also

2512
01:57:24,159 --> 01:57:27,199
你也可以列出所有被绑定到一个命名空间的资源
list all the resources that are bound to a namespace

2513
01:57:27,199 --> 01:57:30,159
通过将namespace选项置为true，现在您已经
using namespace true so now that you've

2514
01:57:30,159 --> 01:57:32,320
了解了名称空间是什么
learned what the namespaces are

2515
01:57:32,320 --> 01:57:36,000
为什么要使用它们，在什么情况下使用它们有意义
why to use them in which cases it makes sense to

2516
01:57:36,000 --> 01:57:38,159
同时还有一些
use them in which way and also some

2517
01:57:38,159 --> 01:57:40,800
你应该考虑的特征
characteristics that you should consider

2518
01:57:40,800 --> 01:57:42,639
让我们来看看如何创建
let's actually see how to create

2519
01:57:42,639 --> 01:57:44,400
命名空间中的组件
components in a namespace

2520
01:57:44,400 --> 01:57:46,560
在上一个示例中
in the last example we've created

2521
01:57:46,560 --> 01:57:48,800
我们使用配置文件创建了组件
components using configuration files

2522
01:57:48,800 --> 01:57:52,080
但是没有定义一个命名空间
and nowhere there we have defined a namespace

2523
01:57:52,080 --> 01:57:54,080
默认情况下，如果你
so what happens is by default if you

2524
01:57:54,080 --> 01:57:56,719
不为组件提供命名空间
don't provide a namespace to a component

2525
01:57:56,719 --> 01:57:59,360
它在默认命名空间中创建它们
it creates them in a default namespace

2526
01:57:59,360 --> 01:58:02,080
如果我apply这个ConfigMap组件
so if i apply this config map component

2527
01:58:02,080 --> 01:58:03,920
现在我们来做一下
and let's do that actually right now so

2528
01:58:03,920 --> 01:58:07,119
kubectl apply -f configmap

2529
01:58:07,119 --> 01:58:10,800
如果我apply那个，接着做kubectl get
if i apply that and i do cube ctl get config map

2530
01:58:10,800 --> 01:58:14,239
我的ConfigMap是在默认命名空间中被创建的
my config map was created in a default namespace

2531
01:58:14,239 --> 01:58:18,639
注意，即使是用kubectl get configmap命令
and notice that even in the cubectl getconfigmap command i

2532
01:58:18,639 --> 01:58:21,679
也没有使用命名空间，因为
didn't use a namespace because cubectl

2533
01:58:21,679 --> 01:58:26,320
get或kubectl命令默认使用默认命名空间
get or cubectl commands they take the default namespace

2534
01:58:26,320 --> 01:58:30,639
所以kubectl get configmap实际上
as a default so kubectl get configmap is actually

2535
01:58:30,639 --> 01:58:36,880
和kubectl get configmap -n default一样
same as kubectl get configmap dash default namespace so

2536
01:58:36,880 --> 01:58:38,719
它们是相同的指令，只是简写的方式
these are the same commands it's just a

2537
01:58:38,719 --> 01:58:40,239
会默认采用
shortcut because it takes

2538
01:58:40,239 --> 01:58:42,639
默认(default)命名空间
default as a default namespace okay so

2539
01:58:42,639 --> 01:58:45,040
为了在特定的命名空间中
one way that i can create this config map

2540
01:58:45,040 --> 01:58:47,440
创建这个ConfigMap
in a specific namespace is using

2541
01:58:47,440 --> 01:58:49,440
可以用kubectl apply命令
kubectl apply command

2542
01:58:49,440 --> 01:58:53,280
但是要添加命名空间选项 --namespace
but adding flag namespace

2543
01:58:53,280 --> 01:58:56,159
接上命名空间的名字
and the namespace name so this will

2544
01:58:56,159 --> 01:58:57,440
这会在我的命名空间中
create config map

2545
01:58:57,440 --> 01:59:00,719
创建ConfigMap，这是一种方法
in my namespace and this is one way to

2546
01:59:00,719 --> 01:59:02,480
做这件事的另一种方法是
do it another way is

2547
01:59:02,480 --> 01:59:05,599
在配置文件内进行修改
inside the configuration file itself so

2548
01:59:05,599 --> 01:59:09,040
我可以调整这个configmap
i can adjust this configmap configuration file to

2549
01:59:09,040 --> 01:59:11,119
来包括关于
include the information about the

2550
01:59:11,119 --> 01:59:13,040
目标命名空间的信息
destination namespace itself

2551
01:59:13,040 --> 01:59:16,560
因此，我可以在元数据中添加一个namespace属性
so in the metadata i can add a namespace attribute

2552
01:59:16,560 --> 01:59:19,199
如果我apply这个配置文件
so if i apply this configuration file

2553
01:59:19,199 --> 01:59:22,560
再次使用kubectl apply，现在我想get这个
again using cubectl apply and now if i want to get the

2554
01:59:22,560 --> 01:59:23,920
刚刚创建的组件
component that i created

2555
01:59:23,920 --> 01:59:27,360
在这个特定的命名空间中
in this specific namespace then i have to add

2556
01:59:27,360 --> 01:59:31,360
就需要在kubectl get加上选项
the option or the flag to kubectl get command

2557
01:59:31,360 --> 01:59:33,840
因为就像我说的，默认情况下它会
because as i said by default it will

2558
01:59:33,840 --> 01:59:36,239
只检查默认命名空间
check only in the default namespace

2559
01:59:36,239 --> 01:59:39,199
因此，我建议
so i recommend using the namespace

2560
01:59:39,199 --> 01:59:41,199
在配置文件中使用命名空间
attribute in a configuration file

2561
01:59:41,199 --> 01:59:42,800
而不是提供到
instead of providing it

2562
01:59:42,800 --> 01:59:46,320
kubectl命令中
to the cube ctl command because one

2563
01:59:46,320 --> 01:59:49,119
因为一来，这是一个更好的书写方式
it's it's better documented so you know

2564
01:59:49,119 --> 01:59:51,920
只看配置文件就知道
by just looking at the configuration file

2565
01:59:51,920 --> 01:59:54,159
组件是在哪里创建的
where the component is getting created

2566
01:59:54,159 --> 01:59:55,199
这是重要的信息
because that could be an

2567
01:59:55,199 --> 01:59:58,320
二来
important information and second if

2568
01:59:58,320 --> 02:00:00,400
如果您正在使用自动部署
you're using automated deployment

2569
02:00:00,400 --> 02:00:01,920
来apply配置文件
where you're just applying the

2570
02:00:01,920 --> 02:00:04,159
这将是
configuration files then again this will

2571
02:00:04,159 --> 02:00:05,920
一个更方便的方法
be a more convenient way to do it

2572
02:00:05,920 --> 02:00:08,719
现在我们举个场景的例子
now if for example we take a scenario

2573
02:00:08,719 --> 02:00:11,040
一个团队有自己的名称空间
where one team gets their own namespace

2574
02:00:11,040 --> 02:00:12,560
并且必须
and that has to

2575
02:00:12,560 --> 02:00:15,280
完全在命名空间中工作
work entirely in the namespace it could

2576
02:00:15,280 --> 02:00:17,119
这是很烦人的
be pretty annoying to have to

2577
02:00:17,119 --> 02:00:20,639
如果在每个kubectl命令添加这个命名空间标记的话
add this namespace tag to every cubectl command

2578
02:00:20,639 --> 02:00:22,400
所以为了让它更方便
so in order to make it more convenient

2579
02:00:22,400 --> 02:00:23,920
有一个办法
there is a way to

2580
02:00:23,920 --> 02:00:27,360
更改这个默认或激活状态的名称空间
change this default or active namespace which is

2581
02:00:27,360 --> 02:00:30,400
到其它你选择的任何名称空间
default namespace to whatever namespace

2582
02:00:30,400 --> 02:00:34,159
kubernetes或kubectl并没有
you choose and kubernetes or cubactl doesn't have

2583
02:00:34,159 --> 02:00:36,239
提供任何开箱即用的工具
any out of the box solution for that but

2584
02:00:36,239 --> 02:00:37,679
但是有一种工具叫做kubens
there is a tool called

2585
02:00:37,679 --> 02:00:42,080
你可以安装它来解决
cubens or cubans and you have to install the tool

2586
02:00:42,080 --> 02:00:49,040
在mac上，我要执行brew install kubectx
so on mac so i'm going to execute brew install

2587
02:00:49,040 --> 02:00:52,239
这样就可以安装kubens工具
cube ctx so this will install

2588
02:00:52,239 --> 02:00:55,199
所以一旦我安装了kubens
cubans tool as well so once i have the

2589
02:00:55,199 --> 02:00:57,119
我就可以
kubens installed i can

2590
02:00:57,119 --> 02:01:00,239
执行kubens命令
just execute kubens command

2591
02:01:00,239 --> 02:01:01,840
这会给我一份所有
and this will give me a list of all the

2592
02:01:01,840 --> 02:01:04,400
命名空间的列表，高光显示的就是激活状态的命名空间
name spaces and highlight the one that is

2593
02:01:04,400 --> 02:01:06,960
这里是默认命名空间
active which is default right now and if

2594
02:01:06,960 --> 02:01:08,800
如果我想要改变激活状态的命名空间
i want to change the active

2595
02:01:08,800 --> 02:01:18,719
我可以执行kubens my-namespace
namespace i can do kubens my namespace

2596
02:01:18,719 --> 02:01:22,080
这将会改变激活状态的命名空间
and this will switch the active namespace so if i do

2597
02:01:22,080 --> 02:01:25,840
再做kubens，现在我看到激活的是my-namespace
kubens now i see that active one is my namespace

2598
02:01:25,840 --> 02:01:29,280
现在我可以执行kubectl命令
so now i can execute cubectl commands without

2599
02:01:29,280 --> 02:01:32,480
而不需要提供my-namespace命名空间了
providing mynamespace namespace

2600
02:01:32,480 --> 02:01:35,840
但很明显，如果你在命名空间中转换多次
but obviously if you switch a lot between the namespaces

2601
02:01:35,840 --> 02:01:39,920
这样就不太方便了
this will not be so much convenient

2602
02:01:39,920 --> 02:01:43,040
对于您自己的操作系统和环境
for your own operating system and

2603
02:01:43,040 --> 02:01:46,400
可能会有不同的安装过程
environment there will be different installation

2604
02:01:46,400 --> 02:01:48,800
所以我要在简介下方
process so i'm going to link the cube

2605
02:01:48,800 --> 02:01:53,000
加上kubectx安装指南的链接
ctx installation guide in the description below

2606
02:01:55,199 --> 02:01:56,480
在这段视频中，我们会讲
so in this video we're going to talk

2607
02:01:56,480 --> 02:01:58,239
什么是Ingress
about what ingress is

2608
02:01:58,239 --> 02:02:01,440
你应该如何使用它，还有
and how you should use it and also what are

2609
02:02:01,440 --> 02:02:04,560
Ingress有哪些不同的用例
different use cases for ingress so first

2610
02:02:04,560 --> 02:02:06,480
首先让我们想象一个简单的
of all let's imagine a simple

2611
02:02:06,480 --> 02:02:09,599
kubernetes集群，我们有一个应用程序的pod
kubernetes cluster where we have a pod

2612
02:02:09,599 --> 02:02:12,880
以及相应的my-app service
of my application and its corresponding

2613
02:02:12,880 --> 02:02:14,960
首先
service my app service so the first

2614
02:02:14,960 --> 02:02:16,960
你的ui应用需要
thing you need for your ui application

2615
02:02:16,960 --> 02:02:18,480
可通过浏览器访问
is to be accessible

2616
02:02:18,480 --> 02:02:23,119
所以为了外部请求能够
through browser right so for external requests to be able to

2617
02:02:23,119 --> 02:02:26,639
到达您的应用程序
reach your application so one way to do that

2618
02:02:26,639 --> 02:02:28,320
一个简单的方法是通过外部service
an easy way is through an external

2619
02:02:28,320 --> 02:02:32,880
也就是您可以使用
service where basically you can access the application using

2620
02:02:32,880 --> 02:02:35,920
http协议 + ip地址
http protocol the ip address of

2621
02:02:35,920 --> 02:02:39,280
加上节点和端口
the node and the port however this is

2622
02:02:39,280 --> 02:02:42,880
这有利于测试用例，如果你想
good for test cases and if you want to try

2623
02:02:42,880 --> 02:02:44,239
非常快地尝试一些东西的话
something very fast

2624
02:02:44,239 --> 02:02:47,599
但这不是最终的产品的样子
but this is not what the final product should look like

2625
02:02:47,599 --> 02:02:49,520
最终的成品应该是这样的
the final product should be like this so

2626
02:02:49,520 --> 02:02:50,880
你有一个给应用程序的域名
you have a domain name

2627
02:02:50,880 --> 02:02:53,920
你想要通过https实现安全连接
for application and you want a secure connection

2628
02:02:53,920 --> 02:02:56,719
实现这个的方式是
using https so the way to do that is

2629
02:02:56,719 --> 02:02:58,480
使用kubernetes组件
using kubernetes component

2630
02:02:58,480 --> 02:03:01,679
叫做ingress，你将会有my-app ingress
called ingress so you'll have my app

2631
02:03:01,679 --> 02:03:04,239
而不是外部service
ingress and instead of external service

2632
02:03:04,239 --> 02:03:07,840
相反你会有内部service
you would instead have an internal service so you

2633
02:03:07,840 --> 02:03:13,040
这样不会通过ip地址和端口开放您的应用程序
would not open your application through the ip address and the port

2634
02:03:13,040 --> 02:03:14,880
现在，如果请求来自浏览器
and now if the request comes from the

2635
02:03:14,880 --> 02:03:16,239
它会首先到达Ingress
browser it's going to

2636
02:03:16,239 --> 02:03:18,480
然后Ingress
first reach the ingress and ingress then

2637
02:03:18,480 --> 02:03:20,719
会把它重定向到内部Service
we'll redirect it to the internal service

2638
02:03:20,719 --> 02:03:22,719
然后它最终会到达pod
and then it will eventually end up with

2639
02:03:22,719 --> 02:03:26,400
现在我们看一看
the pod so now let's actually take a look and see how

2640
02:03:26,400 --> 02:03:28,239
外部service怎么配置
external service configuration

2641
02:03:28,239 --> 02:03:31,679
这样你就有一个实际的理解
looks like so that you have a practical understanding

2642
02:03:31,679 --> 02:03:34,960
你有一个负载均衡器类型的service
so you have the service which is of type load balancer

2643
02:03:34,960 --> 02:03:38,480
这意味着我们要向公众开放
this means we are opening it to public by assigning

2644
02:03:38,480 --> 02:03:41,599
通过给Service分配一个外部ip地址以及端口号
an external ip address to the service and this is

2645
02:03:41,599 --> 02:03:46,159
用户就可以通过你在这里指定的
the port number that user can access the application

2646
02:03:46,159 --> 02:03:49,920
外部ip地址以及端口号
at so basically the ip address the external ip address

2647
02:03:49,920 --> 02:03:53,199
访问应用程序
and the port number that you specify here

2648
02:03:53,199 --> 02:03:56,079
现在有了Ingress
now with ingress of course it looks

2649
02:03:56,079 --> 02:03:57,679
当然它看起来很不同
differently so let's go

2650
02:03:57,679 --> 02:03:59,679
看一下Ingress的语法
through the syntax of ingress basically

2651
02:03:59,679 --> 02:04:03,760
类型是Ingress而不是Service
you have a kind ingress instead of a service and in the

2652
02:04:03,760 --> 02:04:06,000
在spec部分
specification where the whole configuration

2653
02:04:06,000 --> 02:04:10,239
你有所谓的规则或者路由规则
happens you have so-called rules or routing rules

2654
02:04:10,239 --> 02:04:14,000
这基本上定义了域名地址
and this basically defines that the main address or

2655
02:04:14,000 --> 02:04:17,440
或者对该主机的所有请求都必须
all the requests to that host must be

2656
02:04:17,440 --> 02:04:20,960
转发给内部service
forwarded to an internal service

2657
02:04:20,960 --> 02:04:24,719
这就是用户在浏览器中要输入的域名
so this is the host that user will enter in the browser

2658
02:04:24,719 --> 02:04:28,320
在ingress中，用户这样定义映射
and in ingress users define a mapping so what happens when

2659
02:04:28,320 --> 02:04:31,360
如果向该主机发出请求出现了问题
that request to that host gets issued

2660
02:04:31,360 --> 02:04:34,079
内部就会将其重定向到service
you redirect it internally to a service

2661
02:04:34,079 --> 02:04:37,040
这里的路径是指url
the path here basically means the url path

2662
02:04:37,040 --> 02:04:40,079
域名之后的所有东西
so everything after the domain name

2663
02:04:40,079 --> 02:04:42,719
要在这条路径加上斜杠
so slash whatever path comes up to that

2664
02:04:42,719 --> 02:04:46,960
您可以在这里定义这些规则，稍后我们会看到一些
you can define those rules here and we'll see some different

2665
02:04:46,960 --> 02:04:49,599
关于路径配置的示例
examples of the path configuration later

2666
02:04:49,599 --> 02:04:52,239
正如你在这个配置中看到的
and as you see here in this configuration

2667
02:04:52,239 --> 02:04:55,760
我们用的是http协议
we have a http protocol so later

2668
02:04:55,760 --> 02:04:59,440
稍后在这段视频中，我将向你们展示如何配置https连接
in this video i'm going to show you how to configure https

2669
02:04:59,440 --> 02:05:02,560
通过使用Ingress组件
connection using ingress component so

2670
02:05:02,560 --> 02:05:06,239
现在在spec中我们没有任何关于安全连接的配置
right now in the specification we don't have anything configured

2671
02:05:06,239 --> 02:05:09,040
它只是http
for the secure connection it's just http

2672
02:05:09,040 --> 02:05:11,119
这里需要注意的一点是
and one thing to note here is that

2673
02:05:11,119 --> 02:05:14,320
这里的http属性
this http attribute here does not correspond

2674
02:05:14,320 --> 02:05:17,520
和这个并不对应，这是一个协议
to this one here this is a protocol that

2675
02:05:17,520 --> 02:05:21,040
传入的请求被转发到
the incoming request gets forwarded to

2676
02:05:21,040 --> 02:05:23,440
给内部service
to the internal service so this is

2677
02:05:23,440 --> 02:05:25,440
所以这实际上是第二步
actually the second step and

2678
02:05:25,440 --> 02:05:28,159
不要把它和这个弄混了
not to confuse it with this one and now

2679
02:05:28,159 --> 02:05:29,119
让我们看看
let's see

2680
02:05:29,119 --> 02:05:32,960
内部service与Ingress是怎么运作的
how the internal service to that ingress will look like

2681
02:05:32,960 --> 02:05:36,400
所以基本上backend就是目标
so basically backend is the target

2682
02:05:36,400 --> 02:05:39,520
传入的请求将被重定向到那里
where the request the incoming request will be redirected

2683
02:05:39,520 --> 02:05:41,599
serviceName应该对应内部service的名称
and the service name should correspond

2684
02:05:41,599 --> 02:05:43,920
如下所示
the internal service name like this

2685
02:05:43,920 --> 02:05:47,760
并且servicePort应该是内部Service的端口
and the port should be the internal service port

2686
02:05:47,760 --> 02:05:50,000
你可以看到在外部和内部service之间
and as you see here the only difference

2687
02:05:50,000 --> 02:05:52,239
唯一的区别
between the external and internal services

2688
02:05:52,239 --> 02:05:54,639
就是在内部service中我不再有
is that here in internal service i don't

2689
02:05:54,639 --> 02:05:56,719
第三个端口
have the third port which is the node

2690
02:05:56,719 --> 02:05:58,639
也就是从30000开始的节点端口
ports starting from thirty thousand we

2691
02:05:58,639 --> 02:06:00,320
现在在这里的属性
now have that attribute here

2692
02:06:00,320 --> 02:06:04,719
类型是默认类型，不是负载平衡器
and the type is a default type not a load balancer but

2693
02:06:04,719 --> 02:06:07,760
而是内部service类型，即集群ip
internal service type which is cluster ip so

2694
02:06:07,760 --> 02:06:11,520
这应该是一个有效的域名地址
this should be a valid domain address so you can just

2695
02:06:11,520 --> 02:06:14,719
只要满足有效，在这里可以写任何东西
write anything here it has to be first of all valid

2696
02:06:14,719 --> 02:06:18,159
你应该把域名映射到
and you should map that domain name to

2697
02:06:18,159 --> 02:06:21,679
节点的ip地址
ip address of the node that represents

2698
02:06:21,679 --> 02:06:24,159
也就是你的kubernetes集群的入口
an entry point to your kubernetes cluster

2699
02:06:24,159 --> 02:06:26,239
举个例子，如果你决定
so for example if you decide that one of

2700
02:06:26,239 --> 02:06:28,800
kubernetes集群中的一个节点
the nodes inside the kubernetes cluster

2701
02:06:28,800 --> 02:06:31,199
将会是入口，那么你
is going to be the entry point then you

2702
02:06:31,199 --> 02:06:34,079
应该把这个映射到该节点的ip地址
should map this to the ip address of that node or

2703
02:06:34,079 --> 02:06:36,480
我们待会儿就会看到
and we will see that later if you

2704
02:06:36,480 --> 02:06:40,000
如果你在kubernetes集群之外配置一个服务器
configure a server outside of the kubernetes cluster that

2705
02:06:40,000 --> 02:06:44,079
让它成为到你的kubernetes集群的入口点
will become the entry point to your kubernetes cluster then you

2706
02:06:44,079 --> 02:06:47,760
应该让这里的主机名映射到该服务器的ip地址
should map this host name to the ip address of that

2707
02:06:47,760 --> 02:06:49,760
现在我们学习了
server so now that we saw

2708
02:06:49,760 --> 02:06:52,079
kubernetes的Ingress组件的基本内容
what kubernetes ingress components looks

2709
02:06:52,079 --> 02:06:54,320
让我们看看如何
like let's see how to actually configure

2710
02:06:54,320 --> 02:06:57,760
在集群中配置Ingress
ingress in the cluster so remember this

2711
02:06:57,760 --> 02:06:59,679
记住这张我在一开始给你们看的图
diagram i showed you at the beginning

2712
02:06:59,679 --> 02:07:02,719
基本上你有一个pod、service
so basically you have a pod service and

2713
02:07:02,719 --> 02:07:04,480
和相应的Ingress
corresponding ingress

2714
02:07:04,480 --> 02:07:07,760
现在，如果你仅创建了这个ingress组件
now if you create that ingress component

2715
02:07:07,760 --> 02:07:10,880
是不足以
alone that won't be uh enough

2716
02:07:10,880 --> 02:07:13,920
使Ingress路由规则工作的
for ingress routing rules to work

2717
02:07:13,920 --> 02:07:17,920
此外你需要的是一个Ingress的实现
what you need in addition is an implementation for ingress

2718
02:07:17,920 --> 02:07:20,960
这个实现被称作Ingress控制器
and that implementation is called ingress controller

2719
02:07:20,960 --> 02:07:23,199
第一步是安装一个
so the step one will be to install an

2720
02:07:23,199 --> 02:07:25,040
Ingress控制器
ingress controllers which is

2721
02:07:25,040 --> 02:07:28,239
基本上是另一个或另一组
basically another pod or another set of

2722
02:07:28,239 --> 02:07:32,400
在您的kubernetes集群的节点上运行的pod
parts that run on your node in your kubernetes cluster

2723
02:07:32,400 --> 02:07:35,679
从而评价和处理Ingress规则
and thus evaluation and processing of ingress

2724
02:07:35,679 --> 02:07:39,760
所以我向您展示过的ingress组件的yaml文件
rules so the yaml file that i showed you with the

2725
02:07:39,760 --> 02:07:43,840
基本上就是这个部分
ingress component is basically this part right here

2726
02:07:43,840 --> 02:07:48,239
是要额外安装在kubernetes集群中的
and this has to be additionally installed in kubernetes cluster

2727
02:07:48,239 --> 02:07:51,280
所以什么是Ingress控制器，确切地说
so what is ingress controller um exactly

2728
02:07:51,280 --> 02:07:54,639
Ingress控制器的功能是
the function of ingress controller is to

2729
02:07:54,639 --> 02:07:58,079
评估所有你在集群中定义的规则
evaluate all the rules that you have defined in your cluster

2730
02:07:58,079 --> 02:08:01,840
用这种方式来管理所有的重定向
and this way to manage all the redirections so basically

2731
02:08:01,840 --> 02:08:05,920
这将是你配置过的
this will be the entry point in the cluster for all the

2732
02:08:05,920 --> 02:08:09,599
对集群内所有域名和子域名请求的入口点
requests to that domain or subdomain rules that you've

2733
02:08:09,599 --> 02:08:13,119
它将评估所有规则
configured and this will evaluate all the rules because

2734
02:08:13,119 --> 02:08:16,320
因为你可能有50条规则或者50个Ingress组件
you may have 50 rules or 50 ingress

2735
02:08:16,320 --> 02:08:18,880
在您的集群中
components created in your cluster it

2736
02:08:18,880 --> 02:08:21,679
它会评估所有的规则并在此基础上决定
will evaluate all the rules and decide based on that

2737
02:08:21,679 --> 02:08:26,000
哪条转发规则适用于此具体的请求
which forwarding rule applies for that specific request

2738
02:08:26,000 --> 02:08:29,199
为了安装这个Ingress的实现
so in order to install this implementation of

2739
02:08:29,199 --> 02:08:31,199
进入你的集群，你必须
ingress in your cluster you have to

2740
02:08:31,199 --> 02:08:36,320
在很多不同的第三方实现中选择
decide which one of many different third-party implementations

2741
02:08:36,320 --> 02:08:38,400
我会在简介中
you want to choose from i'll put a link

2742
02:08:38,400 --> 02:08:40,639
放一个链接，里面是
of the whole list in the description where you see

2743
02:08:40,639 --> 02:08:43,280
不同种类的Ingress控制器的列表
different kinds of ingress controllers

2744
02:08:43,280 --> 02:08:44,480
你可以从中选择
you can choose from

2745
02:08:44,480 --> 02:08:46,159
有一个来自kubernetes自己的
there is one from kubernetes itself

2746
02:08:46,159 --> 02:08:48,239
叫做kubernetes nginx ingress控制器
which is kubernetes nginx

2747
02:08:48,239 --> 02:08:50,079
但是还有其他的
ingress controller but there are others

2748
02:08:50,079 --> 02:08:54,320
一旦你在集群中安装了Ingress控制器
as well so once you install ingress controller in your cluster

2749
02:08:54,320 --> 02:08:55,440
你可以
you're good to go

2750
02:08:55,440 --> 02:08:59,520
创造Ingress，整个配置就可以工作了
create ingress roles and the whole configuration is going to work

2751
02:08:59,520 --> 02:09:02,159
现在我已经向你们展示了如何
so now that i've shown you how ingress

2752
02:09:02,159 --> 02:09:04,079
在kubernetes集群中使用Ingress
can be used in a kubernetes cluster

2753
02:09:04,079 --> 02:09:07,840
有一件事我认为是很重要的
there is one thing that i think is important to understand

2754
02:09:07,840 --> 02:09:10,639
就设置整个集群
in terms of setting up the whole cluster

2755
02:09:10,639 --> 02:09:13,119
能够接收外部请求而言
to be able to receive external requests

2756
02:09:13,119 --> 02:09:16,400
首先你要考虑的是
now first of all you have to consider

2757
02:09:16,400 --> 02:09:18,000
kubernetes所在的环境
the environment where your kubernetes

2758
02:09:18,000 --> 02:09:21,520
如果您正在使用一些云服务供应商
cluster is running if you are using some cloud

2759
02:09:21,520 --> 02:09:24,800
比如亚马逊网络服务
service provider like amazon web services

2760
02:09:24,800 --> 02:09:28,560
谷歌云以及更多
google cloud lino there are a couple more that have

2761
02:09:28,560 --> 02:09:31,599
它们都有现成的kubernetes解决方案
out of the box kubernetes solutions um

2762
02:09:31,599 --> 02:09:34,800
或者它们有自己的虚拟化、负载均衡等等
or they have their own virtualized load balances

2763
02:09:34,800 --> 02:09:37,840
你的集群配置会
etc your cluster configuration would

2764
02:09:37,840 --> 02:09:39,280
看起来像这样
look something like this

2765
02:09:39,280 --> 02:09:41,920
你会有一个云负载均衡器
so you would have a cloud load balancer

2766
02:09:41,920 --> 02:09:46,800
这是由云供应商特别实现的
that is specifically implemented by that cloud provider and

2767
02:09:46,800 --> 02:09:50,400
从浏览器来的外部请求
external requests coming from the browser will first

2768
02:09:50,400 --> 02:09:53,119
将首先到达负载均衡器
hit the load balancer and that load

2769
02:09:53,119 --> 02:09:54,880
负载均衡器将重定向该请求
balancer then will redirect

2770
02:09:54,880 --> 02:09:58,880
到Ingress控制器
the request to ingress controller now this is not

2771
02:09:58,880 --> 02:10:00,719
这不是唯一的方式
the only way to do it even in cloud

2772
02:10:00,719 --> 02:10:02,480
即使是在云端
environment you can do it in

2773
02:10:02,480 --> 02:10:05,840
也有很多不同的方式，但是这个是最常见的策略
in a couple of different ways but this is one of the most common

2774
02:10:05,840 --> 02:10:09,199
采用云供应商做这个的优势
uh strategies an advantage of

2775
02:10:09,199 --> 02:10:13,199
是你不必
using cloud provider for that is that you don't have to

2776
02:10:13,199 --> 02:10:16,400
自己实现一个负载均衡器
implement a load balancer yourself so

2777
02:10:16,400 --> 02:10:19,520
只用付出最少的努力
with minimal effort probably on most

2778
02:10:19,520 --> 02:10:21,520
大多数云供应商会给您提供负载均衡器
cloud providers you will have the load

2779
02:10:21,520 --> 02:10:23,119
启动并运行
balancer up and running

2780
02:10:23,119 --> 02:10:25,679
并准备好接受那些请求
and ready to receive those requests and

2781
02:10:25,679 --> 02:10:29,040
然后把这些请求转发给你的kubernetes集群
forward those requests then to your kubernetes cluster

2782
02:10:29,040 --> 02:10:32,320
这是很简单的配置
so very easy setup now if you're

2783
02:10:32,320 --> 02:10:36,000
如果你要将kubernetes集群部署到裸机环境
deploying your kubernetes cluster on a bare metal environment

2784
02:10:36,000 --> 02:10:38,239
那你就得自己做那部分
then you would have to do that part

2785
02:10:38,239 --> 02:10:40,880
所以基本上你必须自己配置
yourself so basically you would have to configure

2786
02:10:40,880 --> 02:10:43,920
kubernetes集群的某种入口点
some kind of entry point to your kubernetes cluster yourself

2787
02:10:43,920 --> 02:10:45,920
有一大堆不同的方式做这件事
and there's a whole list of different

2788
02:10:45,920 --> 02:10:49,199
我要把它们放在简介中
ways to do that and i'm going to put that also in the description

2789
02:10:49,199 --> 02:10:53,040
但一般来说，要么在集群里
but generally speaking either inside of a cluster

2790
02:10:53,040 --> 02:10:56,880
或者在集群用一个单独的服务器
or outside as a separate server

2791
02:10:56,880 --> 02:10:59,440
你必须提供一个入口点
you will have to provide an entry point

2792
02:10:59,440 --> 02:11:03,920
其中一个类型是外部代理服务器
and one of those types is an external proxy server

2793
02:11:03,920 --> 02:11:08,079
可以是软件或硬件解决方案
which can be a software or hardware solution

2794
02:11:08,079 --> 02:11:12,480
它将承担负载均衡器和集群入口点的角色
that will take the role of that load balancer and entry point

2795
02:11:12,480 --> 02:11:15,760
所以基本上这意味着
to your cluster so basically what this would mean

2796
02:11:15,760 --> 02:11:19,199
你会有一个单独的服务器
is that you will have a separate server

2797
02:11:19,199 --> 02:11:20,960
你会给它一个公共ip地址
and you would give this a public ip

2798
02:11:20,960 --> 02:11:23,360
你可以开发端口
address and you would open the ports

2799
02:11:23,360 --> 02:11:27,040
从而让请求被接受
in order for the requests to be accepted

2800
02:11:27,040 --> 02:11:30,159
然后这个代理服务器就会
and this proxy server then will act

2801
02:11:30,159 --> 02:11:32,480
作为集群的入口点
as an entry point to your cluster so

2802
02:11:32,480 --> 02:11:34,239
成为唯一一个
this will be the only one

2803
02:11:34,239 --> 02:11:36,639
可以从外部访问的服务器
accessible externally so none of the

2804
02:11:36,639 --> 02:11:39,119
所以kubernetes集群中的其他服务器没有可以
servers in your kubernetes cluster will have

2805
02:11:39,119 --> 02:11:41,840
可公开访问的ip地址
publicly accessible ip address which is

2806
02:11:41,840 --> 02:11:44,560
显然这是一个很安全的实践
obviously a very good security practice

2807
02:11:44,560 --> 02:11:47,760
因此，所有请求都将进入代理服务器
so all the requests will enter the proxy server

2808
02:11:47,760 --> 02:11:49,760
然后将重定向请求
and that will then redirect the request

2809
02:11:49,760 --> 02:11:51,440
到Ingress控制器
to ingress controller

2810
02:11:51,440 --> 02:11:54,639
然后Ingress控制器会决定
and ingress controller will then decide which

2811
02:11:54,639 --> 02:11:58,480
哪一个规则适用于这个特定的请求
ingress rule applies to that specific request

2812
02:11:58,480 --> 02:12:01,920
然后全部内部请求转发将会发生
and the whole internal request forwarding will happen

2813
02:12:01,920 --> 02:12:05,599
就像我说的，有不同的方法来配置和建立它
so as i said there are different ways to configure that

2814
02:12:05,599 --> 02:12:08,800
取决于你在使用哪个环境
and to set it up depending on which environment you are

2815
02:12:08,800 --> 02:12:11,440
还有你选择的方法
and also which approach you choose but i

2816
02:12:11,440 --> 02:12:12,960
但我认为这是一个
think it's a very important concept to

2817
02:12:12,960 --> 02:12:14,320
理解整个集群配置的非常重要的概念
understand how the whole

2818
02:12:14,320 --> 02:12:18,000
在我的例子中
cluster setup works so in my case since i'm using

2819
02:12:18,000 --> 02:12:21,920
我在笔记本电脑上用minikube来演示这一切
a mini cube to demonstrate all this on my laptop

2820
02:12:21,920 --> 02:12:24,320
设置将非常简单
the setup will be pretty easy and even

2821
02:12:24,320 --> 02:12:27,760
尽管它可能并不完全适用于你的集群设置
though this might not apply exactly to your cluster setting

2822
02:12:27,760 --> 02:12:31,040
不过在实践中你会看到这些东西是怎么工作的
still you will see in practice how all these things work

2823
02:12:31,040 --> 02:12:34,079
第一件事是在minikube中安装ingress控制器
so the first thing is to install ingress controller

2824
02:12:34,079 --> 02:12:37,840
方法是
in mini cube and the way to do that is by

2825
02:12:37,840 --> 02:12:41,199
执行minikube addons enable ingress命令
executing mini cube add-ons enable

2826
02:12:41,199 --> 02:12:45,599
这会自动配置
ingress so what this does is automatically configures

2827
02:12:45,599 --> 02:12:48,639
或者自动启动ingress控制器的
or automatically starts the kubernetes

2828
02:12:48,639 --> 02:12:52,400
k8s nginx实现
nginx implementation of ingress controller so that's one

2829
02:12:52,400 --> 02:12:54,639
这是众多第三方实现中的一种
of the many third-party implementations

2830
02:12:54,639 --> 02:12:56,400
你也可以
which you can also

2831
02:12:56,400 --> 02:12:58,480
在生产环境中安全使用它
safely use in production environments

2832
02:12:58,480 --> 02:13:00,639
而不仅仅是在迷你方块中
not just mini cube but this is what

2833
02:13:00,639 --> 02:13:04,400
minikube实际上提供给你
minicube actually offers you out of the box so with one

2834
02:13:04,400 --> 02:13:06,800
一个简单的现成的命令
simple command ingress controller will

2835
02:13:06,800 --> 02:13:09,119
让Ingress控制器在集群中被配置
be configured in your cluster

2836
02:13:09,119 --> 02:13:13,599
如果你在kube-system命名空间执行kubectl get pod
and if you do cube ctl get pod in a cube system namespace

2837
02:13:13,599 --> 02:13:16,719
你会看到nginx ingress controller pod已经在集群中运行了
you will see the nginx ingress controller pod

2838
02:13:16,719 --> 02:13:19,920
所以一旦安装了Ingress控制器
running in your cluster so once i have ingress controller

2839
02:13:19,920 --> 02:13:22,239
现在我可以创建一个Ingress规则
installed now i can create an ingress

2840
02:13:22,239 --> 02:13:24,079
可以由控制器评估
rule that the controller can

2841
02:13:24,079 --> 02:13:27,440
移步命令行
evaluate so let's actually head over to the command line

2842
02:13:27,440 --> 02:13:29,040
我要在那里创建用于kubernetes面板组件
where i'm going to create ingress rule

2843
02:13:29,040 --> 02:13:31,520
的Ingress规则
for kubernetes dashboard component

2844
02:13:31,520 --> 02:13:35,360
在我的minikube集群中
so in my minicube cluster i have

2845
02:13:35,360 --> 02:13:38,320
有kubernetes面板
kubernetes dashboard which is right now

2846
02:13:38,320 --> 02:13:40,239
现在还无法被外部访问
not accessible externally

2847
02:13:40,239 --> 02:13:42,480
所以我要做的是既然我已经
so what i'm gonna do is since i already

2848
02:13:42,480 --> 02:13:45,520
为kubernetes面板提供了内部service
have internal service for kubernetes dashboard

2849
02:13:45,520 --> 02:13:48,560
以及一个相应的端口
and a port for that i'm going to

2850
02:13:48,560 --> 02:13:50,320
我就要为面板配置Ingress规则
configure an ingress rule

2851
02:13:50,320 --> 02:13:53,920
这样我就能使用一些域名
for the dashboard so i can access it from a browser

2852
02:13:53,920 --> 02:13:57,360
通过浏览器访问它了
using some domain name

2853
02:13:57,360 --> 02:14:02,880
这展示了我的所有在k8s面板的
so i'm gonna so this shows me all the components that

2854
02:14:02,880 --> 02:14:04,639
组件
i have in k8s dashboard

2855
02:14:04,639 --> 02:14:07,760
既然我已经有给k8s面板的内部sersvice
and since i already have uh internal service

2856
02:14:07,760 --> 02:14:11,280
pod也正在运行
for kubernetes dashboard and the pod that's running

2857
02:14:11,280 --> 02:14:14,719
我现在可以创建一个Ingress规则
i can now create an ingress uh rule

2858
02:14:14,719 --> 02:14:18,639
以便通过一些主机名访问k8s面板
in order to access the kubernetes dashboard using some

2859
02:14:18,639 --> 02:14:21,599
让我们继续
host name so let's go ahead and do that

2860
02:14:21,599 --> 02:14:23,440
所以我要给k8s面板创建一个Ingress
so i'm gonna create an ingress

2861
02:14:23,440 --> 02:14:27,599
kubernetes的仪表盘，这些是元数据
for kubernetes dashboard um so these are just metadata

2862
02:14:27,599 --> 02:14:29,440
名字是dashboard-ingress
the name is going to be dashboard

2863
02:14:29,440 --> 02:14:31,679
命名空间将会是
ingress and the namespace is going to be

2864
02:14:31,679 --> 02:14:34,480
和service以及pod在同一个命名空间中
in the same namespace as the service and pod

2865
02:14:34,480 --> 02:14:37,520
在spec中，我们会定义规则
so in the specification we are going to define

2866
02:14:37,520 --> 02:14:40,719
第一条规则
the rules so the first rule

2867
02:14:40,719 --> 02:14:43,920
是我要调用的主机名
is the host name i'm just gonna

2868
02:14:43,920 --> 02:14:50,480
我要定义dashboard.com
call i'm gonna define dashboard.com

2869
02:14:50,480 --> 02:14:55,599
以及http转发到内部service
and the http forwarding to internal service

2870
02:14:55,599 --> 02:14:59,280
path
path let's leave it at all path

2871
02:14:59,280 --> 02:15:02,000
然后就是service的backend
and this is the backend of the service

2872
02:15:02,000 --> 02:15:03,760
所以serviceName将是
so service name will be

2873
02:15:03,760 --> 02:15:09,760
我们在这里看到的service的名字
what we saw here so this is the service name

2874
02:15:09,760 --> 02:15:13,920
以及servicePort
and service port

2875
02:15:13,920 --> 02:15:18,320
这里service监听的端口80
is where the service listens so this is actually 80

2876
02:15:18,320 --> 02:15:21,280
就在这里
right here and this will be it that's

2877
02:15:21,280 --> 02:15:22,639
这就是Ingress的配置
the ingress configuration

2878
02:15:22,639 --> 02:15:25,920
转发所有被指向dashboard.com
for uh forwarding every request

2879
02:15:25,920 --> 02:15:29,520
的请求
that is directed to dashboard.com

2880
02:15:29,520 --> 02:15:32,480
转发到内部kubernetes dashboard service
to internal kubernetes dashboard service

2881
02:15:32,480 --> 02:15:34,159
我们知道它是内部的
and we know it's internal because its

2882
02:15:34,159 --> 02:15:36,079
因为它类型为“ClusterIp”
type is cluster ip so

2883
02:15:36,079 --> 02:15:39,119
没有外部ip地址
no external ip address so obviously

2884
02:15:39,119 --> 02:15:42,960
显然我只是编了个主机名dashboard.com
i just made up host name dashboard.com

2885
02:15:42,960 --> 02:15:46,560
它没有注册在任何地方
it's not registered anywhere and i also didn't

2886
02:15:46,560 --> 02:15:50,000
我也没有配置任意ip地址
configure anywhere which ip address

2887
02:15:50,000 --> 02:15:52,480
用于主机名的解析
this host name should resolve to and

2888
02:15:52,480 --> 02:15:55,199
而这是你必须配置的东西
this is something that you will always have to configure

2889
02:15:55,199 --> 02:15:59,040
首先让我们来创建这个ingress规则
so first of all let's actually create that ingress rule

2890
02:15:59,040 --> 02:16:02,480
输入kubectl apply
so kubectl apply

2891
02:16:02,480 --> 02:16:06,639
文件名为dashboard-ingress.yaml
and it's called dashboard ingress

2892
02:16:06,639 --> 02:16:10,480
可以看到Ingress被创建了
yaml see ingress was created so if i do

2893
02:16:10,480 --> 02:16:18,239
所以如果我在命名空间get ingress
get ingress in the namespace

2894
02:16:18,239 --> 02:16:21,280
我应该在这里看到我的ingress
i should see my ingress here and as you see

2895
02:16:21,280 --> 02:16:23,520
如你所见，地址现在是空的，因为它需要
address is now empty because it takes a

2896
02:16:23,520 --> 02:16:24,719
还有一点时间
little bit of time to

2897
02:16:24,719 --> 02:16:28,159
将地址分配给ingress
assign the address um to ingress

2898
02:16:28,159 --> 02:16:30,560
所以我们得等着
so we'll have to wait for that to get

2899
02:16:30,560 --> 02:16:34,800
等着ip地址映射到这个主机
the ip address that will map to this host

2900
02:16:34,800 --> 02:16:38,399
所以我要watch一下
so i'm just gonna watch this

2901
02:16:38,399 --> 02:16:41,280
现在看到那个地址是被分配了
and it's i see that address was assigned

2902
02:16:41,280 --> 02:16:43,519
所以我现在要做的是
so what i'm gonna do now is that i'm gonna

2903
02:16:43,519 --> 02:16:55,040
把这个地址写进/etc/hosts文件
take that address and in my etc hosts file

2904
02:16:55,040 --> 02:16:58,080
写在最后，定义这个映射
at the end i'm going to define that mapping

2905
02:16:58,080 --> 02:17:05,120
这样ip地址就会映射到dashboard.com，可以本地工作了
so that ip address will be mapped to dashboard.com and again this works

2906
02:17:05,120 --> 02:17:06,240
如果我要
locally if i'm going to

2907
02:17:06,240 --> 02:17:08,639
在浏览器中输入dashboard.com
type dashboard.com in the browser this

2908
02:17:08,639 --> 02:17:11,200
就会去被映射的ip地址
will be the ip address that it's going to be

2909
02:17:11,200 --> 02:17:15,359
它基本上意味着
mapped to which basically means that the

2910
02:17:15,359 --> 02:17:19,120
进入我的minikube集群的请求将会
request will come in to my mini cube cluster will be

2911
02:17:19,120 --> 02:17:22,000
移交给Ingress控制器
handed over to ingress controller and ingress

2912
02:17:22,000 --> 02:17:23,840
接着Ingress控制器将会评估
controller then will go and evaluate

2913
02:17:23,840 --> 02:17:25,840
我在这里定义的规则
this rule that i've defined here

2914
02:17:25,840 --> 02:17:29,439
并将请求转发给service
and forward that request to service

2915
02:17:29,439 --> 02:17:31,599
这就是我们需要的配置
so this is all the configuration we need

2916
02:17:31,599 --> 02:17:38,880
现在我要输入dashboard.com
so now i'm gonna go and enter dashboard.com

2917
02:17:38,880 --> 02:17:42,479
我将在这里看到我的kubernetes面板
and i will see my kubernetes dashboard here

2918
02:17:42,479 --> 02:17:46,800
Ingress还有一个叫默认backend的东西
so ingress also has something called a default backend

2919
02:17:46,800 --> 02:17:53,679
如果我做kubectl describe ingress
so if i do cubectl describe ingress

2920
02:17:53,679 --> 02:18:00,160
接上ingress的名字和命名空间
the name of the ingress and the namespace

2921
02:18:00,160 --> 02:18:04,160
我会得到这个输出
i'll get this output and here

2922
02:18:04,160 --> 02:18:07,200
有一个名为default backend的属性
there is an attribute called default backend

2923
02:18:07,200 --> 02:18:11,040
映射到默认的http后端，端口80
that maps to default http backend

2924
02:18:11,040 --> 02:18:14,000
这意味着
port 80. so what this means is that

2925
02:18:14,000 --> 02:18:15,679
每当请求进入
whenever a request comes into the

2926
02:18:15,679 --> 02:18:17,120
kubernetes集群
kubernetes cluster

2927
02:18:17,120 --> 02:18:19,760
它没有映射到任何后端
that is not mapped to any backend so

2928
02:18:19,760 --> 02:18:20,960
也就没有规则
there is no rule

2929
02:18:20,960 --> 02:18:24,399
将请求映射到其它service
for mapping that request to an to a service

2930
02:18:24,399 --> 02:18:27,760
那么这个默认后端就会
then this default backend is used

2931
02:18:27,760 --> 02:18:31,359
被用于处理这个请求
to handle that request so obviously

2932
02:18:31,359 --> 02:18:35,519
所以很明显，如果您没有在集群中创建或定义此service
if you don't have this service created or defined

2933
02:18:35,519 --> 02:18:38,160
kubernetes将尝试
in your cluster kubernetes will try to

2934
02:18:38,160 --> 02:18:40,399
转发给它找不到的service
forward it to the service it won't find it

2935
02:18:40,399 --> 02:18:44,479
你会得到一些默认错误响应
and you would get some default error response

2936
02:18:44,479 --> 02:18:48,479
例如，如果我输入一些
so for example if i entered some

2937
02:18:48,479 --> 02:18:50,719
我没有配置的路径
path that i haven't configured i just

2938
02:18:50,719 --> 02:18:52,559
就会找不到页面
get page not found

2939
02:18:52,559 --> 02:18:55,679
一个很好的用法是
so a good usage for that is to define

2940
02:18:55,679 --> 02:18:58,800
当页面无法找到时，定义自定义错误消息
custom error messages when a page isn't found

2941
02:18:58,800 --> 02:19:01,120
当有请求时，你可以或者程序可以
when a request comes in that you can

2942
02:19:01,120 --> 02:19:03,519
处理错误消息
handle or the application can handle

2943
02:19:03,519 --> 02:19:07,040
这样用户仍然可以看到一些有意义的错误消息
so that users still see some meaningful error message

2944
02:19:07,040 --> 02:19:08,960
或者只是一个定制页面
or just a custom page where you can

2945
02:19:08,960 --> 02:19:10,960
将它们重定向到您的主页
redirect them to your home page

2946
02:19:10,960 --> 02:19:14,160
或者类似的东西
or something like this so all you have to do is

2947
02:19:14,160 --> 02:19:17,599
要做到这些你需要创建一个具有名字的内部service
create an internal service with the same name

2948
02:19:17,599 --> 02:19:21,359
也就是default-http-backend以及端口号80
so default http backend and the port number

2949
02:19:21,359 --> 02:19:24,479
还可以创建一个pod或应用程序
and also create a pod or application

2950
02:19:24,479 --> 02:19:29,760
发送那个自定义错误消息响应
that sends that error custom error message response

2951
02:19:29,760 --> 02:19:31,679
所以到目前为止，我已经向你们展示了
so till now i have shown you what

2952
02:19:31,679 --> 02:19:33,760
什么是Ingress，如何使用它
ingress is and how you can use it i've

2953
02:19:33,760 --> 02:19:36,800
我还演示了如何在minikube中创建一个ingress规则
also shown you a demo of how to create an ingress rule

2954
02:19:36,800 --> 02:19:39,920
但我们只使用了
in minicube but we've used only

2955
02:19:39,920 --> 02:19:43,599
一个非常基本的ingress yaml配置
a very basic ingress yaml configuration

2956
02:19:43,599 --> 02:19:47,599
只是简单的转发到一个内部service
just a simple forwarding to one internal service

2957
02:19:47,599 --> 02:19:50,800
只有一条路径，但你还可以
with one path but you can do much

2958
02:19:50,800 --> 02:19:54,479
做更多关于Ingress配置的事情
more with ingress configuration than just

2959
02:19:54,479 --> 02:19:58,080
相比于基本的转发。在下一个部分
basic uh forwarding and in the next section

2960
02:19:58,080 --> 02:20:01,120
我们会讲更多的用例
we're gonna go through more use cases of

2961
02:20:01,120 --> 02:20:05,600
关于你如何给kubernetes集群中的应用程序
how you can define more fine granular routing for

2962
02:20:05,600 --> 02:20:08,319
定义更细粒度的路由
applications inside kubernetes cluster

2963
02:20:08,319 --> 02:20:11,840
首先是给相同主机
so the first thing is defining multiple

2964
02:20:11,840 --> 02:20:14,960
定义多条路径
paths of the same host so consider

2965
02:20:14,960 --> 02:20:18,399
考虑如下用例，谷歌有一个域名
following use case google has

2966
02:20:18,399 --> 02:20:22,000
却提供了众多服务
one domain but has many services that it offers

2967
02:20:22,000 --> 02:20:23,840
例如，如果你有一个谷歌账户
so for example if you have a google

2968
02:20:23,840 --> 02:20:25,760
你可以使用它的分析
account you can use its analytics

2969
02:20:25,760 --> 02:20:28,880
你可以用它购物，用它的日历
you can use it shopping you you have a calendar

2970
02:20:28,880 --> 02:20:31,439
你有一个gmail等等这些都是
you have a gmail etc so all of these are

2971
02:20:31,439 --> 02:20:33,520
单独的应用程序
separate applications

2972
02:20:33,520 --> 02:20:36,479
却可以通过相同的域名访问
that are accessible with the same domain

2973
02:20:36,479 --> 02:20:39,200
所以假设您有一个应用程序
so consider you have an application that

2974
02:20:39,200 --> 02:20:40,800
与之类似
does something similar

2975
02:20:40,800 --> 02:20:43,920
所以你提供了两个不同的应用程序
so you offer two separate applications

2976
02:20:43,920 --> 02:20:46,960
他们是同一个生态系统的两部分，但你仍然
they're part of the same ecosystem but you still

2977
02:20:46,960 --> 02:20:50,160
想要把它们放在不同的url上
want to have them on separate urls so what you

2978
02:20:50,160 --> 02:20:53,840
所以你可以在规则中可以定义主机myapp.com
can do is that in rules you can define the host

2979
02:20:53,840 --> 02:20:56,960
而在路径部分
which is myapp.com and in the path

2980
02:20:56,960 --> 02:21:00,399
可以定义多条路径
section you can define multiple path so if user

2981
02:21:00,399 --> 02:21:03,439
如果用户想要访问你的analytics应用程序
wants to access your analytics application

2982
02:21:03,439 --> 02:21:07,280
他们必须进入myapp.com/analytics
then they have to enter myapp.com analytics

2983
02:21:07,280 --> 02:21:10,880
然后将请求转发给内部的
and that will forward the request to internal and

2984
02:21:10,880 --> 02:21:14,880
analytic service及其pod，如果他们想要
analytic service and the pod or if they want to

2985
02:21:14,880 --> 02:21:17,760
访问shopping应用程序
access the shopping application then the

2986
02:21:17,760 --> 02:21:20,560
那么url将是myapp.com/shopping
url for that would be myapp.com

2987
02:21:20,560 --> 02:21:23,040
这样你就可以
shopping so this way you can do

2988
02:21:23,040 --> 02:21:24,960
利用同一台主机的一个ingress
forwarding with one ingress

2989
02:21:24,960 --> 02:21:27,120
通过多条路径
of the same host to multiple

2990
02:21:27,120 --> 02:21:28,560
转发到多个应用程序
applications using

2991
02:21:28,560 --> 02:21:31,920
另一个用例是
multiple path another use case is

2992
02:21:31,920 --> 02:21:35,359
不使用url
when instead of using urls

2993
02:21:35,359 --> 02:21:39,200
区分可访问的不同的应用程序
to make different applications accessible

2994
02:21:39,200 --> 02:21:42,000
有些公司使用子域名
some companies use sub-domains so

2995
02:21:42,000 --> 02:21:46,160
不用myapp.com/analytics这样的分支
instead of having myapp.com analytics they create

2996
02:21:46,160 --> 02:21:50,160
而是用子域名analytics.myapp.com取代
a sub-domain analytics.myapp.com

2997
02:21:50,160 --> 02:21:53,200
所以如果你的应用程序是这样配置的
so if you have your application configured that way

2998
02:21:53,200 --> 02:21:55,120
您的配置将像这样
your configuration will look like this

2999
02:21:55,120 --> 02:21:56,960
不再像前面的例子
so instead of having one host

3000
02:21:56,960 --> 02:22:00,000
用一个主机名和多条路径
like in the previous example and multiple path

3001
02:22:00,000 --> 02:22:03,200
这里有多个主机名
here inside now you have multiple hosts

3002
02:22:03,200 --> 02:22:06,399
每个主机代表一个子域名
where each host represents a subdomain and

3003
02:22:06,399 --> 02:22:08,960
在里面你只有一条路径
inside you just have one path that again

3004
02:22:08,960 --> 02:22:12,160
将该请求重定向到analytics service
redirects that request to analytic service

3005
02:22:12,160 --> 02:22:14,160
很直接
pretty straightforward so now in the

3006
02:22:14,160 --> 02:22:16,960
同样的你可以将analytic的请求设置和pod
same request setting you have analytic service

3007
02:22:16,960 --> 02:22:21,600
应用到下面，现在请求会看起来像这样
and a pod behind it now the request will look like

3008
02:22:21,600 --> 02:22:25,040
通过子域名代替路径
this using the subdomain instead of path

3009
02:22:25,040 --> 02:22:27,520
最后一个我提到的话题
and one final topic that i mentioned

3010
02:22:27,520 --> 02:22:28,880
我们将在这里讨论
that we'll cover here

3011
02:22:28,880 --> 02:22:31,920
就是配置tls证书
is configuring tls certificate till now

3012
02:22:31,920 --> 02:22:32,880
到现在我们只看到
we've only seen

3013
02:22:32,880 --> 02:22:36,640
http请求的Ingress配置
ingress configuration for http requests but it's

3014
02:22:36,640 --> 02:22:40,319
但其实配置https的Ingress转发是非常简单的
super easy to configure https forwarding in

3015
02:22:40,319 --> 02:22:43,439
所以你唯一需要的就是
ingress so the only thing that you need to do is

3016
02:22:43,439 --> 02:22:47,120
在rules部分上面定义名为tls的属性
define attribute called tls above the rules

3017
02:22:47,120 --> 02:22:50,960
hosts主机名还是一样的
section with host which is the same host as right here

3018
02:22:50,960 --> 02:22:54,800
secretName是一个secret的引用
and the secret name which is a reference

3019
02:22:54,800 --> 02:22:56,880
在一个维持着tls证书的集群中
of a secret that you have to create in a

3020
02:22:56,880 --> 02:23:01,200
创建的
cluster that holds that tls certificate so the secret

3021
02:23:01,200 --> 02:23:03,120
因此secret的配置看起来像这样
configuration would look like

3022
02:23:03,120 --> 02:23:07,680
所以secretName是引用这里
this so the name is the reference right here

3023
02:23:07,680 --> 02:23:10,880
数据或实际内容
and the data or the actual contents contain

3024
02:23:10,880 --> 02:23:14,720
包含tls证书和tls密钥
tls certificate and tls key

3025
02:23:14,720 --> 02:23:16,479
如果你看过我其他的视频
if you've seen my other videos where i

3026
02:23:16,479 --> 02:23:19,200
创建不同的组件，如secret
create different components like secret

3027
02:23:19,200 --> 02:23:23,200
您可能会注意到这里的type属性
you probably notice the type additional type attribute here

3028
02:23:23,200 --> 02:23:27,280
在kubernetes中有一个特定secret的type类型
in kubernetes there is a specific type of a secret

3029
02:23:27,280 --> 02:23:30,560
叫做tls，我们得用它
called tls so we'll have to use that type

3030
02:23:30,560 --> 02:23:33,920
当你创建一个tls secret时
when you create a tls secret and there are three

3031
02:23:33,920 --> 02:23:37,280
有三个小贴士
small notes to be made here one is that

3032
02:23:37,280 --> 02:23:41,920
第一，data部分的密钥必须和这里的命名一模一样
the keys of this data have to be named exactly like that

3033
02:23:41,920 --> 02:23:45,439
第二，这些值是实际的文件内容
the values are the actual file contents

3034
02:23:45,439 --> 02:23:47,439
证书或密钥的内容和
of the certificate or key contents and

3035
02:23:47,439 --> 02:23:49,680
而不是文件路径或位置
not the file path or location

3036
02:23:49,680 --> 02:23:52,160
所以你必须把所有内容都放进去
so you have to put the whole content

3037
02:23:52,160 --> 02:23:54,160
这是编码前的基本知识
here basics before encoded

3038
02:23:54,160 --> 02:23:56,479
第三点是你必须
and the third one is that you have to

3039
02:23:56,479 --> 02:23:59,120
在与Ingress组件相同的命名空间中
create the secret in the same namespace

3040
02:23:59,120 --> 02:24:02,000
创建secret
as the ingress component for it to be

3041
02:24:02,000 --> 02:24:03,600
从而能够使用它
able to use that

3042
02:24:03,600 --> 02:24:05,760
否则你就不能从另一个命名空间
otherwise you can't reference a secret

3043
02:24:05,760 --> 02:24:07,359
引用Secret
from another namespace

3044
02:24:07,359 --> 02:24:11,439
这四行就是你所需要的所有配置
and these four lines is all you need to configure

3045
02:24:11,439 --> 02:24:18,000
将对该主机的https请求映射到内部service
mapping of an https request to that host to internal service

3046
02:24:22,160 --> 02:24:24,080
在这个视频中，我将解释所有的
in this video i'm going to explain all

3047
02:24:24,080 --> 02:24:26,000
关于helm的主要概念
the main concepts of helm

3048
02:24:26,000 --> 02:24:29,040
这样你就能在你自己的项目中使用它
so that you are able to use it in your own projects

3049
02:24:29,040 --> 02:24:31,280
而且helm的版本变化很大
also helm changes a lot from version to

3050
02:24:31,280 --> 02:24:33,680
所以理解基本的共同原则
version so understanding the basic

3051
02:24:33,680 --> 02:24:35,840
以及更重要的用例
common principles and more importantly

3052
02:24:35,840 --> 02:24:37,600
即
its use cases to

3053
02:24:37,600 --> 02:24:40,240
何时和为什么使用helm
when and why we use helm will make it

3054
02:24:40,240 --> 02:24:42,640
可以使其在实践中更容易使用
easier for you to use it in practice

3055
02:24:42,640 --> 02:24:44,960
无论你选择哪个版本
no matter which version you choose so

3056
02:24:44,960 --> 02:24:47,680
我要在这个视频中讲的主题分别是
the topics i'm gonna go through in this video are

3057
02:24:47,680 --> 02:24:50,399
helm和heml chart是什么
helm and helm charts uh what they are

3058
02:24:50,399 --> 02:24:51,359
如何使用它们
how to use them

3059
02:24:51,359 --> 02:24:53,840
以及在什么情况下会用到它们
and in which scenarios they're used and

3060
02:24:53,840 --> 02:24:55,120
还有什么是Tiller
also what is tiller

3061
02:24:55,120 --> 02:24:58,720
以及它在helm体系结构中扮演的角色
and what part it plays in the helm architecture

3062
02:24:58,720 --> 02:25:02,800
所以什么是helm? helm有几个主要特征
so what is helm helm has a couple of main features

3063
02:25:02,800 --> 02:25:05,840
第一个是
that it's used for the first one is as a

3064
02:25:05,840 --> 02:25:07,920
作为kubernetes的包管理器
package manager for kubernetes

3065
02:25:07,920 --> 02:25:11,120
你可以把它想象成给kubernetes用的
so you can think of it as ept yum

3066
02:25:11,120 --> 02:25:13,840
apt yum或者是hombrew等工具
or hombrew for kubernetes so it's a

3067
02:25:13,840 --> 02:25:14,880
所以它是一种方便的方式
convenient way

3068
02:25:14,880 --> 02:25:18,640
用于打包kubernetes的yaml文件
for packaging collections of kubernetes yaml files

3069
02:25:18,640 --> 02:25:22,479
以及在公共或私人registry分发它们
and distributing them in public and private registry

3070
02:25:22,479 --> 02:25:24,479
现在这些定义听起来有点抽象
now these definitions may sound a bit

3071
02:25:24,479 --> 02:25:26,560
让我们把它们分解一下
abstract so let's break them down

3072
02:25:26,560 --> 02:25:30,479
举一些具体的例子
with specific examples so let's say

3073
02:25:30,479 --> 02:25:34,319
您已经将应用程序部署在kubernetes集群中
you have deployed your application in kubernetes cluster

3074
02:25:34,319 --> 02:25:36,560
您希望在集群中额外部署elasticsearch
and you want to deploy elasticsearch

3075
02:25:36,560 --> 02:25:38,000
这样您的应用程序就可以
additionally in your cluster

3076
02:25:38,000 --> 02:25:41,520
收集日志信息
that your application will use to collect

3077
02:25:41,520 --> 02:25:45,040
为了在您的kubernetes集群中
its logs in order to deploy

3078
02:25:45,040 --> 02:25:49,359
部署Elastic Stack
elastic stack in your kubernetes cluster

3079
02:25:49,359 --> 02:25:51,280
你需要几个kubernetes组件
you will need a couple of kubernetes

3080
02:25:51,280 --> 02:25:54,240
您需要一个StatefulSet用于
components so you would need a stateful set which is

3081
02:25:54,240 --> 02:25:57,200
像数据库这样的有状态应用程序
for stateful applications like databases

3082
02:25:57,200 --> 02:25:59,040
您将需要一个ConfigMap
you will need a config map

3083
02:25:59,040 --> 02:26:00,880
从而能够从外部配置
with external configuration you would

3084
02:26:00,880 --> 02:26:03,680
您需要一个Secret，在那里保存一些凭据
need a secret where some credentials

3085
02:26:03,680 --> 02:26:05,760
和秘密数据
and secret data are stored you will need

3086
02:26:05,760 --> 02:26:07,600
你要创建kubernetes用户
to create the kubernetes user with

3087
02:26:07,600 --> 02:26:10,960
其各有各自的权限
its respective permissions and also

3088
02:26:10,960 --> 02:26:12,800
还需要创建一些Service
create couple of services

3089
02:26:12,800 --> 02:26:17,760
现在，如果你要手动创建所有这些文件
now if you were to create all of these files manually

3090
02:26:17,760 --> 02:26:20,720
通过在互联网上单独搜索它们中的每一个
by searching for each one of them

3091
02:26:20,720 --> 02:26:23,600
将是乏味的工作
separately on internet would be a tedious job

3092
02:26:23,600 --> 02:26:26,640
直到你集齐所有这些yaml文件
and until you have all these yaml files collected

3093
02:26:26,640 --> 02:26:28,399
并进行了测试和试验
and tested and tried out it might take

3094
02:26:28,399 --> 02:26:32,000
而且elasticstack在所有集群中的部署
some time and since elasticstack deployment

3095
02:26:32,000 --> 02:26:35,600
可以相当标准化
is pretty much the standard across all clusters

3096
02:26:35,600 --> 02:26:37,520
但其他人可能不得不
other people will probably have to go

3097
02:26:37,520 --> 02:26:40,319
通过同样的方式再部署一次
through the same so it made perfect sense that

3098
02:26:40,319 --> 02:26:44,000
所以如果有人曾经创建了这些yaml文件
someone created these yaml files once

3099
02:26:44,000 --> 02:26:46,000
然后把它们打包，做成其他人也可用
and packaged them up and made it

3100
02:26:46,000 --> 02:26:47,439
将是非常有意义的
available somewhere

3101
02:26:47,439 --> 02:26:50,479
这样其他人也会使用
so that other people who also use the

3102
02:26:50,479 --> 02:26:52,399
同样的部署，可以使用它们
same kind of deployment could use them

3103
02:26:52,399 --> 02:26:55,280
在他们自己的kubernetes集群中
in their kubernetes cluster and that

3104
02:26:55,280 --> 02:26:57,200
而这样的yaml文件集
bundle of yaml files

3105
02:26:57,200 --> 02:27:00,640
被称为helm chart
is called helm chart so using helm you

3106
02:27:00,640 --> 02:27:02,000
所以使用helm你可以创建自己的
can create your own

3107
02:27:02,000 --> 02:27:05,600
helm chart或yaml文件集
helm charts or bundles of those yaml files

3108
02:27:05,600 --> 02:27:08,800
把它们推到一些helm仓库
and push them to some

3109
02:27:08,800 --> 02:27:12,479
使它对其他人可用
helm repository to make it available for others

3110
02:27:12,479 --> 02:27:14,720
或者你可以使用它们
or you can consume so you can use

3111
02:27:14,720 --> 02:27:16,080
下载并使用现有的
download and use

3112
02:27:16,080 --> 02:27:19,120
其他人推到仓库的helm chart
existing helm charts that other people pushed

3113
02:27:19,120 --> 02:27:22,479
并使其在不同的仓库中可用
and made available in differentrepositories so

3114
02:27:22,479 --> 02:27:25,840
所以一些常用的部署，如数据库应用程序
commonly used deployments like database applications

3115
02:27:25,840 --> 02:27:28,960
elasticsearch mongodb mysql or

3116
02:27:28,960 --> 02:27:31,680
或者像prometheus这样的监控应用程序
monitoring applications like prometheus

3117
02:27:31,680 --> 02:27:35,280
它们都有复杂的配置
that all have this kind of complex setup

3118
02:27:35,280 --> 02:27:40,160
也都在一些helm仓库中有可用的helm chart
all have charts available in some helm repository

3119
02:27:40,160 --> 02:27:44,560
所以使用一个简单的“helm install chart名”命令
so using a simple helm install chart name command

3120
02:27:44,560 --> 02:27:46,240
您可以重用
you can reuse the configuration that

3121
02:27:46,240 --> 02:27:48,319
别人已经做完了的配置
someone else has already made

3122
02:27:48,319 --> 02:27:50,399
不需付出额外的努力
without additional effort and sometimes

3123
02:27:50,399 --> 02:27:51,359
有时那个发布者
that someone is

3124
02:27:51,359 --> 02:27:53,120
甚至是创造了那个软件的公司
even the company that created the

3125
02:27:53,120 --> 02:27:55,520
这样的分享chart的功能
application and this functionality

3126
02:27:55,520 --> 02:27:58,880
在被广泛使用
of sharing charts that became pretty

3127
02:27:58,880 --> 02:28:00,880
事实上也是为什么
widely used actually was one of the

3128
02:28:00,880 --> 02:28:02,560
helm相比于其它可用工具
contributors to why

3129
02:28:02,560 --> 02:28:06,880
要更受欢迎的原因之一
helm became so popular compared to its alternative tools

3130
02:28:06,880 --> 02:28:10,479
所以现在如果你有一个集群
so now if you're if you have a cluster and you

3131
02:28:10,479 --> 02:28:12,399
你需要一些部署
need some kind of deployment that you

3132
02:28:12,399 --> 02:28:14,560
并且认为别人已经做过了
think should be available out there you

3133
02:28:14,560 --> 02:28:16,000
应该可以用命令行查到
can actually look it up

3134
02:28:16,000 --> 02:28:18,479
那么你可以执行
either using command line so you can do

3135
02:28:18,479 --> 02:28:20,319
“helm search <关键词>”命令
helm search with a keyword

3136
02:28:20,319 --> 02:28:23,840
或者你可以选择任意一种
or you can go to either helms on

3137
02:28:23,840 --> 02:28:28,319
公共仓库如helmhub或helm chart主页
public repository helmhub or on helm charts pages

3138
02:28:28,319 --> 02:28:31,600
或其他可用的仓库
or other repositories that are available

3139
02:28:31,600 --> 02:28:33,920
我会把所有相关的链接都放在
and i will put all the relevant links

3140
02:28:33,920 --> 02:28:35,680
这段视频的简介中
for this video in the description so you

3141
02:28:35,680 --> 02:28:37,040
你可以去查看一下
can check them out

3142
02:28:37,040 --> 02:28:40,479
helm chart除了有那些公共registry
now apart from those public registries for

3143
02:28:40,479 --> 02:28:44,000
也有私人registry
helm charts they're also private registries because

3144
02:28:44,000 --> 02:28:45,840
因为当公司开始创建这些chart
when companies start creating those

3145
02:28:45,840 --> 02:28:48,800
他们也开始在
charts they also started distributing them

3146
02:28:48,800 --> 02:28:51,359
在组织内部发布它们
among or internally in the organization

3147
02:28:51,359 --> 02:28:53,600
所以在公司内部，而不是公开
so it made perfect sense to create

3148
02:28:53,600 --> 02:28:57,040
共享这些chart
registries to share those charts

3149
02:28:57,040 --> 02:28:59,760
就很有意义
within the organization and not publicly

3150
02:28:59,760 --> 02:29:01,920
所以有一些工具
so there are a couple of tools out there

3151
02:29:01,920 --> 02:29:05,040
它们被用作helm chart的
they're used as helm charts

3152
02:29:05,040 --> 02:29:07,520
私有仓库
private repositories as well another

3153
02:29:07,520 --> 02:29:08,960
helm的另一个功能是
functionality of

3154
02:29:08,960 --> 02:29:12,000
模板引擎
helm is that it's a templating engine

3155
02:29:12,000 --> 02:29:15,200
这是什么意思呢
so what does that actually mean imagine you have

3156
02:29:15,200 --> 02:29:18,240
想象你有一个应用程序
an application that is made up of

3157
02:29:18,240 --> 02:29:20,720
由多种微服务组成
multiple microservices and you're

3158
02:29:20,720 --> 02:29:23,520
在你的kubernetes集群中要把它们全部部署
deploying all of them in your kubernetes cluster

3159
02:29:23,520 --> 02:29:27,840
这些微服务中的每一个deployment和service
and deployment and service of each of those microservices

3160
02:29:27,840 --> 02:29:30,319
是非常一致的
are pretty much the same with the only

3161
02:29:30,319 --> 02:29:32,960
区别仅在于应用程序名称和版本
difference that the application name and version

3162
02:29:32,960 --> 02:29:36,000
或docker镜像名称
are different or the docker image name

3163
02:29:36,000 --> 02:29:38,640
和docker镜像版本标签不同
and version tags are different so

3164
02:29:38,640 --> 02:29:39,680
没有helm时
without helm

3165
02:29:39,680 --> 02:29:42,800
您需要为每一个微服务
you would write separate yml files

3166
02:29:42,800 --> 02:29:45,920
编写单独的yaml配置文件
configuration files for each of those microservices so

3167
02:29:45,920 --> 02:29:50,399
那样你会有多个deployment和service的文件
you would have multiple deployment service files where

3168
02:29:50,399 --> 02:29:54,720
每一个都有自己的应用程序名称和版本
each one has its own application name and version

3169
02:29:54,720 --> 02:29:57,359
但它们唯一区别是
defined but since the only difference

3170
02:29:57,359 --> 02:29:58,399
yaml文件中的
between those

3171
02:29:58,399 --> 02:30:01,600
仅仅几行或
yaml files are just couple of lines or

3172
02:30:01,600 --> 02:30:03,040
几个数值
couple of values

3173
02:30:03,040 --> 02:30:06,080
用helm你能做的就是给所有这些微服务
using helm what you can do is that you can define

3174
02:30:06,080 --> 02:30:09,359
定义一个共同的蓝图
a common blueprint for all the microservices

3175
02:30:09,359 --> 02:30:12,479
这些值是动态的
and the values that are dynamic or the values that

3176
02:30:12,479 --> 02:30:15,920
将会被占位符取代
are going to change replace by

3177
02:30:15,920 --> 02:30:20,080
也就是定义一个模板文件
placeholders and that would be a template file

3178
02:30:20,080 --> 02:30:21,600
模板文件看起来像这样
so the template file would look

3179
02:30:21,600 --> 02:30:23,040
你会得到标准yaml文件
something like this you would have a

3180
02:30:23,040 --> 02:30:25,280
作为模板文件
template file which is standard yaml

3181
02:30:25,280 --> 02:30:28,319
但是某些地方会有Value...
but instead of values in some places you would have

3182
02:30:28,319 --> 02:30:30,479
这个语法意味着
the syntax which means that you're

3183
02:30:30,479 --> 02:30:32,479
要从外部配置中
taking a value

3184
02:30:32,479 --> 02:30:35,120
获取一个数值
from external configuration and that

3185
02:30:35,120 --> 02:30:36,880
语法中Value.后面的
external configuration if you see the

3186
02:30:36,880 --> 02:30:38,160
就是
syntax here dot

3187
02:30:38,160 --> 02:30:41,520
外部配置中值的来源
values that external configuration comes from

3188
02:30:41,520 --> 02:30:46,560
此时需要一个叫value.yaml的额外文件
an additional yaml file which is called values.yemo and

3189
02:30:46,560 --> 02:30:49,520
在这里，您可以定义所有这些
here you can define all those values

3190
02:30:49,520 --> 02:30:50,960
你会在模板文件中用到的值
that you're going to

3191
02:30:50,960 --> 02:30:53,520
例如
use in that template file so for example

3192
02:30:53,520 --> 02:30:55,600
这里定义了这四个值
here those four values are defined

3193
02:30:55,600 --> 02:30:58,720
在values.yaml文件中
in a values yaml file and

3194
02:30:58,720 --> 02:31:01,920
.Value是一个对象
what dot values is it's an object that

3195
02:31:01,920 --> 02:31:03,760
基于values.yaml文件
is being created

3196
02:31:03,760 --> 02:31:06,080
所提供的值
based on the values that are supplied by

3197
02:31:06,080 --> 02:31:08,080
被创造出来的对象
a values yaml file

3198
02:31:08,080 --> 02:31:11,760
同样可以通过命令行使用
and also through command line using

3199
02:31:11,760 --> 02:31:15,600
--set选项，所以无论哪种方式
dash dash set flag so whichever way you

3200
02:31:15,600 --> 02:31:16,399
你定义这些附加值
define those

3201
02:31:16,399 --> 02:31:19,439
它们被组合起来放在一起
additional values they're combined and put together

3202
02:31:19,439 --> 02:31:21,920
放到.Value对象中
in dot values object that you can then

3203
02:31:21,920 --> 02:31:25,120
你就可以在模板文件中使用这些值了
use in those template files to get the values out

3204
02:31:25,120 --> 02:31:27,760
所以现在不再有那么多yaml文件了
so now instead of having yaml files for

3205
02:31:27,760 --> 02:31:30,080
你只有一个微服务的文件
each microservice you just have one

3206
02:31:30,080 --> 02:31:33,840
你可以简单地动态替换这些值
and you can simply replace those values

3207
02:31:33,840 --> 02:31:37,040
这在您要对应用程序使用持续交付
dynamically and this is especially practical

3208
02:31:37,040 --> 02:31:38,960
持续集成时
when you're using continuous delivery

3209
02:31:38,960 --> 02:31:40,479
是尤其实用的
continuous integration

3210
02:31:40,479 --> 02:31:42,240
因为你能
for your application because what you

3211
02:31:42,240 --> 02:31:44,160
使用那些yaml模板文件
can do is that in your build

3212
02:31:44,160 --> 02:31:47,840
构建流水线
pipeline you can use those template yaml files

3213
02:31:47,840 --> 02:31:51,520
并在部署它们之前
and replace the values on the fly

3214
02:31:51,520 --> 02:31:54,000
即时替换这些值
before deploying them another use case

3215
02:31:54,000 --> 02:31:55,359
除了包管理器
where you can use

3216
02:31:55,359 --> 02:31:58,880
和模板引擎
the helm features of package manager

3217
02:31:58,880 --> 02:32:02,479
另一个你可以使用helm的用例是
and templating engine is when you deploy

3218
02:32:02,479 --> 02:32:04,640
当您要在不同kubernetes集群中
the same set of applications across

3219
02:32:04,640 --> 02:32:06,720
部署相同的应用程序集时
different kubernetes clusters

3220
02:32:06,720 --> 02:32:11,120
所以考虑这样的用例
so consider use case where you have your microservice

3221
02:32:11,120 --> 02:32:14,800
你有应用程序
application that you want to deploy on development

3222
02:32:14,800 --> 02:32:17,600
要部署在开发环境、模拟环境和生产环境集群中
staging and production clusters so

3223
02:32:17,600 --> 02:32:19,040
相比于在每个集群中
instead of deploying the

3224
02:32:19,040 --> 02:32:22,720
部署单独的yaml文件
individual yaml files separately in each cluster

3225
02:32:22,720 --> 02:32:26,240
你可以把它们打包成你自己的chart
you can package them up to make your own application

3226
02:32:26,240 --> 02:32:30,640
包含所有特定部署所需要的
chart that will have all the necessary yaml files

3227
02:32:30,640 --> 02:32:34,240
yaml文件
that that particular deployment needs

3228
02:32:34,240 --> 02:32:38,240
然后你可以用它们在不同k8s集群环境中
and then you can use them to redeploy the same

3229
02:32:38,240 --> 02:32:41,600
重新部署应用
application in different kubernetes cluster environments

3230
02:32:41,600 --> 02:32:44,080
使用一个命令即可
using one command which can also make

3231
02:32:44,080 --> 02:32:45,840
这使得整个部署过程更加容易
the whole deployment process

3232
02:32:45,840 --> 02:32:48,640
所以现在你知道了
easier so now that you know what helm

3233
02:32:48,640 --> 02:32:50,960
helm chart是用来干什么的
charts are used for it let's actually

3234
02:32:50,960 --> 02:32:54,160
让我们看看一个helm charm结构的例子
look at an example helm chart structure

3235
02:32:54,160 --> 02:32:57,439
这样才能更好的理解
to have a better understanding so typically

3236
02:32:57,439 --> 02:33:00,479
典型的helm chart是由这样的目录结构组成的
chart is made up of such a directory structure

3237
02:33:00,479 --> 02:33:02,640
最上层的是
so would have the top level will be the

3238
02:33:02,640 --> 02:33:03,920
chart名称
name of the chart

3239
02:33:03,920 --> 02:33:06,000
在这个目录中
and inside the directory you would have

3240
02:33:06,000 --> 02:33:07,560
就会有下面的
following so

3241
02:33:07,560 --> 02:33:10,160
Chart.yaml，它基本上是一个文件
chart.yaml is basically a file that

3242
02:33:10,160 --> 02:33:12,800
包含关于chart的所有元信息
contains all the meta information about the chart

3243
02:33:12,800 --> 02:33:16,080
可以是名字和版本，也可能是依赖关系列表等等
it could be name and version maybe list of dependencies

3244
02:33:16,080 --> 02:33:20,000
values.yaml我之前提到过
etc values.yaml that i mentioned before

3245
02:33:20,000 --> 02:33:23,359
里面放所有为模板文件
is place where all the values are cons

3246
02:33:23,359 --> 02:33:26,720
配置的数值
configured for the template files

3247
02:33:26,720 --> 02:33:28,640
这里就是默认值
and this will actually be the default

3248
02:33:28,640 --> 02:33:30,560
你可以稍后
values that you can

3249
02:33:30,560 --> 02:33:34,640
重写里面的值
override later the charts directory will have

3250
02:33:34,640 --> 02:33:37,600
charts目录里有chart的依赖关系
chart dependencies inside meaning that

3251
02:33:37,600 --> 02:33:38,640
意味着如果这个chart
if this chart

3252
02:33:38,640 --> 02:33:42,000
依赖于其他chart
depends on other charts then those chart

3253
02:33:42,000 --> 02:33:43,040
那么这些chart的依赖关系
dependencies will

3254
02:33:43,040 --> 02:33:46,080
将会被存储在这里，templates文件夹
be stored here and templates folder is

3255
02:33:46,080 --> 02:33:49,439
基本上存储模板文件
basically where the template files are stored

3256
02:33:49,439 --> 02:33:53,120
所以当你执行helm install命令时
so when you execute helm install command

3257
02:33:53,120 --> 02:33:57,120
要将这些yaml文件实际部署到k8s中
to actually deploy those yaml files into kubernetes

3258
02:33:57,120 --> 02:34:00,080
这里的模板文件将
the template files from here will be

3259
02:34:00,080 --> 02:34:02,200
被values.yaml的值填充
filled with the values from

3260
02:34:02,200 --> 02:34:05,680
产生有效的k8s清单
values.yaml producing valid kubernetes

3261
02:34:05,680 --> 02:34:09,920
然后就可以部署到kubernetes
manifest that can then be deployed intokubernetes

3262
02:34:09,920 --> 02:34:13,120
也可以选择让其他的文件放进这个文件夹中
and optionally you can have some other files in this

3263
02:34:13,120 --> 02:34:16,880
如readme或许可文件等等
folder like readme or license file

3264
02:34:16,880 --> 02:34:20,880
以便更好地了解
etc so to have a better understanding of how values

3265
02:34:20,880 --> 02:34:23,680
数值是如何注入到helm模板中的
are injected into helm templates

3266
02:34:23,680 --> 02:34:24,720
考虑到
consider that

3267
02:34:24,720 --> 02:34:28,880
values.yaml是默认配置值
in values.yaml which is a default value configuration you have

3268
02:34:28,880 --> 02:34:32,960
你要有三套值、镜像名称、端口和版本
following three values image name port and version

3269
02:34:32,960 --> 02:34:36,160
就像我提到的，定义的默认值可以
and as i mentioned the default values that are

3270
02:34:36,160 --> 02:34:40,160
被以不同的方式覆盖
defined here can be overridden in couple of different ways

3271
02:34:40,160 --> 02:34:44,160
一种方法是在执行helm install命令时
one way is that when executing helm install

3272
02:34:44,160 --> 02:34:47,439
提供一个可选的values.yaml文件
command you can provide an alternative

3273
02:34:47,439 --> 02:34:51,280
通过在命令中加入--values选项
values yaml file using values flag

3274
02:34:51,280 --> 02:34:54,800
例如，如果values.yaml文件
so for example if values yaml file

3275
02:34:54,800 --> 02:34:56,640
将有以下三个值
will have following three values which

3276
02:34:56,640 --> 02:34:58,479
镜像名称、端口和版本
are image name port and version

3277
02:34:58,479 --> 02:35:02,000
您可以定义自己的values.yaml文件
you can define your own values yaml file

3278
02:35:02,000 --> 02:35:05,600
命名为my-values.yaml
called myvalues.yaml and you can override

3279
02:35:05,600 --> 02:35:08,319
你可以覆盖这些值
one of those values or you can even add

3280
02:35:08,319 --> 02:35:10,160
甚至加上一些新的属性
some new attributes there

3281
02:35:10,160 --> 02:35:14,080
这两个会被合并到.Values对象
and those two will be merged which will result

3282
02:35:14,080 --> 02:35:17,520
看起来像这样
into a dot values object that will look like this

3283
02:35:17,520 --> 02:35:20,800
会有来自values.yaml的镜像名和端口
so would have image name and port from values.yaml

3284
02:35:20,800 --> 02:35:23,920
以及你自己的values文件的版本信息
and the one that you overwrote with your own

3285
02:35:23,920 --> 02:35:28,240
你还可以提供
values file alternatively you can also provide

3286
02:35:28,240 --> 02:35:31,920
额外的独立的值
additional individual values using

3287
02:35:31,920 --> 02:35:35,280
通过直接在命令行
set flag where you can define the values

3288
02:35:35,280 --> 02:35:36,479
加上set选项
directly on the command line

3289
02:35:36,479 --> 02:35:39,280
但是当然把所有这些值存储进文件
but of course it's more organized and

3290
02:35:39,280 --> 02:35:41,120
而不是仅仅在命令行中提供它们
better manageable to have

3291
02:35:41,120 --> 02:35:43,040
会更有组织性
files where you store all those values

3292
02:35:43,040 --> 02:35:45,680
更易于管理
instead of just providing them on a command line

3293
02:35:45,680 --> 02:35:48,800
helm的另一个特点是版本管理
another feature of helm is release management

3294
02:35:48,800 --> 02:35:52,000
这是根据它的配置提供的
which is provided based on its setup but

3295
02:35:52,000 --> 02:35:53,760
这里需要注意的是
it's important to note here

3296
02:35:53,760 --> 02:35:58,080
helm版本2和版本3的区别
the difference between helm versions 2 and 3.

3297
02:35:58,080 --> 02:36:00,640
在helm的第二版中
in version 2 of helm the helm

3298
02:36:00,640 --> 02:36:02,720
安装分为两个部分
installation comes in two parts

3299
02:36:02,720 --> 02:36:05,600
你有helm客户端和服务器
you have helm client and the server and

3300
02:36:05,600 --> 02:36:07,200
服务器部分被称为tiller
the server part is called

3301
02:36:07,200 --> 02:36:10,800
所以当你使用helm install
tiller so whenever you deploy helm chart

3302
02:36:10,800 --> 02:36:13,920
部署helm chart的时候，helm客户端将会
using helm install my chart helm client

3303
02:36:13,920 --> 02:36:16,720
把yaml文件发送给tiller
will send the yaml files to tiller

3304
02:36:16,720 --> 02:36:21,120
tiller在kubernetes集群中运行
that actually runs or has to run in a kubernetes cluster

3305
02:36:21,120 --> 02:36:24,240
tiller会执行这些请求
and tiller then will execute these requests and create

3306
02:36:24,240 --> 02:36:27,280
并利用这些yaml文件
components from these yaml files

3307
02:36:27,280 --> 02:36:29,359
在kubernetes集群内部创建组件
inside the kubernetes cluster and

3308
02:36:29,359 --> 02:36:31,280
这个架构
exactly this architecture

3309
02:36:31,280 --> 02:36:33,680
提供额外有价值的helm特性
offers additional valuable feature of

3310
02:36:33,680 --> 02:36:34,880
即版本管理
helm which is

3311
02:36:34,880 --> 02:36:38,240
所以helm客户端服务端的工作方式就是
release management so the way helm client

3312
02:36:38,240 --> 02:36:41,280
当你创建或更改部署时
server setup works is that whenever you

3313
02:36:41,280 --> 02:36:45,120
tiller将会
create or change deployment tiller will store

3314
02:36:45,120 --> 02:36:48,160
存储每个客户端发送的配置的副本
a copy of each configuration client send

3315
02:36:48,160 --> 02:36:52,000
为将来引用，因此创建一个
for future reference thus creating a history of

3316
02:36:52,000 --> 02:36:59,120
chart执行的历史记录，这样当你执行helm upgrade chartname的时候
chart executions so when you execute helm upgrade chartname

3317
02:36:59,120 --> 02:37:00,880
更改将应用到
the changes will be applied to the

3318
02:37:00,880 --> 02:37:02,960
现有的部署
existing deployment instead of

3319
02:37:02,960 --> 02:37:06,160
而不是删除它并创建一个新的
removing it and creating a new one and also

3320
02:37:06,160 --> 02:37:09,680
同样的，为防升级出现问题
in case the upgrade goes wrong for example

3321
02:37:09,680 --> 02:37:11,920
比如某些yaml文件是错误的
some yaml files were false or some

3322
02:37:11,920 --> 02:37:13,120
或者一些配置错了
configuration was

3323
02:37:13,120 --> 02:37:16,240
你可以回滚版本
wrong you can roll back that upgrade using

3324
02:37:16,240 --> 02:37:19,280
通过helm rollback chart name命令
helm rollback chart name command

3325
02:37:19,280 --> 02:37:22,560
正因为tiller每当你
and all this is possible because of that chart

3326
02:37:22,560 --> 02:37:25,200
从helm客户端发送请求到tiller保存了chart执行的历史记录这一切才成为可能
execution history that tiller keeps

3327
02:37:25,200 --> 02:37:26,160
tiller保存了chart执行的历史记录
whenever you

3328
02:37:26,160 --> 02:37:29,359
这一切才成为可能
send those requests from helm client to

3329
02:37:29,359 --> 02:37:32,160
然而，这样的设置
tiller however this setup has a big

3330
02:37:32,160 --> 02:37:33,359
有一个很大的隐患
caveat which is

3331
02:37:33,359 --> 02:37:35,680
kubernetes集群里
that tiller has too much power inside

3332
02:37:35,680 --> 02:37:37,680
tiller的权力太大了
the kubernetes cluster

3333
02:37:37,680 --> 02:37:41,280
它可以创建、更新、删除组件
it can create update delete components and it has

3334
02:37:41,280 --> 02:37:44,960
有太多的权限，这使得它
too much permissions and this makes it

3335
02:37:44,960 --> 02:37:47,680
实际上这是一个很大的安全问题
actually a big security issue and this

3336
02:37:47,680 --> 02:37:49,040
这也就是在helm版本3
was one of the reasons why

3337
02:37:49,040 --> 02:37:52,240
实际上移除了tiller的原因之一
in helm3 they actually removed the tiller part

3338
02:37:52,240 --> 02:37:55,920
现在它只是一个简单的helm二进制文件
and it's just a simple helm binary now and

3339
02:37:55,920 --> 02:37:58,800
这里有必要提一下，因为
it's important to mention here because a

3340
02:37:58,800 --> 02:37:59,520
很多人
lot of people

3341
02:37:59,520 --> 02:38:02,640
听说过tiller
have heard of tiller and when you deploy

3342
02:38:02,640 --> 02:38:05,680
当你部署helm版本3时
a helm version 3 you shouldn't be confused that

3343
02:38:05,680 --> 02:38:08,000
你不应该因没有tiller而感到困惑
tiller isn't actually there anymore

3344
02:38:10,880 --> 02:38:12,880
在这段视频中，我将告诉你如何
in this video i will show you how you

3345
02:38:12,880 --> 02:38:14,000
在kubernetes中
can persist data

3346
02:38:14,000 --> 02:38:17,359
使用volume保存数据
in kubernetes using volumes we will cover

3347
02:38:17,359 --> 02:38:20,240
我们会讲解kubernetes存储的三个组成部分
three components of kubernetes storage

3348
02:38:20,240 --> 02:38:21,280
persistent volume

3349
02:38:21,280 --> 02:38:24,479
persistent volume claim和storage class
persistent volume claim and storage class

3350
02:38:24,479 --> 02:38:26,960
看看每个组件是做什么的
and see what each component does and how

3351
02:38:26,960 --> 02:38:28,000
如何创建
it's created and

3352
02:38:28,000 --> 02:38:31,040
以及如何用于数据持久化
used for data persistence

3353
02:38:31,040 --> 02:38:34,399
考虑您的应用程序需要
consider a case where you have a mysql database pod

3354
02:38:34,399 --> 02:38:37,680
一个有mysql的数据库pod
which your application uses data gets added

3355
02:38:37,680 --> 02:38:40,479
数据在数据库中创建和更新
updated in the database maybe you create

3356
02:38:40,479 --> 02:38:42,160
也许你创建了一个新的数据库和一个新的用户等等
a new database with a new

3357
02:38:42,160 --> 02:38:46,960
但默认情况下，当你重新启动时
user etc but default when you restart the pod

3358
02:38:46,960 --> 02:38:49,280
所有这些改变都会消失
all those changes will be gone because

3359
02:38:49,280 --> 02:38:51,120
因为kubernetes没有给你
kubernetes doesn't give you

3360
02:38:51,120 --> 02:38:54,000
提供开箱即用的数据持久化
data persistence out of the box that's

3361
02:38:54,000 --> 02:38:56,240
你必须在重启前为每个
something that you have to explicitly

3362
02:38:56,240 --> 02:38:58,720
需要保存数据的应用程序
configure for each application that

3363
02:38:58,720 --> 02:39:00,240
显式配置
needs saving data between

3364
02:39:00,240 --> 02:39:04,640
基本上你需要一个
pod restarts so basically you need a storage

3365
02:39:04,640 --> 02:39:07,520
并不依赖于pod的生命周期的存储器
that doesn't depend on the pod lifecycle

3366
02:39:07,520 --> 02:39:10,240
所以当pod死了的时候
so it will still be there when pod dies a

3367
02:39:10,240 --> 02:39:11,840
一个新的会被创建
new one gets created

3368
02:39:11,840 --> 02:39:13,920
这样新的pod就能使用
so the new part can pick up where the

3369
02:39:13,920 --> 02:39:15,840
上一个pod留下的数据
previous one left off

3370
02:39:15,840 --> 02:39:18,960
因此，它将从存储器中读取现有数据
so it will read the existing data from that storage

3371
02:39:18,960 --> 02:39:22,800
从而获取最新的数据，然而你并不知道
to get up-to-date data however you don't know

3372
02:39:22,800 --> 02:39:26,000
新pod会在哪个节点上重新启动
on which node the new part restarts so

3373
02:39:26,000 --> 02:39:27,680
你的存储也必须是
your storage must also be

3374
02:39:27,680 --> 02:39:31,200
在所有节点上可用的，而不仅仅是特定的一个节点可用
available on all nodes not just one specific one

3375
02:39:31,200 --> 02:39:35,359
这样当新的pod想要读取现有数据时
so that when the new pod tries to read the existing data

3376
02:39:35,359 --> 02:39:38,479
最新的数据就在那里
the up-to-date data is there on

3377
02:39:38,479 --> 02:39:42,960
集群中的任何节点可用
any node in the cluster and also you need

3378
02:39:42,960 --> 02:39:46,560
你还需要一个高度抗毁的存储器
a highly available storage that will survive

3379
02:39:46,560 --> 02:39:49,760
即使整个集群崩溃，仍能生存
even if the whole cluster crashed

3380
02:39:49,760 --> 02:39:53,040
这些是你的存储器的标准或者说要求
so these are the criteria or the requirements that

3381
02:39:53,040 --> 02:39:56,240
要求你的存储器（如数据库存储器）
your storage for example your database storage

3382
02:39:56,240 --> 02:39:59,439
需要是可靠的
will need to have to be reliable another

3383
02:39:59,439 --> 02:40:01,680
另一个持久化存储的用例是
use case for persistent storage which is

3384
02:40:01,680 --> 02:40:04,560
不是为了给数据库用的，而是给目录用
not for database is a directory maybe you have an

3385
02:40:04,560 --> 02:40:06,880
也许你有一个应用程序
application that writes and reads

3386
02:40:06,880 --> 02:40:10,720
从预配置目录中读写文件
files from pre-configured directory this could be session

3387
02:40:10,720 --> 02:40:15,120
可能是程序的会话文件或配置文件文件等等
files for application or configuration files etc

3388
02:40:15,120 --> 02:40:18,319
你可以配置以上任何一种类型的存储
and you can configure any of this type of storage

3389
02:40:18,319 --> 02:40:20,720
通过使用叫做“Persistent Volume”（持久卷）的kubernetes组件
using kubernetes component called

3390
02:40:20,720 --> 02:40:24,560
将持久卷看作
persistent volume think of a persistent volume as a

3391
02:40:24,560 --> 02:40:25,840
集群的资源
cluster resource

3392
02:40:25,840 --> 02:40:30,000
就像ram或cpu一样，只是它用来存储
just like ram or cpu that is used to store

3393
02:40:30,000 --> 02:40:34,080
数据持久卷就像任何其他组件
data persistent volume just like any other component

3394
02:40:34,080 --> 02:40:37,279
使用kubernetes yaml文件创建
gets created using kubernetes yaml file

3395
02:40:37,279 --> 02:40:40,240
你可以指定kind是
where you can specify the kind which is

3396
02:40:40,240 --> 02:40:41,439
persistent volume

3397
02:40:41,439 --> 02:40:45,439
在spec部分，你必须定义
and in the specification section you have to define

3398
02:40:45,439 --> 02:40:47,200
不同的参数，比如多少
different parameters like how much

3399
02:40:47,200 --> 02:40:50,319
应该为卷创建多大的存储
storage should be created for the volume

3400
02:40:50,319 --> 02:40:54,960
但是由于持久卷只是一个抽象组件
but since persistent volume is just an abstract component

3401
02:40:54,960 --> 02:40:59,359
它必须从实际的物理存储器中获取存储空间
it must take the storage from the actual physical storage right

3402
02:40:59,359 --> 02:41:03,120
比如来自集群节点的本地硬盘
like local hard drive from the cluster nodes

3403
02:41:03,120 --> 02:41:06,880
或者集群外部nfs服务器
or your external nfs servers outside of the cluster

3404
02:41:06,880 --> 02:41:10,000
又或者像aws这样的云存储
or maybe cloud storage like aws

3405
02:41:10,000 --> 02:41:13,520
谷歌云存储等等
block storage or from google cloud storage etc

3406
02:41:13,520 --> 02:41:17,760
所以问题是这个存储后端来自
so the question is where does this storage back-end come from

3407
02:41:17,760 --> 02:41:21,120
本地，远程，还是云端；谁来配置它
local or remotes or on cloud who configures it

3408
02:41:21,120 --> 02:41:23,760
谁使它对集群可用
who makes it available to the cluster

3409
02:41:23,760 --> 02:41:26,479
这就是kubernetes中数据持久化的复杂之处
and that's the tricky part of data persistence

3410
02:41:26,479 --> 02:41:30,640
因为kubernetes并不关心你的实际存储情况
in kubernetes because kubernetes doesn't care about your

3411
02:41:30,640 --> 02:41:33,600
它给了你Persistent volume
actual storage it gives you persistent

3412
02:41:33,600 --> 02:41:36,080
作为接口接入到实际的存储空间
volume component as an interface

3413
02:41:36,080 --> 02:41:39,439
而你作为维护人员或者管理人员
to the actual storage that you as a maintainer

3414
02:41:39,439 --> 02:41:42,479
必须考虑这样的问题
or administrator have to take care of

3415
02:41:42,479 --> 02:41:46,560
所以你得决定你的服务或应用程序
so you have to decide what type of storage your cluster

3416
02:41:46,560 --> 02:41:49,600
需要哪种类型的存储
services or applications would need and

3417
02:41:49,600 --> 02:41:52,479
并自己创建和管理它们
create and manage them by yourself

3418
02:41:52,479 --> 02:41:53,680
管理的意思是
managing meaning do

3419
02:41:53,680 --> 02:41:57,600
备份，并确保它们不会被破坏等
backups and make sure they don't get corrupt etc

3420
02:41:57,600 --> 02:42:01,439
所以kubernetes中的存储可以看作是
so think of storage in kubernetes as an external

3421
02:42:01,439 --> 02:42:05,680
插入到您的集群中的插件，无论它是
plug-in to your cluster whether it's a local storage

3422
02:42:05,680 --> 02:42:07,680
运行中的集群所在的实际节点上的本地存储
on the actual nodes where the cluster is

3423
02:42:07,680 --> 02:42:09,840
还是远程存储
running or a remote storage

3424
02:42:09,840 --> 02:42:13,200
都没关系，它们都是集群的插件
doesn't matter they're all plugins to the cluster

3425
02:42:13,200 --> 02:42:15,040
你可以为您的集群
and you can have multiple storages

3426
02:42:15,040 --> 02:42:16,960
配置多个存储器
configured for your cluster

3427
02:42:16,960 --> 02:42:20,319
在您的集群中的一个应用程序使用本地磁盘存储
where one application in your cluster uses

3428
02:42:20,319 --> 02:42:24,080
另一个使用nfs服务器
local disk storage another one uses the nfs

3429
02:42:24,080 --> 02:42:27,520
另一个使用一些云存储
server and another one uses some cloud storage

3430
02:42:27,520 --> 02:42:34,000
或者一个应用程序也可以使用多种类型的存储
or one application may also use multiple of those storage types

3431
02:42:34,000 --> 02:42:36,560
通过创建持久卷
and by creating persistent volumes you

3432
02:42:36,560 --> 02:42:40,000
可以使用这些实际的物理存储
can use these actual physical storages so in the

3433
02:42:40,000 --> 02:42:42,560
所以在持久卷的spec部分
persistent volume specification section

3434
02:42:42,560 --> 02:42:45,600
您可以定义
you can define which storage

3435
02:42:45,600 --> 02:42:49,840
您想用哪个存储后端
back-end you want to use to create that storage

3436
02:42:49,840 --> 02:42:53,520
来为您的应用程序创建存储抽象或存储资源
abstraction or storage resource for your applications

3437
02:42:53,520 --> 02:42:56,560
这是我们使用nfs存储后端的例子
so this is an example where we use nfs

3438
02:42:56,560 --> 02:42:59,200
基本上是我们定义的
storage backend so basically we define

3439
02:42:59,200 --> 02:43:01,040
我们需要多少空间
how much storage we need

3440
02:43:01,040 --> 02:43:03,359
一些额外的参数
um some additional parameters so that

3441
02:43:03,359 --> 02:43:07,359
存储应该被读写或只读等
storage like should it be read write or read only etc

3442
02:43:07,359 --> 02:43:12,240
还有存储后端的参数
and the storage back end with its parameters

3443
02:43:12,240 --> 02:43:15,439
这是我们用的另一个例子
and this is another example where we use

3444
02:43:15,439 --> 02:43:18,399
用谷歌云作为存储后端
google cloud as a storage backend again

3445
02:43:18,399 --> 02:43:23,520
同样地要在sepc部分指定容量和访问模式等等
with the storage backend specified here and capacity and access modes here

3446
02:43:23,520 --> 02:43:26,640
显然，因存储后端的类型不同
now obviously depending on the storage type

3447
02:43:26,640 --> 02:43:30,720
一些在spec部分的属性
on the storage backend some of the attributes in the specification

3448
02:43:30,720 --> 02:43:32,640
会有所不同，因为他们是
will be different because they're

3449
02:43:32,640 --> 02:43:35,520
特定于存储类型的
specific to the storage type

3450
02:43:35,520 --> 02:43:37,439
这是另一个本地存储的例子
this is another example of a local

3451
02:43:37,439 --> 02:43:40,640
存储在节点本身上
storage which is on the node itself

3452
02:43:40,640 --> 02:43:42,720
有一个额外的nodeAffinity属性
which has additional node affinity

3453
02:43:42,720 --> 02:43:44,800
现在你不需要一次去记
attribute now you don't have to remember

3454
02:43:44,800 --> 02:43:47,120
去知道所有这些属性
and know all these attributes

3455
02:43:47,120 --> 02:43:51,040
因为你可能不需要全部这些属性
at once because you may not need all of them and also

3456
02:43:51,040 --> 02:43:53,439
此外我将单独做一个视频
i will make separate videos covering

3457
02:43:53,439 --> 02:43:54,880
讲解一些最常用的volumes
some of the most used

3458
02:43:54,880 --> 02:43:58,319
并逐一通过示例来解释
volumes and explain them individually with examples

3459
02:43:58,319 --> 02:44:01,040
在那里我会详细地解释
and demos so there i'm going to explain

3460
02:44:01,040 --> 02:44:02,720
哪些属性
in more detail which

3461
02:44:02,720 --> 02:44:05,200
应该被用于特定的volume
attributes should be used for these

3462
02:44:05,200 --> 02:44:07,439
以及它们是什么意思
specific volumes and what they actually mean

3463
02:44:07,439 --> 02:44:09,520
在kubernetes官方文档中
in the official kubernetes documentation

3464
02:44:09,520 --> 02:44:11,840
你可以看到完整的列表
you can actually see the complete list

3465
02:44:11,840 --> 02:44:16,319
关于kubernetes支持的超过25个存储后端
of more than 25 storage back-ends that kubernetes supports

3466
02:44:16,319 --> 02:44:19,359
这里要注意的是持久卷
note here that persistent volumes

3467
02:44:19,359 --> 02:44:22,399
不受命名空间束缚
are not namespaced meaning

3468
02:44:22,399 --> 02:44:24,880
整个集群都可以访问它们
they're accessible to the whole cluster

3469
02:44:24,880 --> 02:44:29,359
不像我们看到的其他部件如pod或service
and unlike other components that we saw like pods and services

3470
02:44:29,359 --> 02:44:31,600
它们不在任何命名空间中
they're not in any namespace they're

3471
02:44:31,600 --> 02:44:35,439
对所有命名空间的整个集群都可用
just available to the whole cluster to all the namespaces

3472
02:44:35,439 --> 02:44:37,200
很重要的一点是要区分
now it's important to differentiate here

3473
02:44:37,200 --> 02:44:40,160
在两类volume
between two categories of the volumes

3474
02:44:40,160 --> 02:44:42,800
本地和远程
local and remote each volume type in

3475
02:44:42,800 --> 02:44:44,319
这两个类别中的volume的每种类型
these two categories

3476
02:44:44,319 --> 02:44:48,720
都有自己的用例，否则它们不必存在
has its own use case otherwise they won't exist

3477
02:44:48,720 --> 02:44:50,960
我们稍后在本视频中
and we will see some of these use cases

3478
02:44:50,960 --> 02:44:52,399
会看到一些用例
later in this video

3479
02:44:52,399 --> 02:44:55,680
但是，本地volume类型违反了
however the local volume types violate

3480
02:44:55,680 --> 02:44:59,200
我在开始时提到过的
the second and third requirements of data persistence

3481
02:44:59,200 --> 02:45:02,560
数据库数据持久化的第二个和第三个要求
for databases that i mentioned at the beginning

3482
02:45:02,560 --> 02:45:06,240
即不绑定到特定的节点
which is one not being tied to

3483
02:45:06,240 --> 02:45:09,279
而是每个节点雨露均沾
one specific node but rather to each

3484
02:45:09,279 --> 02:45:11,600
因为你不知道
node equally because you don't know

3485
02:45:11,600 --> 02:45:13,200
新的pod会在哪里启动
where the new pod will

3486
02:45:13,200 --> 02:45:18,160
第二个，在集群崩溃的场景中要能够存活
start and the second surviving in cluster crash scenarios

3487
02:45:18,160 --> 02:45:21,600
由于这些数据库持久化需求的原因
because of these reasons for database persistence

3488
02:45:21,600 --> 02:45:25,920
你应该总是使用远程存储
you should almost always use remote storage

3489
02:45:25,920 --> 02:45:29,520
那么由谁 何时 创建这个持久卷呢
so who creates this persistent volumes and when

3490
02:45:29,520 --> 02:45:32,560
正如我所说的，持久卷是资源
as i said persistent volumes are resources like

3491
02:45:32,560 --> 02:45:35,840
如同cpu或ram
cpu or ram so they have to be already

3492
02:45:35,840 --> 02:45:37,359
所以当依赖于或要使用该持久卷的pod
there in the cluster

3493
02:45:37,359 --> 02:45:40,720
被创建时，该卷必须已经存在于集群中
when the pod that depends on it or that uses it

3494
02:45:40,720 --> 02:45:44,000
所以要备注一下
is created so a side note here is that

3495
02:45:44,000 --> 02:45:46,240
kubernetes有两个主要角色
there are two main roles in kubernetes

3496
02:45:46,240 --> 02:45:49,600
其中一个是创建并维护集群的管理员
there's an administrator who sets up the cluster

3497
02:45:49,600 --> 02:45:52,319
他还要确保
and maintains it and also makes sure the

3498
02:45:52,319 --> 02:45:55,120
集群有足够的资源
cluster has enough resources

3499
02:45:55,120 --> 02:45:57,120
这些人通常是系统管理员
these are usually system administrators

3500
02:45:57,120 --> 02:45:58,640
或公司中的devops工程师
or devops engineers

3501
02:45:58,640 --> 02:46:02,880
第二个角色是kubernetes用户
in a company and the second role is kubernetes user

3502
02:46:02,880 --> 02:46:04,800
在集群中部署应用程序
that deploys the applications in the

3503
02:46:04,800 --> 02:46:07,200
要么直接要么通过CI pipeline构建
cluster either directly or through

3504
02:46:07,200 --> 02:46:10,960
是开发人员和devops团队
ci pipeline these are developer devops teams

3505
02:46:10,960 --> 02:46:13,200
谁创建和部署应用程序
who create the applications and deploy

3506
02:46:13,200 --> 02:46:15,600
在这个例子中，kubernetes管理员
them so in this case the kubernetes

3507
02:46:15,600 --> 02:46:18,160
将是那个
administrator would be the one to

3508
02:46:18,160 --> 02:46:20,640
负责配置实际存储的人
configure the actual storage

3509
02:46:20,640 --> 02:46:24,399
确保nfs服务器存储的安好
meaning to make sure that the nfs server

3510
02:46:24,399 --> 02:46:27,840
并进行配置
storage is there and configured or maybe

3511
02:46:27,840 --> 02:46:30,479
或者也许创建和配置一个
create and configure a cloud storage

3512
02:46:30,479 --> 02:46:32,720
对集群是可用的云存储
that will be available for the cluster

3513
02:46:32,720 --> 02:46:36,160
接着，来自开发团队关于应用需要的存储类型的的信息
and second create persistent volume components

3514
02:46:36,160 --> 02:46:39,120
从这些存储后端
from these storage backends based on the

3515
02:46:39,120 --> 02:46:42,720
创建持久卷
information from developer team of what types of storage

3516
02:46:42,720 --> 02:46:46,640
然后开发人员
their applications would need and the developers then

3517
02:46:46,640 --> 02:46:48,960
会知道存储器在那里并且可以
will know that storage is there and can

3518
02:46:48,960 --> 02:46:50,880
被他们的应用程序使用
be used by their applications

3519
02:46:50,880 --> 02:46:53,200
但为了实现这一点，开发者必须
but for that developers have to

3520
02:46:53,200 --> 02:46:56,240
显式配置
explicitly configure the application

3521
02:46:56,240 --> 02:47:00,640
那些使用持久卷组件的应用程序的yaml文件
yaml file to use those persistent volume components

3522
02:47:00,640 --> 02:47:04,080
换句话说，应用程序必须声明那个volume
in other words application has to claim that

3523
02:47:04,080 --> 02:47:06,479
你可以使用
volume storage and you do that using

3524
02:47:06,479 --> 02:47:08,479
kubernetes的另一个组件实现这一点
another component of kubernetes

3525
02:47:08,479 --> 02:47:11,520
它叫做persistent volume claim(PVC)
called persistent volume claim

3526
02:47:11,520 --> 02:47:15,760
PVC同样是通过yaml配置的
persistent volume claims also pvcs are also created

3527
02:47:15,760 --> 02:47:18,800
这里有一个例子
with yaml configuration here's an example

3528
02:47:18,800 --> 02:47:20,640
别担心
claim again don't worry about

3529
02:47:20,640 --> 02:47:24,560
不必理解这里定义的每一个属性
understanding each and every attribute that is defined here

3530
02:47:24,560 --> 02:47:26,800
但要理解更高的层次，即它是如何运作
but on the higher level the way it works

3531
02:47:26,800 --> 02:47:31,840
PVC声明在其中已定义好的
is that pvc claims a volume with certain storage

3532
02:47:31,840 --> 02:47:35,840
具有特定存储大小或容量的卷
size or capacity which is defined in the persistent volume claim

3533
02:47:35,840 --> 02:47:40,000
还有一些额外的特征，比如访问类型
and some additional characteristics like access type

3534
02:47:40,000 --> 02:47:43,439
应该是只读还是读写等等
should be read only or read write or the type

3535
02:47:43,439 --> 02:47:46,960
只要持久卷
etc and whatever persistent volume

3536
02:47:46,960 --> 02:47:51,040
符合这个标准，或者说满足这个声明
matches this criteria or in other words satisfies this

3537
02:47:51,040 --> 02:47:54,080
它就会被应用程序所用
claim will be used for the application

3538
02:47:54,080 --> 02:47:57,439
但这还不是全部，你必须在你的pod的配置中
but that's not all you have to now use that claim

3539
02:47:57,439 --> 02:48:00,479
使用这个声明，就像这样
in your pods configuration like this

3540
02:48:00,479 --> 02:48:02,880
所以在pod的spec部分
so in the pod specification here you

3541
02:48:02,880 --> 02:48:05,120
会有volumes属性
have the volumes

3542
02:48:05,120 --> 02:48:12,479
通过PVC名称引用该PVC
attribute that references the persistent volume claim with its name

3543
02:48:12,479 --> 02:48:16,479
现在pod和其中的所有容器
so now the pod and all the containers inside the pod

3544
02:48:16,479 --> 02:48:20,080
都能访问到那个持久卷存储了
will have access to that persistent volume

3545
02:48:20,080 --> 02:48:22,960
为了能够一步步穿透
storage so to go through those levels of

3546
02:48:22,960 --> 02:48:24,960
不同层级的抽象
abstraction step by step

3547
02:48:24,960 --> 02:48:29,200
pods通过使用PVC作为volume来访问存储
pods access storage by using the claim as a volume

3548
02:48:29,200 --> 02:48:33,200
所以他们通过PVC发出请求
right so they request the volume through claim

3549
02:48:33,200 --> 02:48:36,160
PVC会在集群中
the claim then will go and try to find a

3550
02:48:36,160 --> 02:48:38,399
寻找一个满足声明要求的
volume persistent volume in the cluster

3551
02:48:38,399 --> 02:48:40,880
持久卷
that satisfies the claim

3552
02:48:40,880 --> 02:48:44,560
volume将会有一个
and the volume will have a storage the actual storage

3553
02:48:44,560 --> 02:48:47,920
实际的存储后端
backend that it will create

3554
02:48:47,920 --> 02:48:50,399
从那里创建存储资源
that storage resource from and this way

3555
02:48:50,399 --> 02:48:52,080
这样pod就可以
the pod will now be able

3556
02:48:52,080 --> 02:48:55,600
使用实际的存储后端了
to use that actual storage backend

3557
02:48:55,600 --> 02:48:58,800
注意，PVC必须存在于
note here that claims must exist in the

3558
02:48:58,800 --> 02:49:00,880
与pod相同的命名空间
same namespace as the pod

3559
02:49:00,880 --> 02:49:03,359
正如我之前提到的
using the claim while as i mentioned

3560
02:49:03,359 --> 02:49:08,479
持久卷不受限于命名空间，所以一旦
before persistent volumes are not namespaced so once the pod

3561
02:49:08,479 --> 02:49:10,720
pod通过PVC
finds the matching persistent volume

3562
02:49:10,720 --> 02:49:14,399
找到匹配的持久卷
through the persistent volume claim the

3563
02:49:14,399 --> 02:49:16,080
然后volume接着就会挂载到pod上
volume is then mounted

3564
02:49:16,080 --> 02:49:20,479
像这样，这就来到了pod级
into the pod like this here this is a pod level

3565
02:49:20,479 --> 02:49:24,479
然后这个volume可以被挂载到pod中的容器
and then that volume can be mounted into the container

3566
02:49:24,479 --> 02:49:28,319
也就是这一级
inside the pot which is this level right here

3567
02:49:28,319 --> 02:49:31,760
如果pod里有多个容器
and if you have multiple containers here in the pot you can

3568
02:49:31,760 --> 02:49:35,120
你可以决定将volume挂载到所有容器
decide to mount this volume in

3569
02:49:35,120 --> 02:49:37,920
或者只挂载到其中的一些
all the containers or just some of those

3570
02:49:37,920 --> 02:49:40,160
现在容器
so now the container

3571
02:49:40,160 --> 02:49:42,160
以及容器内的应用程序
and the application inside the container

3572
02:49:42,160 --> 02:49:44,399
可以读写那个存储器了
can read and write to that storage

3573
02:49:44,399 --> 02:49:47,439
并且一旦pod崩溃，新的创建取而代之
and when the pod dies a new one gets created

3574
02:49:47,439 --> 02:49:50,080
它将访问相同的存储空间
it will have access to the same storage

3575
02:49:50,080 --> 02:49:52,560
并查看之前pod或者是之前容器
and see all the changes the previous pod

3576
02:49:52,560 --> 02:49:55,439
所做的所有更改
or the previous containers made again

3577
02:49:55,439 --> 02:49:58,560
这里的属性像volumes和volumeMounts
the attributes here like volumes and volume mounts etc

3578
02:49:58,560 --> 02:50:01,760
在后面的演示视频中
and how they're used i will show you more specifically

3579
02:50:01,760 --> 02:50:04,800
我会更具体地告诉你它们是如何使用的
and explain in a later demo video

3580
02:50:04,800 --> 02:50:08,399
现在你可能想知道使用volume为什么有这么多抽象
now you may be wondering why so many abstractions

3581
02:50:08,399 --> 02:50:11,520
管理员角色要创建持久卷
for using volume where admin role has to

3582
02:50:11,520 --> 02:50:14,800
而用户角色要创建PVC（声明）
create persistent volume and user role creates a claim

3583
02:50:14,800 --> 02:50:17,840
来声明那个持久卷
on that persistent volume and that isn't used in pod

3584
02:50:17,840 --> 02:50:21,680
我不可以只用一个组件配置所有东西
can i just use one component and configure everything there

3585
02:50:21,680 --> 02:50:25,359
这其实对用户来说是有好处的
well this actually has a benefit because as a user

3586
02:50:25,359 --> 02:50:27,040
这意味着开发人员只需要
meaning a developer who just wants to

3587
02:50:27,040 --> 02:50:29,680
在集群中部署它们的应用程序
deploy their application in the cluster

3588
02:50:29,680 --> 02:50:33,600
而不用关心实际的存储器
you don't care about where the actual storage is

3589
02:50:33,600 --> 02:50:36,800
您知道您希望您的数据库具有持久性
you know you want your database to have persistence

3590
02:50:36,800 --> 02:50:39,040
数据是被放到
and whether the data will leave on the

3591
02:50:39,040 --> 02:50:40,160
gluster fs

3592
02:50:40,160 --> 02:50:43,920
或aws ebs或本地存储
or aws ebs or local storage

3593
02:50:43,920 --> 02:50:47,760
对你来说无所谓，只要数据被安全存储
doesn't matter for you as long as the data is safely stored

3594
02:50:47,760 --> 02:50:50,800
或者如果你需要一个目录存储文件
or if you need a directory storage for files

3595
02:50:50,800 --> 02:50:52,640
你不关心目录在哪里
you don't care where the directory

3596
02:50:52,640 --> 02:50:55,120
只要有足够的空间
actually leaves as long as it has enough space

3597
02:50:55,120 --> 02:50:59,520
还能正常工作就行，但你肯定不想
and works properly and you sure don't want to care about

3598
02:50:59,520 --> 02:51:02,720
亲自设置这些实际的存储
setting up these actual storages yourself

3599
02:51:02,720 --> 02:51:05,520
你只想要50g的存储空间给你的elastic
you just want 50 gigabyte storage for

3600
02:51:05,520 --> 02:51:08,479
或者10GB给你的应用程序
your elastic or 10 gigabyte for your application

3601
02:51:08,479 --> 02:51:12,160
这样你就可以利用PVC声明一个存储
that's it so you make a claim for storage using pvc

3602
02:51:12,160 --> 02:51:15,840
并假设集群中已经有存储资源
and assume that cluster has storage

3603
02:51:15,840 --> 02:51:19,680
这使得
resources already there and this makes

3604
02:51:19,680 --> 02:51:23,439
对开发人员来说部署应用程序更容易
deploying the applications easier for developers

3605
02:51:23,439 --> 02:51:24,800
因为他们不需要关心
because they don't have to take care of

3606
02:51:24,800 --> 02:51:28,640
部署的应用程序之外的东西
the stuff beyond deploying the applications

3607
02:51:28,640 --> 02:51:30,640
现在有两个volume类型
now there are two volume types that i

3608
02:51:30,640 --> 02:51:32,800
我认为需要单独提及
think needs to be mentioned separately

3609
02:51:32,800 --> 02:51:34,560
因为它们和其它的有些许不同
because they're a bit different from the

3610
02:51:34,560 --> 02:51:39,120
它们是ConfigMap和Secret
rest and these are config map and secret now if you have

3611
02:51:39,120 --> 02:51:42,160
如果你看过我的其它的kubernetes的视频
watched my other video on kubernetes components

3612
02:51:42,160 --> 02:51:45,040
那么你对两者都已经很熟悉了
then you are already familiar with both

3613
02:51:45,040 --> 02:51:46,080
它们都是
both of them are

3614
02:51:46,080 --> 02:51:49,520
本地volume，但不像其他那些
local volumes but unlike the rest these two

3615
02:51:49,520 --> 02:51:52,640
这两个不是通过pv(持久卷)和pvc产生的
aren't created via pv and pvc

3616
02:51:52,640 --> 02:51:57,040
而是独立的组件并且由kubernetes自己管理
but are rather own components and managed by kubernetes itself

3617
02:51:57,040 --> 02:51:58,560
考虑一个场景
consider a case where you need a

3618
02:51:58,560 --> 02:52:01,040
你需要给prometheus对应的pod一个配置文件
configuration file for your prometheus

3619
02:52:01,040 --> 02:52:04,800
或者一个类似于mosquito的消息代理服务
pod or maybe a message broker service like mosquito

3620
02:52:04,800 --> 02:52:07,840
或者考虑一下当你需要一个证书
or consider when you need a certificate file

3621
02:52:07,840 --> 02:52:11,760
安装在您的应用程序中，在这两种情况下
mounted inside your application in both cases

3622
02:52:11,760 --> 02:52:15,600
您需要一个文件可被pod使用
you need a file available to your pod

3623
02:52:15,600 --> 02:52:17,520
为使这些发生，你要自己创建
so how this works is that you create

3624
02:52:17,520 --> 02:52:19,760
configmap或secret组件
configmap or secret component

3625
02:52:19,760 --> 02:52:22,319
你可以把它安装到你的pod里
and you can mount that into your pod and

3626
02:52:22,319 --> 02:52:23,520
以及你的容器里
into your container

3627
02:52:23,520 --> 02:52:25,600
与你安装PVC的方式一样
the same way as you would mount

3628
02:52:25,600 --> 02:52:30,000
所以你会有一个ConfigMap或Secret属性
persistent volume claim so instead you would have a config map or

3629
02:52:30,000 --> 02:52:33,439
在我介绍本地volume类型的视频中
secret here and i will show you a demo of this

3630
02:52:33,439 --> 02:52:37,359
会给你们看一个关于此的演示
in a video where i cover local volume types

3631
02:52:37,359 --> 02:52:39,200
快速总结一下
so to quickly summarize what we've

3632
02:52:39,200 --> 02:52:40,640
我们到目前为止所讲的内容
covered so far

3633
02:52:40,640 --> 02:52:44,240
正如我们看到的，在它的核心，volume就是一个目录
as we see at its core a volume is just a directory

3634
02:52:44,240 --> 02:52:46,640
里面可能有一些数据
possibly with some data in it which is

3635
02:52:46,640 --> 02:52:48,479
能够被pod中的容器所访问
accessible to the containers

3636
02:52:48,479 --> 02:52:51,760
我们学习了该目录是如何被创建可用的
in a pod how that directory is made available

3637
02:52:51,760 --> 02:52:55,120
以及什么样的存储介质是受支持的
or what storage medium actually backed by

3638
02:52:55,120 --> 02:52:58,399
目录的内容是
and the contents of the directory are

3639
02:52:58,399 --> 02:53:02,880
由您定义的特定volume类型
defined by a specific volume type you use

3640
02:53:02,880 --> 02:53:06,640
为了使用一个volume，一个pod会在spec的volumes属性中指定
so to use a volume a pod specifies what volumes

3641
02:53:06,640 --> 02:53:10,560
什么样的volume要被提供给pod
to provide for the pod in the specification

3642
02:53:10,560 --> 02:53:12,960
在pod内
volumes attribute and inside the pod

3643
02:53:12,960 --> 02:53:14,080
你可以
then you can decide

3644
02:53:14,080 --> 02:53:18,000
通过containers部分的volumeMounts属性
where to mount that storage into

3645
02:53:18,000 --> 02:53:22,880
把存储器挂载到哪里
using volume mounts attribute inside the container section

3646
02:53:22,880 --> 02:53:26,240
这是容器内部的路径
and this is a path inside the container

3647
02:53:26,240 --> 02:53:29,760
应用程序可以利用其访问
where application can access whatever

3648
02:53:29,760 --> 02:53:32,800
我们挂载到容器中的存储器
storage we mounted into the container

3649
02:53:32,800 --> 02:53:34,880
就像我说的，如果有多个容器
and as i said if you have multiple

3650
02:53:34,880 --> 02:53:36,720
你可以决定
containers you can decide

3651
02:53:36,720 --> 02:53:40,560
哪个容器有权访问存储器
which container should get access to that storage

3652
02:53:40,560 --> 02:53:44,479
有趣的是，一个pod可以同时使用
interesting note for you is that a pod can actually use

3653
02:53:44,479 --> 02:53:47,840
不同类型的多个volume
multiple volumes of different types simultaneously

3654
02:53:47,840 --> 02:53:51,760
假设你有一个ElasticSearch应用程序
let's say you have an elasticsearch application

3655
02:53:51,760 --> 02:53:54,720
或者在您的集群中运行的pod
or pod running in your cluster that

3656
02:53:54,720 --> 02:53:56,880
需要通过ConfigMap挂载一个配置文件
needs a configuration file

3657
02:53:56,880 --> 02:54:00,880
或者需要一个证书
mounted through a config map needs a certificate

3658
02:54:00,880 --> 02:54:04,560
比如通过Secret安装了一个客户端证书
let's say client certificate are mounted as a secret

3659
02:54:04,560 --> 02:54:08,080
它还需要数据库存储
and it needs database storage let's say which is

3660
02:54:08,080 --> 02:54:11,600
比如用aws Elastic Block Storage
backed with aws elastic

3661
02:54:11,600 --> 02:54:15,040
在这种情况下你可以配置
block storage so in this case you can configure

3662
02:54:15,040 --> 02:54:19,120
这三个全都在你的pod或deployment里
all three inside your pod or deployment

3663
02:54:19,120 --> 02:54:22,960
这就是我们之前看到的pod的spec部分
so this is the pod specification that we saw before

3664
02:54:22,960 --> 02:54:26,319
在这里volumes属性这一级，你可以列出
and here on the volumes level you will just list

3665
02:54:26,319 --> 02:54:31,680
所有想要挂载到pod的volume
all the volumes that you want to mount into your pod

3666
02:54:31,680 --> 02:54:32,960
这里你在后台有一个PVC
so let's say you have a persistent

3667
02:54:32,960 --> 02:54:36,880
其在声明aws块存储的持久卷
volume claim that in the background claims persistent volume from

3668
02:54:36,880 --> 02:54:41,200
这里你有一个ConfigMap
aws block storage and here you have the config map

3669
02:54:41,200 --> 02:54:43,520
这里有个Secret
and here have a secret and here in the

3670
02:54:43,520 --> 02:54:45,600
这里的volumeMounts中你可以通过名称
volume mounts you can list

3671
02:54:45,600 --> 02:54:49,439
列出所有存储挂载点
all those uh storage mounts using the names

3672
02:54:49,439 --> 02:54:52,640
这就是持久化存储
right so you have the persistent storage

3673
02:54:52,640 --> 02:54:54,080
然后你有了ConfigMap和Secret
then you have the config map

3674
02:54:54,080 --> 02:54:58,080
每一个都被挂载到容器内指定的路径
and the secret and each one of them is mounted to a certain

3675
02:54:58,080 --> 02:55:01,439
我们现在看到
path inside the container now we saw that

3676
02:55:01,439 --> 02:55:03,920
为了kubernetes中持久化数据
to persist data in kubernetes admins

3677
02:55:03,920 --> 02:55:06,720
管理员需要为集群配置存储
need to configure storage for the cluster

3678
02:55:06,720 --> 02:55:08,960
创建持久卷
create persistent volumes and developers

3679
02:55:08,960 --> 02:55:10,319
开发人员然后就可以通过PVC声明
then can claim them

3680
02:55:10,319 --> 02:55:13,520
但是考虑
using pvcs but consider a cluster with

3681
02:55:13,520 --> 02:55:15,120
一个有数以百计的应用程序的集群
hundreds of applications

3682
02:55:15,120 --> 02:55:16,960
每天都要进行部署
where things get deployed daily and

3683
02:55:16,960 --> 02:55:19,359
这些应用程序都需要存储
storage is needed for these applications

3684
02:55:19,359 --> 02:55:21,359
因此开发人员需要要求管理员
so developers need to ask admins to

3685
02:55:21,359 --> 02:55:24,000
在部署应用程序之前
create persistent volumes they need

3686
02:55:24,000 --> 02:55:27,120
创建所需的持久卷
for applications before deploying them and

3687
02:55:27,120 --> 02:55:29,200
然后，管理员可能不得不手动请求
admins then may have to manually request

3688
02:55:29,200 --> 02:55:32,160
来自云或存储器供应商的存储资源
storage from cloud or storage provider

3689
02:55:32,160 --> 02:55:35,359
并手动创建数百个持久卷
and create hundreds of persistent volumes for

3690
02:55:35,359 --> 02:55:38,399
以满足所有需要存储的应用程序的需求
all the applications that need storage

3691
02:55:38,399 --> 02:55:42,479
那是一段乏味的时间
manually and that can be tedious time consuming

3692
02:55:42,479 --> 02:55:45,760
而且很快就会变得一团糟
and can get messy very quickly so to

3693
02:55:45,760 --> 02:55:48,000
为了让这个过程更有效率
make this process more efficient

3694
02:55:48,000 --> 02:55:52,080
kubernetes持久化还有第三个组件可以用
there is a third component of kubernetes persistence

3695
02:55:52,080 --> 02:55:54,960
称为Storage Class
called storage class storage class

3696
02:55:54,960 --> 02:55:57,279
它基本上就是在pvc声明它时
basically creates or provisions

3697
02:55:57,279 --> 02:56:00,319
动态地创造或提供持久卷
persistent volumes dynamically whenever

3698
02:56:00,319 --> 02:56:03,840
用这种方式在集群中
pvc claims it and this way creating or

3699
02:56:03,840 --> 02:56:05,920
创造或者提供volume
provisioning volumes in a cluster

3700
02:56:05,920 --> 02:56:08,960
可以是自动化的
may be automated storage class

3701
02:56:08,960 --> 02:56:12,479
Storage Class(SC)也使用yaml配置文件创建
also gets created using yaml configuration file

3702
02:56:12,479 --> 02:56:14,960
这是一个例子文件
so this is an example file where we have

3703
02:56:14,960 --> 02:56:19,040
kind属性是Storage Class
the kind storage class storage class creates

3704
02:56:19,040 --> 02:56:22,560
SC在后台动态创建持久卷
persistent volumes dynamically in the background so

3705
02:56:22,560 --> 02:56:24,399
记得我们在PV组件中
remember we define storage

3706
02:56:24,399 --> 02:56:27,439
定义了存储后端
backend in the persistent volume component

3707
02:56:27,439 --> 02:56:30,800
现在我们必须在SC中也定义它
now we have to define it in the storage class component

3708
02:56:30,800 --> 02:56:34,720
为此，我们需要provisioner属性
and we do that using the provisioner attribute

3709
02:56:34,720 --> 02:56:37,760
它是SC配置的主要部分
which is the main part of the storage class configuration

3710
02:56:37,760 --> 02:56:39,920
因为它告诉了kubernetes
because it tells kubernetes which

3711
02:56:39,920 --> 02:56:41,680
选用哪一个特定的存储平台供应商
provisioner to be used

3712
02:56:41,680 --> 02:56:46,160
或云服务供应商
for a specific storage platform or cloud provider

3713
02:56:46,160 --> 02:56:50,080
来创建持久卷
to create the persistent volume component out of it

3714
02:56:50,080 --> 02:56:52,160
因此每个存储后端都有自己的
so each storage backend has its own

3715
02:56:52,160 --> 02:56:55,120
kubernetes在内部分配的供应商
provisioner that kubernetes offers internally

3716
02:56:55,120 --> 02:56:58,160
它们的前缀是kubernetes.io
which are prefixed with kubernetes.io

3717
02:56:58,160 --> 02:57:02,560
比如这个，这些是内部供应商
like this one here and these are internal provisioners

3718
02:57:02,560 --> 02:57:05,760
对于其他存储类型
and for others or other storage types

3719
02:57:05,760 --> 02:57:09,680
他们是外部的供应商
they're external provisioners that you have to

3720
02:57:09,680 --> 02:57:12,880
你必须在SC中明确地查找并使用它们
then explicitly go and find and use that

3721
02:57:12,880 --> 02:57:17,600
除了provisioner属性
in your storage class and in addition to provisioner attribute

3722
02:57:17,600 --> 02:57:20,000
我们配置
we configure parameters of the storage

3723
02:57:20,000 --> 02:57:23,520
想请求的持久卷的参数，像这样
we want to request for our persistent volume like this

3724
02:57:23,520 --> 02:57:27,200
SC基本上是另一个抽象层
one's here so storage class is basically another abstraction

3725
02:57:27,200 --> 02:57:30,800
它抽象了底层的存储器供应商
level that abstracts the underlying storage provider

3726
02:57:30,800 --> 02:57:33,200
以及该存储的参数
as well as parameters for that storage

3727
02:57:33,200 --> 02:57:35,520
存储的特性
characteristics for the storage

3728
02:57:35,520 --> 02:57:38,800
比如什么磁盘类型等等
like what disk type or etc

3729
02:57:38,800 --> 02:57:42,560
所以它是怎么工作的，或者说你怎么在pod配置中用SC呢
so how does it work or how do you use storage class

3730
02:57:42,560 --> 02:57:45,279
和持久卷相同
in the pod configuration same as

3731
02:57:45,279 --> 02:57:47,840
它是被请求
persistent volume it is requested or

3732
02:57:47,840 --> 02:57:52,000
或者说被pvc声明的，所以在pvc中
claimed by pvc so in the pvc configuration

3733
02:57:52,000 --> 02:57:55,040
这里我们添加了额外的属性
here we add additional attribute

3734
02:57:55,040 --> 02:57:58,560
这就是所谓的storageclassName
that is called storage class name that

3735
02:57:58,560 --> 02:58:02,640
它引用要使用的SC
references the storage class to be used to create

3736
02:58:02,640 --> 02:58:08,720
以创建满足PVC声明要求的持久卷
a persistent volume that satisfies the claims of this

3737
02:58:08,720 --> 02:58:11,760
所以现在当pod通过PVC声明一个存储
pvc so now when a pod claims

3738
02:58:11,760 --> 02:58:15,120
PVC将会从相应的SC
storage through pvc the pvc will request

3739
02:58:15,120 --> 02:58:16,160
请求存储
that storage from

3740
02:58:16,160 --> 02:58:19,520
SC将通过provisioner对应实际的存储后端
storage class which then will provision

3741
02:58:19,520 --> 02:58:22,720
提供或
or create persistent volume that

3742
02:58:22,720 --> 02:58:26,240
创建持久卷
meets the needs of that claim using provisioner

3743
02:58:26,240 --> 02:58:29,359
以满足该声明使用的需要
from the actual storage backend now this

3744
02:58:29,359 --> 02:58:32,479
这个高水平的概览应该可以帮助你理解
should help you understand the concepts of how

3745
02:58:32,479 --> 02:58:37,000
在kubernetes中数据持久化的众多概念
data is persisted in kubernetes is a high level overview

3746
02:58:40,000 --> 02:58:41,680
在这集视频中，我们将讨论
in this video we're going to talk about

3747
02:58:41,680 --> 02:58:44,240
kubernetes中的StatefulSet是什么
what stateful set is in kubernetes

3748
02:58:44,240 --> 02:58:46,960
它的目的是什么
and what purpose it has so what is

3749
02:58:46,960 --> 02:58:48,319
那么什么是StatefulSet呢
stateful set

3750
02:58:48,319 --> 02:58:50,960
它是一种kubernetes组件
it's a kubernetes component that is used

3751
02:58:50,960 --> 02:58:53,600
专门用于有状态的应用程序
specifically for stateful applications

3752
02:58:53,600 --> 02:58:55,439
为了理解这一点，首先你
so in order to understand that first you

3753
02:58:55,439 --> 02:58:58,880
需要了解什么是有状态的应用程序
need to understand what a stateful application is

3754
02:58:58,880 --> 02:59:02,720
有状态应用程序的例子是所有数据库
examples of stateful applications are all databases

3755
02:59:02,720 --> 02:59:06,560
像mysql elasticsearch mongodb等
like mysql elasticsearch mongodb etc

3756
02:59:06,560 --> 02:59:09,359
或任何存储数据以跟踪状态的
or any application that stores data to

3757
02:59:09,359 --> 02:59:11,200
应用程序
keep track of its state

3758
02:59:11,200 --> 02:59:13,680
换句话说，这些都是
in other words these are applications

3759
02:59:13,680 --> 02:59:16,319
通过保存信息到存储器以跟踪状态的应用
that track state by saving that information

3760
02:59:16,319 --> 02:59:19,200
而无状态的应用程序
in some storage stateless applications

3761
02:59:19,200 --> 02:59:20,319
另一方面
on the other hand

3762
02:59:20,319 --> 02:59:23,520
则不保留以前交互的记录
do not keep records of previous interaction

3763
02:59:23,520 --> 02:59:26,960
每个请求或交互都是
and each request or interaction is handled

3764
02:59:26,960 --> 02:59:30,960
作为一个全新的孤立的交互来处理的
as a completely new isolated interaction

3765
02:59:30,960 --> 02:59:32,560
完全基于
based entirely on the information that

3766
02:59:32,560 --> 02:59:34,720
伴随它而来的信息
comes with it and sometimes

3767
02:59:34,720 --> 02:59:36,800
有时无状态应用程序会连接到
stateless applications connect to the

3768
02:59:36,800 --> 02:59:38,080
有状态应用程序
stateful application

3769
02:59:38,080 --> 02:59:41,359
并转发请求
to forward those requests so imagine a

3770
02:59:41,359 --> 02:59:43,920
所以想象一个简单的应用程序设置
simple setup of a node.js application

3771
02:59:43,920 --> 02:59:46,960
node.js被连接到mongodb数据库
that is connected to mongodb database

3772
02:59:46,960 --> 02:59:50,800
当一个请求进入node.js应用程序时
when a request comes in to the node.js application

3773
02:59:50,800 --> 02:59:52,880
它不依赖于任何先前的数据
it doesn't depend on any previous data

3774
02:59:52,880 --> 02:59:55,439
来处理这个传入请求
to handle this incoming request

3775
02:59:55,439 --> 03:00:00,080
它可以根据请求本身的有效载荷来处理
it can handle it based on the payload in the request itself

3776
03:00:00,080 --> 03:00:03,040
现在，一个典型的这样的请求将
now a typical such request will

3777
03:00:03,040 --> 03:00:04,960
另外需要根据数据库中的数据进行更新
additionally need to update some

3778
03:00:04,960 --> 03:00:08,640
或查询数据库中的数据
data in the database or query the data

3779
03:00:08,640 --> 03:00:11,520
这就是mongodb发挥作用的地方
that's where mongodb comes in so when

3780
03:00:11,520 --> 03:00:14,399
node.js将请求转发给mongodb
node.js forwards that request to mongodb

3781
03:00:14,399 --> 03:00:19,040
mongodb将基于以前的状态更新数据
mongodb will update the data based on its previous state

3782
03:00:19,040 --> 03:00:22,160
或者从它的存储中查询数据
or query the data from its storage so

3783
03:00:22,160 --> 03:00:24,240
所以对于每个请求，它都需要处理数据
for each request it needs to handle data

3784
03:00:24,240 --> 03:00:26,399
显然总是取决于
and obviously always depends on the

3785
03:00:26,399 --> 03:00:29,920
最新的数据或状态从而使结果可用
most up-to-date data or state to be available

3786
03:00:29,920 --> 03:00:32,240
而nodejs只是一个传递器
while nodejs is just a pass-through for

3787
03:00:32,240 --> 03:00:34,000
传递数据更新或查询的请求
data updates or queries

3788
03:00:34,000 --> 03:00:37,120
它只处理代码
and it just processes code

3789
03:00:37,120 --> 03:00:39,279
因为有状态和无状态应用程序
now because of this difference between

3790
03:00:39,279 --> 03:00:42,000
两者之间的差异
stateful and stateless applications

3791
03:00:42,000 --> 03:00:45,279
它们都使用kubernetes中的不同组件
they're both deployed different ways using

3792
03:00:45,279 --> 03:00:48,720
以不同的方式部署
different components in kubernetes

3793
03:00:48,720 --> 03:00:50,880
无状态应用程序
stateless applications are deployed

3794
03:00:50,880 --> 03:00:52,720
使用deployment组件
using deployment component

3795
03:00:52,720 --> 03:00:55,840
deployment是pod的抽象
deployment is an abstraction of pods

3796
03:00:55,840 --> 03:00:58,960
并允许你复制应用程序
and allows you to replicate that application

3797
03:00:58,960 --> 03:01:02,800
即可以在集群中
meaning run two five ten identical parts of the same

3798
03:01:02,800 --> 03:01:05,600
运行两个、五个、十个相同的无状态应用程序
stateless application in the cluster so

3799
03:01:05,600 --> 03:01:08,479
无状态应用程序使用deployment
while stateless applications are deployed using

3800
03:01:08,479 --> 03:01:12,160
而有状态应用程序在k8s中
deployment stateful applications in kubernetes

3801
03:01:12,160 --> 03:01:16,479
是使用StatefulSet组件部署的
are deployed using stateful set components

3802
03:01:16,479 --> 03:01:18,399
就像deployment
and just like deployment statefulset

3803
03:01:18,399 --> 03:01:20,000
StatefulSet一样使得复制成为可能
makes it possible to replicate

3804
03:01:20,000 --> 03:01:23,600
或者也能运行多个副本
the stateful app parts or to run multiple

3805
03:01:23,600 --> 03:01:27,040
换句话说，它们都是管理副本
replicas of it in other words they both manage

3806
03:01:27,040 --> 03:01:30,800
基于同一个指定规格容器的副本
parts that are based on an identical container

3807
03:01:30,800 --> 03:01:34,080
你也可以以同样的方式
specification and you can also configure

3808
03:01:34,080 --> 03:01:37,359
为它们二者都配置存储
storage with both of them equally

3809
03:01:37,359 --> 03:01:40,399
既然它们都是
in the same way so if both

3810
03:01:40,399 --> 03:01:44,880
管理pod的副本
manage the replication of pods and also configuration of

3811
03:01:44,880 --> 03:01:48,000
并且以相同的方式保存数据
data persistence in the same way the question

3812
03:01:48,000 --> 03:01:52,319
那么问题来了，这是很多人问的，也是很多人常常困惑的
is what a lot of people ask and are also often confused about

3813
03:01:52,319 --> 03:01:54,080
两者有什么区别
what is the difference between those two

3814
03:01:54,080 --> 03:01:56,880
为什么我们对于每种类型的应用程序
components why we use different ones

3815
03:01:56,880 --> 03:02:00,080
使用不同的组件，所以下一节
for each type of application so in the next section

3816
03:02:00,080 --> 03:02:02,319
我们来谈谈不同之处
we're gonna talk about the differences

3817
03:02:02,319 --> 03:02:04,720
现在复制有状态的应用程序
now replicating stateful application

3818
03:02:04,720 --> 03:02:08,160
是更困难的，因为有几个
is more difficult and has a couple of requirements

3819
03:02:08,160 --> 03:02:10,640
无状态应用程序所没有的需求
that stateless applications do not have

3820
03:02:10,640 --> 03:02:11,920
我们首先来看看
so let's look at this

3821
03:02:11,920 --> 03:02:15,520
一个mysql数据库的例子
first with the example of a mysql database

3822
03:02:15,520 --> 03:02:18,560
假设您有一个mysql数据库的pod
let's say you have one mysql database part

3823
03:02:18,560 --> 03:02:21,760
处理来自java应用程序的请求
that handles requests from a java application

3824
03:02:21,760 --> 03:02:24,880
该应用程序是由deployment组件部署的
which is deployed using a deployment component

3825
03:02:24,880 --> 03:02:28,720
假设你扩展了java应用到三个pod
and let's say you scale the java application to three parts

3826
03:02:28,720 --> 03:02:31,760
这样他们就能并行处理更多的客户请求
so they can handle more client requests

3827
03:02:31,760 --> 03:02:35,120
同时，你想要扩展mysql应用程序
in parallel you want to scale mysql app

3828
03:02:35,120 --> 03:02:37,279
因此它可以处理更多的java请求
so it can handle more java requests as

3829
03:02:37,279 --> 03:02:39,600
扩展java应用程序的方式是很直接的
well scaling your java application

3830
03:02:39,600 --> 03:02:44,319
java应用程序副本
here is pretty straightforward java applications replica parts

3831
03:02:44,319 --> 03:02:47,439
会是相同的和可互换的
will be identical and interchangeable so

3832
03:02:47,439 --> 03:02:49,439
所以你可以很容易地
you can scale it

3833
03:02:49,439 --> 03:02:51,520
利用deployment进行扩展
using a deployment pretty easily

3834
03:02:51,520 --> 03:02:53,439
deployment将按任意顺序创建pod
deployment will create the pods in any

3835
03:02:53,439 --> 03:02:55,359
按任意随机的顺序
order in any random order

3836
03:02:55,359 --> 03:02:58,880
最后会得到随机的哈希值作为pod名称
they will get random hashes at the end of the pod name

3837
03:02:58,880 --> 03:03:00,960
他们将获得一个service来做负载均衡
they will get one service that load

3838
03:03:00,960 --> 03:03:03,680
来让合适副本处理对应请求
balances to any one of the replica pods

3839
03:03:03,680 --> 03:03:06,000
同样地，当你删除它们时
for any request and also when you delete

3840
03:03:06,000 --> 03:03:10,080
它们会在同一时间被按随机顺序删除
them they get deleted in a random order or at the same time

3841
03:03:10,080 --> 03:03:12,240
或者当你缩小它们规模的时候
right or when you scale them down

3842
03:03:12,240 --> 03:03:15,600
例如，从三个副本减到两个
from three to two replicas for example one

3843
03:03:15,600 --> 03:03:19,200
某个随机的副本pod会被选择删除
random replica part gets chosen to be deleted

3844
03:03:19,200 --> 03:03:22,319
所以并不复杂，但另一方面
so no complications there on the other hand

3845
03:03:22,319 --> 03:03:25,439
mysql副本无法在同一时刻
mysql part replicas cannot be created

3846
03:03:25,439 --> 03:03:27,520
被按任意次序创建或删除
and deleted at the same time

3847
03:03:27,520 --> 03:03:31,120
它们不可以被随机处理
in any order and they can't be randomly addressed

3848
03:03:31,120 --> 03:03:34,399
原因是那些副本
and the reason for that is because the replica

3849
03:03:34,399 --> 03:03:37,760
事实上，并不完全相同
parts are not identical in fact

3850
03:03:37,760 --> 03:03:40,880
它们从共同的pod构建
they each have their own additional identity

3851
03:03:40,880 --> 03:03:44,240
但在共同的蓝图之上
on top of the common blueprint of the pod

3852
03:03:44,240 --> 03:03:47,520
又有各自额外的身份标识
that they get created from and giving each

3853
03:03:47,520 --> 03:03:51,840
并且赋予了每个pod一个自己的私人标识
part its own required individual identity

3854
03:03:51,840 --> 03:03:55,279
这就是StatefulSet与deployment的不同之处
is actually what stateful set does different from

3855
03:03:55,279 --> 03:03:57,840
对于StatefulSet来说，其中的每一个pod
deployment it maintains a sticky

3856
03:03:57,840 --> 03:04:00,160
都维持着一个紧紧相连的标识
identity for each of its pots

3857
03:04:00,160 --> 03:04:01,920
就像我说的，这些pod被创建时
and as i said these pods are created

3858
03:04:01,920 --> 03:04:03,520
来自同一规范
from the same specification

3859
03:04:03,520 --> 03:04:06,160
但它们是不可互换的
but they're not interchangeable each has

3860
03:04:06,160 --> 03:04:08,160
每一个都有一个持久的标识符
a persistent identifier

3861
03:04:08,160 --> 03:04:11,359
它在任何重调度时都会保持着
that it maintains across any rescheduling

3862
03:04:11,359 --> 03:04:15,120
也就是说当一个pod死了，并被新的取代时
so meaning when pod dies and it gets replaced

3863
03:04:15,120 --> 03:04:18,399
它仍会保持这个身份表示
by a new part it keeps that identity so

3864
03:04:18,399 --> 03:04:21,120
你现在可能要问的问题是
the question you may be asking now is

3865
03:04:21,120 --> 03:04:24,960
为什么这些pod需要它们自己的身份标识？
why do these parts need their own identities why they can't be

3866
03:04:24,960 --> 03:04:27,359
为什么它们不能就像deployment一样可互换？
interchangeable just like with deployment

3867
03:04:27,359 --> 03:04:29,520
所以这是为什么呢
so why is that and this is a concept

3868
03:04:29,520 --> 03:04:31,040
你需要理解的一个关于扩展数据库应用程序的概念是
that you need to understand about

3869
03:04:31,040 --> 03:04:34,720
一般
scaling database applications in general

3870
03:04:34,720 --> 03:04:37,200
当你启动单个mysql pod时
when you start with a single mysql pod

3871
03:04:37,200 --> 03:04:38,720
它将同时用于两者读写数据
it will be used for both

3872
03:04:38,720 --> 03:04:43,200
但当你再添加一个时
reading and writing data but when you add a second one

3873
03:04:43,200 --> 03:04:45,920
它不能采取同样的方式，因为如果
it cannot act the same way because if

3874
03:04:45,920 --> 03:04:48,960
你允许两个mysql的独立实例
you allow two independent instances of mysql to

3875
03:04:48,960 --> 03:04:50,720
均能改变相同的数据
change the same data

3876
03:04:50,720 --> 03:04:53,520
将以数据不一致告终
you will end up with data inconsistency

3877
03:04:53,520 --> 03:04:56,560
所以要有一种机制决定
so instead there is a mechanism that decides

3878
03:04:56,560 --> 03:05:00,880
只有一个pod被允许写或更改数据
that only one part is allowed to write or change the data

3879
03:05:00,880 --> 03:05:04,640
同时多个mysql实例共享
which is shared reading at the same time by multiple

3880
03:05:04,640 --> 03:05:08,080
共享对同一堆数据的读权限
parts mysql instances from the same data

3881
03:05:08,080 --> 03:05:11,200
完全没问题
is completely fine and the pod that is allowed to

3882
03:05:11,200 --> 03:05:14,560
那个被允许更新数据的pod被称为master
update the data is called the master the others

3883
03:05:14,560 --> 03:05:17,520
其它的被称为slave
are called slaves so this is the first

3884
03:05:17,520 --> 03:05:20,319
所以这是第一个区分这些pod的点
thing that differentiates these parts from each other

3885
03:05:20,319 --> 03:05:23,040
所以不是所有pod都是一样的
so not all pods are same identical but

3886
03:05:23,040 --> 03:05:24,399
有一个master pod
there is a master pod

3887
03:05:24,399 --> 03:05:26,560
剩下的是slave pod
and they're the slave parts right and

3888
03:05:26,560 --> 03:05:28,640
从存储的角度看
there's also difference between those

3889
03:05:28,640 --> 03:05:32,319
slave pod之间也有区别，这是第二个点
slave parts in terms of storage which is the next point

3890
03:05:32,319 --> 03:05:34,960
所以问题是这些pod
so the thing is that these pods do not

3891
03:05:34,960 --> 03:05:36,800
并不能访问相同的物理存储器
have access to the same

3892
03:05:36,800 --> 03:05:40,399
即使他们使用相同的数据
physical storage even though they use the same data

3893
03:05:40,399 --> 03:05:44,160
他们也没在用相同的物理存储器来存储数据
they're not using the same physical storage of the data

3894
03:05:44,160 --> 03:05:47,439
他们都有自己的存储副本
they each have their own replicas of the storage

3895
03:05:47,439 --> 03:05:50,560
每个都可以访问自身
that each one of them can access for itself

3896
03:05:50,560 --> 03:05:54,399
这意味着每个pod的副本任何时候
and this means that each pod replica at any time

3897
03:05:54,399 --> 03:05:56,399
必须与另一个pod副本都有相同的数据
must have the same data as the other

3898
03:05:56,399 --> 03:05:58,479
为了达到这个目的，他们
ones and in order to achieve that they

3899
03:05:58,479 --> 03:06:01,200
必须持续同步他们的数据
have to continuously synchronize their data

3900
03:06:01,200 --> 03:06:05,120
既然master是唯一被允许改变数据的
and since master is the only one allowed to change data

3901
03:06:05,120 --> 03:06:09,200
而slave们需要关心它们自己的数据存储
and the slaves need to take care of their own data storage

3902
03:06:09,200 --> 03:06:12,319
显然slave们一定知道每一个更改
obviously the slaves must know about each

3903
03:06:12,319 --> 03:06:16,479
这样就可以自己更新数据到最新状态
such change so they can update their own data storage

3904
03:06:16,479 --> 03:06:20,240
为下一次查询请求做准备
to be up to date for the next query requests

3905
03:06:20,240 --> 03:06:24,240
这样的集群数据库需要一个机制
and there's a mechanism in such clustered database setup

3906
03:06:24,240 --> 03:06:28,160
允许连续数据同步
that allows for continuous data synchronization

3907
03:06:28,160 --> 03:06:32,080
master更改数据并且所有slave更新自己的数据存储
master changes data and all slaves update their own data

3908
03:06:32,080 --> 03:06:36,160
保持同步并确保每个pod都有相同的状态
storage to keep in sync and to make sure that each pod

3909
03:06:36,160 --> 03:06:38,399
现在假设
has the same state now let's say you

3910
03:06:38,399 --> 03:06:40,800
你有mysql的一个master和两个slave pod
have one master and two slave

3911
03:06:40,800 --> 03:06:44,080
一个新的pod副本加入现有设置
parts of mysql now what happens when a new pod

3912
03:06:44,080 --> 03:06:47,359
会发生什么
replica joins the existing setup because now

3913
03:06:47,359 --> 03:06:50,880
因为新的pod需要创造自己的存储
that new pod also needs to create its own

3914
03:06:50,880 --> 03:06:54,000
然后数据同步
storage and then take care of synchronizing it

3915
03:06:54,000 --> 03:06:56,399
所以它首先要从之前的pod
what happens is that it first clones the

3916
03:06:56,399 --> 03:06:58,720
克隆数据
data from the previous part not just

3917
03:06:58,720 --> 03:07:01,120
不是从集群中的任意一个pod
any pod in the in the setup but always

3918
03:07:01,120 --> 03:07:02,720
而是从上一个pod
from the previous part

3919
03:07:02,720 --> 03:07:06,000
一旦它克隆了最新的数据
and once it has the up-to-date data cloned

3920
03:07:06,000 --> 03:07:08,240
它开始连续同步
it starts continuous synchronization as

3921
03:07:08,240 --> 03:07:10,240
监听master pod所做的任何修改
well to listen for any

3922
03:07:10,240 --> 03:07:13,200
这也意味着
updates by masterpod and this also means

3923
03:07:13,200 --> 03:07:14,960
我想指出这一点
and i want to point this out since it's

3924
03:07:14,960 --> 03:07:16,720
很有趣的一点
pretty interesting point

3925
03:07:16,720 --> 03:07:18,720
这意味着你的有状态应用程序
it means that you can actually have a

3926
03:07:18,720 --> 03:07:21,200
可以得到的是一个临时存储
temporary storage for a stateful application

3927
03:07:21,200 --> 03:07:23,600
而不是保存的数据
and not persist the data at all since

3928
03:07:23,600 --> 03:07:26,319
因为pod之间在复制数据
the data gets replicated between the pods

3929
03:07:26,319 --> 03:07:29,040
理论上有可能
so theoretically it is possible to just

3930
03:07:29,040 --> 03:07:30,960
只依赖数据复制维持集群
rely on data replication

3931
03:07:30,960 --> 03:07:34,080
但这也意味着
between the pots but this will also mean that

3932
03:07:34,080 --> 03:07:37,120
当所有pod死了
the whole data will be lost when

3933
03:07:37,120 --> 03:07:39,279
所有数据都会丢失
all the parts die so for example if

3934
03:07:39,279 --> 03:07:41,120
比如若StatefulSet被删除或
stateful set gets deleted or

3935
03:07:41,120 --> 03:07:43,680
集群或所有节点崩溃
the cluster crashes or all the nodes

3936
03:07:43,680 --> 03:07:46,319
而pod副本都在那里运行
where these pod replicas are running crash

3937
03:07:46,319 --> 03:07:49,279
或者所有pod都在同一时间死亡
and every pod dies at the same time the

3938
03:07:49,279 --> 03:07:50,319
数据就会消失
data will be gone

3939
03:07:50,319 --> 03:07:52,319
因此，使用数据持久化
and therefore it's still a best practice

3940
03:07:52,319 --> 03:07:54,319
仍然是有状态应用程序的最佳实践
to use data persistence

3941
03:07:54,319 --> 03:07:57,840
丢失数据在大部分数据库用例上
for stateful applications if losing the data will be

3942
03:07:57,840 --> 03:08:01,760
都是无法接受的
unacceptable which is the case in most database applications

3943
03:08:01,760 --> 03:08:04,960
而有持久化存储，数据将幸存
and with persistent storage data will survive

3944
03:08:04,960 --> 03:08:08,479
即使StatefulSet的所有pod都死了
even if all the parts of the stateful set die

3945
03:08:08,479 --> 03:08:10,640
或者即使你删除了整个StatefulSet组件
or even if you delete the complete

3946
03:08:10,640 --> 03:08:13,359
所有pod也会紧跟着被消灭
stateful set component and all the parts get

3947
03:08:13,359 --> 03:08:16,560
而持久化的存储和数据
wiped out as well the persistent

3948
03:08:16,560 --> 03:08:20,080
将得到保留
storage and the data will still remain because

3949
03:08:20,080 --> 03:08:23,920
因为持久卷的生命周期
persistent volume uh life cycle isn't connected

3950
03:08:23,920 --> 03:08:26,960
与其它组件如deployement或StatefulSet
or isn't tied to a life cycle of

3951
03:08:26,960 --> 03:08:30,399
的生命周期无关
other components like deployment or

3952
03:08:30,399 --> 03:08:33,439
实现这个的方法是
stateful set and the way to do this is

3953
03:08:33,439 --> 03:08:37,200
为您的StatefulSet配置持久卷
configuring persistent volumes for your stateful set

3954
03:08:37,200 --> 03:08:40,720
因为每个pod都有自己的数据存储
and since each pod has its own data storage

3955
03:08:40,720 --> 03:08:43,279
意味着它们自己的持久卷
meaning it's their own persistent volume

3956
03:08:43,279 --> 03:08:46,160
由它自己支持的物理存储器做备份
that is then backed up by its own physical storage

3957
03:08:46,160 --> 03:08:48,640
其中包括同步数据或
which includes the synchronized data or

3958
03:08:48,640 --> 03:08:50,640
复制数据库数据
the replicated database data

3959
03:08:50,640 --> 03:08:53,760
还有pod的状态
but also the state of the pod

3960
03:08:53,760 --> 03:08:56,960
每个pod都有自己的状态
so each pod has its own state which has

3961
03:08:56,960 --> 03:09:01,200
关于它是master还是slave
information about whether it's a masterpod or a slave

3962
03:09:01,200 --> 03:09:04,000
或其他各自的身份标识
or other individual characteristics and

3963
03:09:04,000 --> 03:09:05,439
所有这些都被存储到
all of this gets stored

3964
03:09:05,439 --> 03:09:09,200
pod自己的存储器中
in the pot's own storage and that means

3965
03:09:09,200 --> 03:09:12,240
当一个pod死了，被替换了
when a pot dies and gets replaced

3966
03:09:12,240 --> 03:09:16,080
其持久化的标识将确保
the persistent pot identifiers make sure that the

3967
03:09:16,080 --> 03:09:19,439
存储卷被替代pod重新挂载
storage volume gets reattached

3968
03:09:19,439 --> 03:09:23,200
就像我说的，因为
to the replacement pod as i said because that storage

3969
03:09:23,200 --> 03:09:26,399
存储除了有复制的数据外，还包含了pod的状态
has the state of the pod in addition to

3970
03:09:26,399 --> 03:09:29,120
你可以再一次克隆数据
that replicated data i mean you can clone the data

3971
03:09:29,120 --> 03:09:32,560
不会有问题
again that will be no problem but it shouldn't lose

3972
03:09:32,560 --> 03:09:35,760
但是不应该丢失它的状态或者说是身份标识
its state or identity state so to say

3973
03:09:35,760 --> 03:09:39,040
为了能够重新挂载
and for this reattachment to work it's

3974
03:09:39,040 --> 03:09:41,279
使用远程存储很重要
important to use a remote storage

3975
03:09:41,279 --> 03:09:44,080
因为如果pod被重新调度
because if the pod gets rescheduled from

3976
03:09:44,080 --> 03:09:45,840
从一个节点调度到另一个节点
one node to another node

3977
03:09:45,840 --> 03:09:48,319
之前的存储必须
the previous storage must be available

3978
03:09:48,319 --> 03:09:50,239
在另一个节点上也是可用的
on the other node as well

3979
03:09:50,239 --> 03:09:52,319
你不能用本地卷来做这个
and you cannot do that using local

3980
03:09:52,319 --> 03:09:53,920
因为它们通常是
volume storage because they are usually

3981
03:09:53,920 --> 03:09:55,840
绑定到特定的节点上的
tied to a specific node

3982
03:09:55,840 --> 03:09:59,359
deployment和StatefulSet间的最后一个区别
and the last difference between deployment and

3983
03:09:59,359 --> 03:10:02,880
是我之前提到的
stateful set is something that i mentioned

3984
03:10:02,880 --> 03:10:05,920
即pod标识
before is the pod identifier meaning that

3985
03:10:05,920 --> 03:10:08,720
每个pod都有自己的标识
every pod has its own identifier so

3986
03:10:08,720 --> 03:10:12,560
不像deployment那样最后得到随机散列
unlike deployment where pods get random hashes at the end

3987
03:10:12,560 --> 03:10:17,520
StatefulSet的pod会有固定次序的名字
stateful set pods get fixed ordered names which is made up

3988
03:10:17,520 --> 03:10:19,200
由StatefulSet的名字以及
of the stateful set name

3989
03:10:19,200 --> 03:10:22,080
是从0开始的序数组成
and ordinal it starts from zero and each

3990
03:10:22,080 --> 03:10:23,840
每个额外的pod将得到下一个数字
additional part will get

3991
03:10:23,840 --> 03:10:27,680
如果你创建一个StatefulSet名为mysql
the next numeral so if you create a stateful set called mysql

3992
03:10:27,680 --> 03:10:31,040
里面有三个副本，名字分别
with three replicas you'll have parts with names

3993
03:10:31,040 --> 03:10:34,479
等于0 1和2
must equal zero one and two the first one is

3994
03:10:34,479 --> 03:10:36,640
按启动顺序，第一个是master，然后是slave
the master and then come the slaves in

3995
03:10:36,640 --> 03:10:39,040
一个重要的注意事项是
the order of startup an important note

3996
03:10:39,040 --> 03:10:41,359
StatefulSet将不会
here is that the stateful set

3997
03:10:41,359 --> 03:10:45,200
在副本中创建下一个pod
will not create the next part in the replica

3998
03:10:45,200 --> 03:10:48,319
如果前一个还没准备好并运行的话
if the previous one isn't already up

3999
03:10:48,319 --> 03:10:52,880
如果第一个pod创建失败了
and running if first pod creation for example failed

4000
03:10:52,880 --> 03:10:55,120
或者在待机状态，下一个也不会被创建
or if it was pending the next one won't

4001
03:10:55,120 --> 03:10:57,359
而只是会等待
get created at all it would just wait

4002
03:10:57,359 --> 03:11:00,479
同样的，删除也是按顺序的
and the same order is held deletion

4003
03:11:00,479 --> 03:11:02,960
但是顺序相反
but in reversed order so for example if

4004
03:11:02,960 --> 03:11:04,160
如果您删除了StatefulSet
you deleted the stateful

4005
03:11:04,160 --> 03:11:08,239
或者把它规模从3缩小到1
set or if you scaled it down to one for example from

4006
03:11:08,239 --> 03:11:10,720
删除将从最后一个pod开始
three the deletion will start from the

4007
03:11:10,720 --> 03:11:14,640
所以第一个将被删除的是mysql-2
last part so my sql two will get deleted first

4008
03:11:14,640 --> 03:11:18,000
直到该pod成功删除
it will wait until that part is successfully deleted

4009
03:11:18,000 --> 03:11:21,279
才会删除mysql-1
and then it will delete my sql one

4010
03:11:21,279 --> 03:11:24,720
然后它会删除mysql-0
and then it will delete must equal zero and again

4011
03:11:24,720 --> 03:11:27,520
所有这些机制都是
all these mechanisms are in place in

4012
03:11:27,520 --> 03:11:29,359
为了保护数据
order to protect the data

4013
03:11:29,359 --> 03:11:33,279
还有有状态应用程序依赖的状态
and the state that the stateful application depends on

4014
03:11:33,279 --> 03:11:36,560
除了这个固定的可预测的名字
in addition to this fixed predictable names

4015
03:11:36,560 --> 03:11:39,359
StatefulSet中的每个pod都有来自一个service的
each part in a stateful set gets its own

4016
03:11:39,359 --> 03:11:42,319
自己的dns端点，所以对于有状态应用程序
dns endpoint from a service so there's a service name

4017
03:11:42,319 --> 03:11:46,000
也会有serviceName属性，就像deployment一样
for the stateful application just like for deployment for example

4018
03:11:46,000 --> 03:11:49,439
从而定位到任何副本的pod
that will address any replica pod

4019
03:11:49,439 --> 03:11:53,359
除此之外在StatefulSet中的每个pod
and plus in addition to that there is individual dns name

4020
03:11:53,359 --> 03:11:57,040
还有个人dns名称，这是deployment中的pod所没有的
for each pod which deployment pods do not have

4021
03:11:57,040 --> 03:12:00,880
个人dns名称由pod的名字
the individual dns names are made up of pod name

4022
03:12:00,880 --> 03:12:04,000
以及管理service的名称组成
and the manage or the governing service

4023
03:12:04,000 --> 03:12:05,439
后者基本上是
name which is basically

4024
03:12:05,439 --> 03:12:09,680
您在StatefulSet内部定义的service的名称
a service name that you define inside the stateful set

4025
03:12:09,680 --> 03:12:13,279
这两个特征意味着有
so these two characteristics meaning having

4026
03:12:13,279 --> 03:12:16,720
可预测的或固定的名字
a predictable or fixed name as well as

4027
03:12:16,720 --> 03:12:20,239
它是固定的个人dns名称
it's fixed individual dns name means that

4028
03:12:20,239 --> 03:12:23,920
意味着当pod重新启动时，ip地址将改变
when pod restarts the ip address will change

4029
03:12:23,920 --> 03:12:27,120
但名字和端点保持不变
but the name and end point will stay the same

4030
03:12:27,120 --> 03:12:29,279
所以我才说pod有着紧密相连的身份标识
that's why i said pods get sticky

4031
03:12:29,279 --> 03:12:31,120
即使在重启
identities so it gets

4032
03:12:31,120 --> 03:12:33,680
也会与该标识绑定
stuck to it even between the restarts

4033
03:12:33,680 --> 03:12:37,279
绑定标识保证了每个副本的pod
and the sticky identity makes sure that each replica pod

4034
03:12:37,279 --> 03:12:40,319
能够保持它的状态和它的作用
can retain its state and its role

4035
03:12:40,319 --> 03:12:43,200
即使它死了，被重新创建了
even when it dies and gets recreated and

4036
03:12:43,200 --> 03:12:44,880
最后我想提一个重要的知识点
finally i want to mention an important

4037
03:12:44,880 --> 03:12:48,160
如您所见，利用持久化存储复制有状态应用程序
point here as you see replicating stateful apps

4038
03:12:48,160 --> 03:12:51,279
如数据库时
like databases with its persistent storage

4039
03:12:51,279 --> 03:12:53,680
需要一个复杂的机制
requires a complex mechanism and

4040
03:12:53,680 --> 03:12:55,040
kubernetes会帮助你并支持你
kubernetes helps you

4041
03:12:55,040 --> 03:12:57,359
设置所有东西
and supports you to set this whole thing

4042
03:12:57,359 --> 03:13:01,680
但你还是需要一个人做很多
up but you still need to do a lot by yourself where kubernetes

4043
03:13:01,680 --> 03:13:03,520
k8s并没有实质的帮助
doesn't actually help you or doesn't

4044
03:13:03,520 --> 03:13:05,520
或者说没有为您提供现成的解决方案
provide you out-of-the-box solutions

4045
03:13:05,520 --> 03:13:07,359
例如，你需要配置
for example you need to configure the

4046
03:13:07,359 --> 03:13:09,600
克隆和数据同步
cloning and data synchronization

4047
03:13:09,600 --> 03:13:11,840
在StatefulSet中，也要
inside the stateful set and also make

4048
03:13:11,840 --> 03:13:13,600
让远程存储可用
the remote storage available

4049
03:13:13,600 --> 03:13:17,120
还要管理和备份
as well as take care of managing and backing it up

4050
03:13:17,120 --> 03:13:20,479
所有这些你都得自己做
all of these you have to do yourself and the reason

4051
03:13:20,479 --> 03:13:23,439
因为有状态的应用程序不是
is that stateful applications are not a

4052
03:13:23,439 --> 03:13:26,479
完美的适合容器化的环境
perfect candidate for containerized environments

4053
03:13:26,479 --> 03:13:30,239
事实上，docker kubernetes和更一般的容器化工具
in fact docker kubernetes and generally containerization

4054
03:13:30,239 --> 03:13:33,760
完美适配无状态应用程序
is perfectly fitting for stateless applications

4055
03:13:33,760 --> 03:13:36,880
没有任何状态和数据依赖
that do not have any state and data dependency

4056
03:13:36,880 --> 03:13:39,359
并且只处理代码，所以
and only process code so scaling and

4057
03:13:39,359 --> 03:13:44,000
在容器中缩放或复制它们是非常容易的
replicating them in containers is super easy

4058
03:13:46,399 --> 03:13:48,720
在这个视频中我会给你一个完整的
in this video i will give you a complete

4059
03:13:48,720 --> 03:13:50,960
kubernetes service的概述
overview of kubernetes services

4060
03:13:50,960 --> 03:13:54,960
首先，我将简要解释什么是kubernetes中的Service组件
first i'll explain shortly what service component is in kubernetes

4061
03:13:54,960 --> 03:13:57,439
等我们需要的时候，我们就
and when we need it and then we'll go

4062
03:13:57,439 --> 03:13:59,520
通过不同的service类型
through the different service types

4063
03:13:59,520 --> 03:14:03,200
ClusterIP类型，Headless类型，NodePort类型
cluster ip service headless service node port

4064
03:14:03,200 --> 03:14:05,680
以及LoadBalancer（负载均衡器）类型
and load balancer services i will

4065
03:14:05,680 --> 03:14:07,520
我会解释它们之间的区别
explain the differences between them

4066
03:14:07,520 --> 03:14:10,560
并说明什么时候用哪一个
and when to use which one so by the end

4067
03:14:10,560 --> 03:14:12,239
在视频最后你会有一个关于k8s的service的
of the video you will have a great

4068
03:14:12,239 --> 03:14:14,640
很全面的理解
understanding of kubernetes services

4069
03:14:14,640 --> 03:14:17,600
并且能够在实践中使用它们
and will be able to use them in practice

4070
03:14:17,600 --> 03:14:19,600
让我们开始吧
so let's get started

4071
03:14:19,600 --> 03:14:21,680
kubernetes中的service是什么
so what is the service in kubernetes and

4072
03:14:21,680 --> 03:14:22,960
我们为什么需要它
why do we need it

4073
03:14:22,960 --> 03:14:26,239
在kubernetes集群中，每个pod都有自己的
in a kubernetes cluster each pod gets its own

4074
03:14:26,239 --> 03:14:30,080
内部ip地址，但是在k8s中的pod都是暂态的
internal ip address but the pods in kubernetes

4075
03:14:30,080 --> 03:14:34,239
意味着它们来来去去会很频繁
are ephemeral meaning that they come and go very frequently

4076
03:14:34,239 --> 03:14:37,040
当pod重新启动或
and when the pod restarts or when old

4077
03:14:37,040 --> 03:14:39,040
一个老的pod死了，被新的pod取代
one dies and the new one gets

4078
03:14:39,040 --> 03:14:42,399
它会获得一个新的ip
started in its place it gets a new ip address

4079
03:14:42,399 --> 03:14:45,520
所以直接使用pod的ip地址是没有意义的
so it doesn't make sense to use pod ip addresses

4080
03:14:45,520 --> 03:14:47,279
因为那样你不得不
directly because then you would have to

4081
03:14:47,279 --> 03:14:51,600
每次pod被重建时都要调整
adjust that every time the pod gets recreated with the service

4082
03:14:51,600 --> 03:14:53,520
然而你有一个解决方案
however you have a solution

4083
03:14:53,520 --> 03:14:56,800
利用一个稳定的或静态的ip地址
of a stable or static ip address that stays

4084
03:14:56,800 --> 03:14:59,120
即使是在pod死掉的时候也能保持住
even when the pod dies so basically in

4085
03:14:59,120 --> 03:15:00,800
所以基本上在每个pod的前部
front of each pod

4086
03:15:00,800 --> 03:15:04,000
我们会设置一个service，它表示
we set a service which represents a persistent

4087
03:15:04,000 --> 03:15:07,040
持久的稳定的可访问该pod的ip地址
stable ip address access that pod

4088
03:15:07,040 --> 03:15:09,200
service还提供负载均衡
a service also provides load balancing

4089
03:15:09,200 --> 03:15:11,040
因为当你有pod的副本时
because when you have pod replicas

4090
03:15:11,040 --> 03:15:15,359
例如，你的微服务应用程序有三个副本
for example three replicas of your microservice application

4091
03:15:15,359 --> 03:15:18,880
或者mysql应用程序有三个副本
or three replicas of mysql application

4092
03:15:18,880 --> 03:15:22,800
service基本上会得到每一个
the service will basically get each request

4093
03:15:22,800 --> 03:15:26,720
指向mysql或你的微服务应用程序的请求
targeted to that mysql or your microservice application

4094
03:15:26,720 --> 03:15:30,000
然后转发到其中一个pod
and then forward it to one of those pods

4095
03:15:30,000 --> 03:15:33,359
这样客户端就可以调用一个稳定的ip地址
so clients can call a single stable ip

4096
03:15:33,359 --> 03:15:36,960
而不是调用单独的pod
address instead of calling each pod individually

4097
03:15:36,960 --> 03:15:40,399
因此，service起到松散耦合的作用
so services are a good abstraction for loose coupling

4098
03:15:40,399 --> 03:15:42,880
是集群内的通信的很好的抽象
for communication within the cluster so

4099
03:15:42,880 --> 03:15:47,359
不仅用于集群内的组件或pod通信
within the cluster components or pods inside the cluster but also

4100
03:15:47,359 --> 03:15:49,840
还可用于外部服务
from external services like if you have

4101
03:15:49,840 --> 03:15:52,000
如你有进入集群的浏览器请求
browser requests coming to the cluster

4102
03:15:52,000 --> 03:15:56,080
或者和外部数据库通信
or if you're talking to an external database for example

4103
03:15:56,080 --> 03:16:00,239
k8s中有几种类型的service
there are several types of services in kubernetes

4104
03:16:00,239 --> 03:16:03,680
第一个也是最常见的一个
the first and the most common one that you probably

4105
03:16:03,680 --> 03:16:07,120
可能是你将在大部分时间内使用的类型，ClusterIP
will use most of the time is the cluster ip type

4106
03:16:07,120 --> 03:16:09,279
这是service的默认类型
this is a default type of a service

4107
03:16:09,279 --> 03:16:10,479
即当你创建一个service
meaning when you create

4108
03:16:10,479 --> 03:16:13,760
但不指定类型时
a service and not specify a type

4109
03:16:13,760 --> 03:16:15,920
它将自动以ClusterIP为类型
it will automatically take cluster ip as

4110
03:16:15,920 --> 03:16:17,760
让我们看看
a type so let's see how

4111
03:16:17,760 --> 03:16:20,960
ClusterIP是如何工作的，以及在k8s的哪里使用它
cluster ip works and where it's used

4112
03:16:20,960 --> 03:16:24,239
想象我们在集群中
in kubernetes setup imagine we have

4113
03:16:24,239 --> 03:16:27,520
部署了一个微服务应用程序
a micro service application deployed in the cluster

4114
03:16:27,520 --> 03:16:31,439
所以我们有包含微服务的容器的pod
so we have a pod with microservice container

4115
03:16:31,439 --> 03:16:34,560
容器在其中运行
running inside that pod and beside that

4116
03:16:34,560 --> 03:16:36,640
除了微服务容器
microservice container we have

4117
03:16:36,640 --> 03:16:39,359
我们还有一个辅助容器，用来收集
a sidecar container that collects the

4118
03:16:39,359 --> 03:16:42,319
微服务的日志，然后发送到某个目标数据库
logs of the microservice and then sends that to

4119
03:16:42,319 --> 03:16:44,960
这两个容器
some destination database so these two

4120
03:16:44,960 --> 03:16:46,800
在pod中运行
containers are running in the pod

4121
03:16:46,800 --> 03:16:48,239
比如说你的微服务容器
and let's say your micro service

4122
03:16:48,239 --> 03:16:50,319
正在pod的端口3000运行
container is running at pod

4123
03:16:50,319 --> 03:16:53,840
而日志容器
3000 and your logging container

4124
03:16:53,840 --> 03:16:57,200
在端口9000上运行
let's say is running on port 9000

4125
03:16:57,200 --> 03:17:00,640
这意味着这两个端口将被打开
this means that those two ports will be now open

4126
03:17:00,640 --> 03:17:04,000
并且可以在pod内访问
and accessible inside the pod and pod

4127
03:17:04,000 --> 03:17:06,399
pod也会从被分配给节点的一个范围内
will also get an ip address

4128
03:17:06,399 --> 03:17:10,080
得到一个ip地址
from a range that is assigned to a node

4129
03:17:10,080 --> 03:17:13,520
它的工作方式是
so the way it works is that if you have

4130
03:17:13,520 --> 03:17:17,680
如果您的kubernetes集群中有三个worker节点
for example three worker nodes in your kubernetes cluster

4131
03:17:17,680 --> 03:17:21,520
每个工作节点将获得一个集群内部的
each worker node will get a range of ip addresses

4132
03:17:21,520 --> 03:17:24,479
ip地址的范围
which are internal in the cluster so for

4133
03:17:24,479 --> 03:17:31,439
比如node 1将获得ip地址范围是10.2.1.x
example the pod one will get ip addresses from a range of 10.2.1

4134
03:17:31,439 --> 03:17:35,439
第二个worker节点将获得这个ip范围
onwards the second worker node will get this ip range

4135
03:17:35,439 --> 03:17:37,439
第三个worker节点将得到这个
and the third worker node will get this

4136
03:17:37,439 --> 03:17:42,880
假设这个pod在node 2启动，因此它得到一个像这样的ip地址
one so let's say this pod starts on node2 so it get an ip address

4137
03:17:42,880 --> 03:17:46,399
如果你想查看集群中的pod的ip地址
that looks like this if you want to see the ip addresses

4138
03:17:46,399 --> 03:17:50,080
你可以实际上
of your pods in the cluster you can actually

4139
03:17:50,080 --> 03:17:53,279
使用kubectl get pod -o wide命令
check them using cube ctl get pod output

4140
03:17:53,279 --> 03:17:55,680
你会得到一些
wide command where you will get some

4141
03:17:55,680 --> 03:17:57,760
关于pod的额外信息
extra information about the pods

4142
03:17:57,760 --> 03:17:59,840
包括它的ip地址
including its ip address and here you

4143
03:17:59,840 --> 03:18:02,640
会看到它被分配的ip地址
will see the ip address that it got assigned

4144
03:18:02,640 --> 03:18:06,560
正如我提到的，这些都来自ip地址的一个范围
and as i mentioned these are from the ip address range

4145
03:18:06,560 --> 03:18:08,479
即集群中的每个worker节点会获得的范围
that each worker node in the cluster

4146
03:18:08,479 --> 03:18:11,520
这是从第一个worker节点的
will get so this is from the first worker node

4147
03:18:11,520 --> 03:18:14,560
这些是第二个worker节点的
and these are from the second worker node

4148
03:18:14,560 --> 03:18:16,479
现在我们可以利用这个ip地址和端口号
so now we can access those containers

4149
03:18:16,479 --> 03:18:18,880
访问这些pod内的容器了
inside the pod at this ip address

4150
03:18:18,880 --> 03:18:22,880
如果我们设置副本数为2
at these ports if we set the replica count to 2

4151
03:18:22,880 --> 03:18:24,560
我们将有另一个pod
we're going to have another pod which is

4152
03:18:24,560 --> 03:18:26,479
和第一个pod相同
identical to the first one

4153
03:18:26,479 --> 03:18:28,640
会和它打开相同的端口
which will open the same ports and it

4154
03:18:28,640 --> 03:18:30,640
但是得到不同的ip地址
will get a different ip address

4155
03:18:30,640 --> 03:18:33,920
假设它从worker节点1启动
let's say if it starts on worker node 1

4156
03:18:33,920 --> 03:18:37,200
你会得到一个看起来像这样的ip地址
you will get an ip address that looks something like this

4157
03:18:37,200 --> 03:18:39,359
现在我们假设这个微服务
now let's say this microservice is

4158
03:18:39,359 --> 03:18:41,600
可通过浏览器访问
accessible through a browser

4159
03:18:41,600 --> 03:18:44,640
我们已经配置好了Ingress
so we have ingress configured and

4160
03:18:44,640 --> 03:18:48,560
想发送到微服务的来自浏览器的请求
the requests coming in from the browser to the micro service

4161
03:18:48,560 --> 03:18:51,840
将由Ingress处理
will be handled by ingress how does this

4162
03:18:51,840 --> 03:18:53,120
传入请求是如何从Ingress
incoming request

4163
03:18:53,120 --> 03:18:56,800
峰回路转 转发到pod的呢
get forwarded from ingress all the way to the pod

4164
03:18:56,800 --> 03:19:00,319
这是通过ClusterIP类型的service实现的
and that happens through a service a cluster ip

4165
03:19:00,319 --> 03:19:04,880
或者所谓的k8s中的内部service
or so-called internal service a service in kubernetes

4166
03:19:04,880 --> 03:19:08,160
和pod一样是组件，但并不是一个线程
is a component just like a pod but it's not a process

4167
03:19:08,160 --> 03:19:10,399
它只是一个抽象层
it's just an abstraction layer that

4168
03:19:10,399 --> 03:19:12,479
表示一个ip地址
basically represents an ip address

4169
03:19:12,479 --> 03:19:17,120
service将会得到一个可被访问的ip地址
so service will get an ip address that it is accessible at

4170
03:19:17,120 --> 03:19:20,720
service也将在某些端口可被访问
and service will also be accessible at a certain port

4171
03:19:20,720 --> 03:19:24,399
假设我们将这个端口定义为3200
let's say we define that port to be 3200

4172
03:19:24,399 --> 03:19:27,040
所以ingress会和service对话
so ingress will talk to the service or

4173
03:19:27,040 --> 03:19:28,479
经由这个端口移交请求
hand over the request

4174
03:19:28,479 --> 03:19:32,080
到这个ip地址
to the service at this ip address at this

4175
03:19:32,080 --> 03:19:35,439
这就是
port so this is how service is

4176
03:19:35,439 --> 03:19:38,160
集群内的service是如何可访问的
accessible within the cluster so the way

4177
03:19:38,160 --> 03:19:39,200
工作方式就是
it works is that

4178
03:19:39,200 --> 03:19:43,359
我们定义了Ingress规则
we define ingress rules that forward the request

4179
03:19:43,359 --> 03:19:46,399
基于请求地址转发请求
based on the request address

4180
03:19:46,399 --> 03:19:50,399
到特定的service
to certain services and we define the service by its

4181
03:19:50,399 --> 03:19:53,680
我们通过名称和dns解析来定义service
name and the dns resolution

4182
03:19:53,680 --> 03:19:56,160
后者将该service名映射到一个ip地址
then maps that service name to an ip

4183
03:19:56,160 --> 03:19:57,680
service于是得到了分配
address that the service

4184
03:19:57,680 --> 03:20:01,120
这就是Ingress怎么知道
actually got assigned so this is how ingress

4185
03:20:01,120 --> 03:20:04,560
如何与service交谈的
knows how to talk to the service so once

4186
03:20:04,560 --> 03:20:08,800
一旦请求被移交给了这个地址的service
the request gets handed over to the service at this address

4187
03:20:08,800 --> 03:20:11,040
然后service就会知道要转发该请求
then service will know to forward that

4188
03:20:11,040 --> 03:20:16,239
到注册为service端点的众多pod之一
request to one of those parts that are registered as the service

4189
03:20:16,239 --> 03:20:20,239
现在有两个问题，service是怎么知道
endpoints now here are two questions how does service know

4190
03:20:20,239 --> 03:20:23,520
它管理哪些pod或
which pods it is managing or which parts

4191
03:20:23,520 --> 03:20:25,359
将请求转发给哪些pod
to forward the request to

4192
03:20:25,359 --> 03:20:28,880
第二个问题是service怎么知道
and the second one is how does service know which port

4193
03:20:28,880 --> 03:20:33,600
对于那个特定的pod，通过哪个端口将请求转发给它
to forward that request to on that specific pod

4194
03:20:33,600 --> 03:20:36,960
第一个是由selector(选择器)定义的
the first one is defined by selectors

4195
03:20:36,960 --> 03:20:40,319
一个service会使用selector属性
a service identifies its member pods or its

4196
03:20:40,319 --> 03:20:44,319
标识其成员pod或其端点pod
endpoint parts using selector attribute

4197
03:20:44,319 --> 03:20:48,000
所以在我们创建的yaml文件中的spec部分
so in the service specification in the yaml file

4198
03:20:48,000 --> 03:20:49,840
我们会
from which we create the service we

4199
03:20:49,840 --> 03:20:52,000
指定selector属性
specify the selector attribute

4200
03:20:52,000 --> 03:20:55,279
那里可以定义键值对列表
that has a key value pairs defined as a list

4201
03:20:55,279 --> 03:20:58,560
这些键值对基本上是标签（也就是label）
now these key value pairs are basically labels

4202
03:20:58,560 --> 03:21:02,560
标识了应该与选择器匹配的pod
that pods should have to match that selector

4203
03:21:02,560 --> 03:21:05,439
所以在pod配置文件中
so in the pod configuration file we

4204
03:21:05,439 --> 03:21:09,040
我们指定pod在metadata中的labels部分
assign the parts certain labels in the metadata section

4205
03:21:09,040 --> 03:21:11,520
这些标签可以是任意名称
and these labels can be arbitrary name

4206
03:21:11,520 --> 03:21:12,399
所以我们可以写my-app
so we can say

4207
03:21:12,399 --> 03:21:15,920
或者给它其它标签
my app for example and give it some other labels

4208
03:21:15,920 --> 03:21:17,600
这基本上是我们自己定义的
this is basically something that we

4209
03:21:17,600 --> 03:21:20,160
我们可以给它起任何想起的名字
define ourselves we can give it any name that we want

4210
03:21:20,160 --> 03:21:22,640
这些只是键值对
these are just key value pairs that

4211
03:21:22,640 --> 03:21:24,000
用于识别一组pod
identify a set of

4212
03:21:24,000 --> 03:21:26,720
在service的yaml文件中，我们
pots and in the service yaml file then we

4213
03:21:26,720 --> 03:21:28,000
定义了选择器
define a selector

4214
03:21:28,000 --> 03:21:31,520
来匹配任何有这些标签的pod
to match any part that has all of these labels

4215
03:21:31,520 --> 03:21:33,120
这意味着如果我们有一个deployment组件
this means if we have a deployment

4216
03:21:33,120 --> 03:21:36,800
创建了三个pod副本
component that creates three replicas of parts

4217
03:21:36,800 --> 03:21:40,160
标签是my-app
with label called app my app

4218
03:21:40,160 --> 03:21:43,439
类型为microservice
and type microservice for example

4219
03:21:43,439 --> 03:21:45,920
在service的selector属性中
and in the service selector attribute we

4220
03:21:45,920 --> 03:21:47,760
定义这两个标签
define those two labels

4221
03:21:47,760 --> 03:21:50,960
然后service就会匹配所有这三个pod的副本
then service will match all of those three

4222
03:21:50,960 --> 03:21:53,600
它会注册所有这三个pod副本
pod replicas and it will register all

4223
03:21:53,600 --> 03:21:56,080
作为它的端点
three parts as its endpoints

4224
03:21:56,080 --> 03:21:57,680
就像我说的，它应该匹配所有
and as i said it should match all the

4225
03:21:57,680 --> 03:21:59,359
而不止一个
selectors not just one

4226
03:21:59,359 --> 03:22:02,960
这就是service如何知道哪个pod属于它
so this is how service will know which parts

4227
03:22:02,960 --> 03:22:06,319
即向哪里转发请求
belong to it meaning where to forward that

4228
03:22:06,319 --> 03:22:10,640
第二个问题是
request to the second question was if a pod has

4229
03:22:10,640 --> 03:22:13,120
如果一个pod有多个不同的端口开放
multiple ports open where two different

4230
03:22:13,120 --> 03:22:15,439
不同的应用程序在pod内部不同端口监听
applications are listening inside the pod

4231
03:22:15,439 --> 03:22:18,479
service如何知道到哪个端口
how does service know which port to

4232
03:22:18,479 --> 03:22:20,239
转发请求
forward the request to

4233
03:22:20,239 --> 03:22:23,920
这在targetPort属性中定义
and this is defined in the target port attribute

4234
03:22:23,920 --> 03:22:28,239
这个targetPort属性
so this target port attribute so let's say target port

4235
03:22:28,239 --> 03:22:31,040
在我们的例子中是3000
in our example is three thousand what

4236
03:22:31,040 --> 03:22:33,760
这意味着当我们创建service时
this means is that when we create the service

4237
03:22:33,760 --> 03:22:37,520
它会找到所有与selector相匹配的pod
it will find all the parts that match this selector

4238
03:22:37,520 --> 03:22:41,359
这些pod会变成service的端点
so these pods will become endpoints of the service

4239
03:22:41,359 --> 03:22:43,279
当service收到请求时
and when the service gets a request it

4240
03:22:43,279 --> 03:22:44,880
会随机选择其中一个pod副本
will pick one of those

4241
03:22:44,880 --> 03:22:48,319
因为它是负载均衡器
pod replicas randomly because it's a load balancer

4242
03:22:48,319 --> 03:22:51,520
它将发送接收到的请求
and it will send the request it received

4243
03:22:51,520 --> 03:22:55,520
到那个特定的pod
to that specific pod on a port

4244
03:22:55,520 --> 03:22:58,720
通过由targetPort属性定义的端口号
defined by target port attribute

4245
03:22:58,720 --> 03:23:02,080
在这种情况下，是3000
in this case 3000 also note that

4246
03:23:02,080 --> 03:23:05,200
还需要说明的是，当你创建一个service时
when you create a service kubernetes creates an

4247
03:23:05,200 --> 03:23:08,479
k8s将会创建一个端点对象，和service本身具有相同名称
endpoints object that has the same name as

4248
03:23:08,479 --> 03:23:11,600
kubernetes将会使用这个端点对象
the service itself and kubernetes will use this

4249
03:23:11,600 --> 03:23:14,720
来追踪
endpoints object to keep track of which

4250
03:23:14,720 --> 03:23:18,080
哪个pod是service的成员
parts are members of the service or as i

4251
03:23:18,080 --> 03:23:20,720
或者说哪些pod是service的端点
said which parts are the end points

4252
03:23:20,720 --> 03:23:23,279
这是动态的
of the service and since this is dynamic

4253
03:23:23,279 --> 03:23:25,040
因为每当你创建一个新的pod副本
because whenever you create a new pod

4254
03:23:25,040 --> 03:23:27,040
或pod死亡时
replica or a pod dies

4255
03:23:27,040 --> 03:23:29,439
端点会被更新
the end points get updated so this

4256
03:23:29,439 --> 03:23:31,840
这个对象会跟踪到
object will basically track that

4257
03:23:31,840 --> 03:23:34,080
注意这里的port属性是任意的
and note here that the service port

4258
03:23:34,080 --> 03:23:37,359
您可以自己定义
itself is arbitrary so you can define it yourself

4259
03:23:37,359 --> 03:23:39,920
而targetPort不是任意的
whereas the target port is not arbitrary

4260
03:23:39,920 --> 03:23:41,279
它必须匹配
it has to match

4261
03:23:41,279 --> 03:23:46,640
容器内应用程序正在监听的端口
the port where container the application container inside the pod

4262
03:23:46,640 --> 03:23:51,520
假设我们的微服务应用程序
is listening at now let's say our microservice application

4263
03:23:51,520 --> 03:23:55,680
通过Ingress以及内部ClusterIP类型service
got its requests from the browser through ingress and

4264
03:23:55,680 --> 03:23:58,800
从浏览器获得请求
internal cluster ip service and now it

4265
03:23:58,800 --> 03:24:00,960
现在它需要与数据库通信
needs to communicate with the database

4266
03:24:00,960 --> 03:24:04,160
来处理请求
to handle that request for example and

4267
03:24:04,160 --> 03:24:06,479
在我们的例子中，我们假设
in our example let's assume that the

4268
03:24:06,479 --> 03:24:10,080
微服务应用程序使用mongodb数据库
microservice application uses mongodb database

4269
03:24:10,080 --> 03:24:13,680
集群中我们有mongodb的两个副本
so we have two replicas of mongodb in the cluster

4270
03:24:13,680 --> 03:24:17,680
它们也是对应service的端点
which also have their own service endpoint

4271
03:24:17,680 --> 03:24:21,600
mongodb对应service也是ClusterIp类型
so mongodb service is also of cluster ip

4272
03:24:21,600 --> 03:24:26,479
它有自己的ip地址，所以现在pod内的微服务应用程序
and it has its own ip address so now the microservice application

4273
03:24:26,479 --> 03:24:30,080
可以与mongodb数据库对话
inside the pod can talk to the mongodb database

4274
03:24:30,080 --> 03:24:33,120
也能使用service端点
also using the service endpoint so the

4275
03:24:33,120 --> 03:24:35,439
所以来自左面两个pod之一的获得请求的哪个pod
request will come from one of the parts

4276
03:24:35,439 --> 03:24:36,880
将会提交请求
that gets the request

4277
03:24:36,880 --> 03:24:40,720
到mongodb服务
from the service to the mongodb service

4278
03:24:40,720 --> 03:24:43,760
在service开放的ip地址和端口上
at this ip address and the port that

4279
03:24:43,760 --> 03:24:47,760
接着Service将再一次
service has open and then service will again

4280
03:24:47,760 --> 03:24:50,880
选择一个pod副本
select one of those pod replicas and

4281
03:24:50,880 --> 03:24:55,600
转发请求到指定pod
forward that request to the selected pod at

4282
03:24:55,600 --> 03:24:59,040
经由targetPort定义的端口号
the port the target port defined here

4283
03:24:59,040 --> 03:25:02,720
这是pod内部mongodb应用监听的端口
and this is the port where mongodb application inside the pod

4284
03:25:02,720 --> 03:25:06,239
让我们假设一下
is listening at now let's assume that

4285
03:25:06,239 --> 03:25:09,279
在mongodb pod里面有另一个容器正在运行
inside that mongodb pod there is another

4286
03:25:09,279 --> 03:25:14,640
在给prometehus监控程序选择监控指标
container running that selects the monitoring metrics for prometheus for example

4287
03:25:14,640 --> 03:25:17,200
并将是mongodb输出结果的地方(exporter)
and that will be a mongodb exporter and

4288
03:25:17,200 --> 03:25:21,760
这个容器正在9216端口运行
that container let's say is running at port 9216

4289
03:25:21,760 --> 03:25:24,800
这就是该应用程序可被访问的地方
and this is where the application is accessible at

4290
03:25:24,800 --> 03:25:27,920
在集群里我们有一个prometheus应用程序
and in the cluster we have a prometheus application

4291
03:25:27,920 --> 03:25:31,279
将下载监控指标
that scrapes the metrics endpoint from

4292
03:25:31,279 --> 03:25:34,800
从这个mongodb exporter容器
this mongodb exporter container from

4293
03:25:34,800 --> 03:25:38,239
从这个端点
this endpoint now that means that service

4294
03:25:38,239 --> 03:25:42,479
意味着service必须处理两个不同的端点请求
has to handle two different endpoint requests

4295
03:25:42,479 --> 03:25:46,319
同样意味着它有两个自己的端口开放
which also means that service has two of its own

4296
03:25:46,319 --> 03:25:50,239
来处理两个不同的请求
ports open for handling these two different

4297
03:25:50,239 --> 03:25:53,279
一个是从客户端来的请求
requests one from the clients that want

4298
03:25:53,279 --> 03:25:55,200
想要与mongodb数据库对话
to talk to the mongodb database

4299
03:25:55,200 --> 03:25:57,439
还有一个来自prometheus
and one from the clients like prometheus

4300
03:25:57,439 --> 03:25:59,200
想要与mongodb exporter程序对话
that want to talk to the mongodb

4301
03:25:59,200 --> 03:26:01,680
这是一个
exporter application and this is an

4302
03:26:01,680 --> 03:26:04,720
多端口service的示例
example of a multi-port service

4303
03:26:04,720 --> 03:26:08,000
注意，当你在一个service中
and note here that when you have multiple

4304
03:26:08,000 --> 03:26:11,200
定义了多个端口
ports defined in a service you have to name

4305
03:26:11,200 --> 03:26:14,239
你必须命名这些端口，如果只有一个端口的话
those ports if it's just one port then you can

4306
03:26:14,239 --> 03:26:16,399
就让它这样匿名
leave it so to say anonymous you don't

4307
03:26:16,399 --> 03:26:18,000
不必使用name属性
have to use the name attribute

4308
03:26:18,000 --> 03:26:20,479
此时它是可选的，但如果你有定义多个端口
it's optional but if you have multiple

4309
03:26:20,479 --> 03:26:22,720
就必须给它们中的每一个命名
ports defined then you have to name

4310
03:26:22,720 --> 03:26:26,160
这是ClusterIP的例子
each one of those so these were examples of cluster

4311
03:26:26,160 --> 03:26:28,800
现在让我们看另一个
ip service type now let's see another

4312
03:26:28,800 --> 03:26:30,399
service的类型
service type which is called

4313
03:26:30,399 --> 03:26:32,720
其被称为headless service
headless service so let's see what

4314
03:26:32,720 --> 03:26:34,720
让我们看看什么是headless service
headless service type is

4315
03:26:34,720 --> 03:26:38,560
正如我们看到的，到达service的每个请求都被转发到
as we saw each request to the service is forwarded to

4316
03:26:38,560 --> 03:26:41,680
注册为service端点的
one of the pod replicas that are

4317
03:26:41,680 --> 03:26:44,560
pod副本中的一个
registered as service endpoints

4318
03:26:44,560 --> 03:26:47,200
但想象一下如果客户想要选择性地
but imagine if a client wants to

4319
03:26:47,200 --> 03:26:49,359
与其中一个pod直接通信
communicate with one of the parts

4320
03:26:49,359 --> 03:26:53,120
或者如果
directly and selectively or what if the

4321
03:26:53,120 --> 03:26:56,880
端点pod彼此需要直接通信
endpoint parts need to communicate with each other

4322
03:26:56,880 --> 03:26:58,720
而不经过service
directly without going through the

4323
03:26:58,720 --> 03:27:01,840
显然在这种情况下，随机选择其中一个pod
service obviously in this case it wouldn't make sense to

4324
03:27:01,840 --> 03:27:04,880
进行service端点地对话是没有意义地
talk to the service endpoint which will randomly select

4325
03:27:04,880 --> 03:27:08,399
因为我们想要与特定的pod沟通
one of the parts because we want the communication

4326
03:27:08,399 --> 03:27:12,960
那还有一种情况
with specific parts now what would be such a use case

4327
03:27:12,960 --> 03:27:15,439
有必要用headless的情况是
a use case where this is necessary is

4328
03:27:15,439 --> 03:27:18,640
当我们在kubernetes中部署有状态应用时
when we're deploying stateful applications in kubernetes

4329
03:27:18,640 --> 03:27:23,040
有状态应用程序，如mysql数据库,mongobd,elasticsearch等等
stateful applications like databases mysql mongodb

4330
03:27:23,040 --> 03:27:28,160
对于这样的应用程序，pod副本是不尽相同的
elasticsearch and so on in such applications the pod replicas

4331
03:27:28,160 --> 03:27:32,319
每一个都有自己的状态
aren't identical but rather each one has its individual

4332
03:27:32,319 --> 03:27:35,200
和特征，例如
state and characteristic for example if

4333
03:27:35,200 --> 03:27:37,359
如果我们正在部署一个mysql应用程序
we're deploying a mysql application

4334
03:27:37,359 --> 03:27:39,520
你会有一个mysql的master实例
you would have a master instance of

4335
03:27:39,520 --> 03:27:43,439
和worker实例
mysql and worker instances of mysql application

4336
03:27:43,439 --> 03:27:46,640
master是唯一被允许
and master is the only pod allowed to

4337
03:27:46,640 --> 03:27:48,720
写数据库的
write to the database and the worker

4338
03:27:48,720 --> 03:27:51,359
worker pods必须连接到master
pods must connect to the master

4339
03:27:51,359 --> 03:27:55,279
在master pod对数据库进行更改后
to synchronize their data after masterpod has

4340
03:27:55,279 --> 03:27:58,160
同步他们的数据
made changes to the database so they get

4341
03:27:58,160 --> 03:27:59,920
从而获得最新的数据
the up-to-date data as well

4342
03:27:59,920 --> 03:28:02,960
当新的worker开始工作时，必须
and when new worker pod starts it must

4343
03:28:02,960 --> 03:28:04,960
直接与最近建立的worker节点联系
connect directly to the most

4344
03:28:04,960 --> 03:28:08,239
从那里克隆数据
recent worker node to clone the data from

4345
03:28:08,239 --> 03:28:11,680
同时还要更新数据状态
and also get up to date with the data state

4346
03:28:11,680 --> 03:28:14,880
这是最常见的
so that's the most common use case where you need

4347
03:28:14,880 --> 03:28:17,920
你需要直接与pod通信的用例
direct communication with individual pods

4348
03:28:17,920 --> 03:28:21,520
在这种情况下，客户端要连接到所有pod
for such case for a client to connect to all pods

4349
03:28:21,520 --> 03:28:23,840
它需要找到
individually it needs to figure out the

4350
03:28:23,840 --> 03:28:26,720
每个pod的ip地址
ip address of each individual pod

4351
03:28:26,720 --> 03:28:28,640
实现这一目标的一个方法是
one option to achieve this would be to

4352
03:28:28,640 --> 03:28:31,359
对kubernetes api服务器调用api
make an api call to kubernetes api

4353
03:28:31,359 --> 03:28:35,200
它将返回pod及其ip地址的列表
server and it will return the list of pods

4354
03:28:35,200 --> 03:28:38,800
但这样会
and their ip addresses but this will make your

4355
03:28:38,800 --> 03:28:42,960
让你的应用程序与kubernetes特定的api的耦合程度太高
application too tied to the kubernetes specific api

4356
03:28:42,960 --> 03:28:44,479
而且这也是低效的
and also this will be inefficient

4357
03:28:44,479 --> 03:28:46,000
因为每次你想
because you will have to get

4358
03:28:46,000 --> 03:28:47,840
连接到其中一个pod
the whole list of parts and their ip

4359
03:28:47,840 --> 03:28:52,239
都必须得到完整的pod清单和ip地址
addresses every time you want to connect to one of the pods but

4360
03:28:52,239 --> 03:28:54,800
作为另一种解决方案，kubernetes允许客户端
as an alternative solution kubernetes allows

4361
03:28:54,800 --> 03:28:58,160
通过dns解析查找pod的ip地址
clients to discover pod ip addresses

4362
03:28:58,160 --> 03:29:01,359
通常它的工作原理是
through dns lookups and usually the way

4363
03:29:01,359 --> 03:29:03,439
当客户端执行一个service的
it works is that when a client performs

4364
03:29:03,439 --> 03:29:06,080
dns解析时
a dns lookup for a service the dns

4365
03:29:06,080 --> 03:29:10,160
dns服务器返回属于service的单个ip地址
server returns a single ip address which belongs to the service

4366
03:29:10,160 --> 03:29:13,279
这将是ClusterIP类型service的地址
and this will be the services cluster ip address

4367
03:29:13,279 --> 03:29:17,040
我们之前看到过
which we saw previously however if you tell kubernetes

4368
03:29:17,040 --> 03:29:20,479
但是如果你通过在创建service时
that you don't need a cluster ip address of the service

4369
03:29:20,479 --> 03:29:23,600
设置ClusterIP字段为none
by setting the cluster ip field to none

4370
03:29:23,600 --> 03:29:26,080
来告诉kubernetes您不需要ClusterIP的地址
when creating a service then the dns

4371
03:29:26,080 --> 03:29:29,200
dns服务器将返回pod的ip地址
server will return the pod ip addresses instead

4372
03:29:29,200 --> 03:29:33,200
而不是service的ip地址，现在客户端可以
of the services ip address and now the client can

4373
03:29:33,200 --> 03:29:37,520
做一个简单的dns解析以获得
do a simple dns lookup to get the ip address

4374
03:29:37,520 --> 03:29:40,960
service成员pod的ip地址
of the pods that are members of that service

4375
03:29:40,960 --> 03:29:44,560
然后客户端可以使用该ip地址连接到
and then client can use that ip address to connect to

4376
03:29:44,560 --> 03:29:49,120
他想通信的指定pod，或者所有的pod
the specific part he wants to talk to or all of the parts

4377
03:29:49,120 --> 03:29:51,520
我们在service配置文件中
so the way we define a headless service

4378
03:29:51,520 --> 03:29:53,840
定义headless service的方式
in a service configuration file

4379
03:29:53,840 --> 03:29:57,359
基本上是将ClusterIP设置为None
is basically setting the cluster ip to none

4380
03:29:57,359 --> 03:29:59,040
所以当我们用这个配置文件
so when we create these service from

4381
03:29:59,040 --> 03:30:01,200
创建这些service时
this configuration file kubernetes

4382
03:30:01,200 --> 03:30:05,040
kubernetes不会为service分配ip地址
will not assign the service a cluster ip address

4383
03:30:05,040 --> 03:30:07,359
当我们列出service时
and we can see that in the output when i

4384
03:30:07,359 --> 03:30:09,040
我们可以在输出中看到这点
list my services

4385
03:30:09,040 --> 03:30:12,560
我有一个ClusterIP的service被创建用于微服务
so i have a cluster ip service that i created

4386
03:30:12,560 --> 03:30:15,120
以及一个headless service
for the microservice and a headless

4387
03:30:15,120 --> 03:30:17,200
请注意，当我们
service and note here that when we

4388
03:30:17,200 --> 03:30:19,120
在集群中部署有状态应用程序时
deploy stateful applications

4389
03:30:19,120 --> 03:30:22,000
以mongodb为例
in the cluster like mongodb for example

4390
03:30:22,000 --> 03:30:26,239
我们有正常的ClusterIP Service
we have the normal service the cluster ip service

4391
03:30:26,239 --> 03:30:29,359
处理基本的到mongodb通信
that basically handles the communication

4392
03:30:29,359 --> 03:30:34,000
或者在pod内的其他容器
to mongodb and maybe other container inside the pod

4393
03:30:34,000 --> 03:30:37,200
除了那个service我们还有headless service
and in addition to that service we have a headless service

4394
03:30:37,200 --> 03:30:39,279
所以我们总是有这两个service
so we always have these two services

4395
03:30:39,279 --> 03:30:40,560
互相扶持
alongside each other

4396
03:30:40,560 --> 03:30:44,479
这样就可以实现通常的对这类用例的负载平衡
so this can do the usual load balancing stuff for

4397
03:30:44,479 --> 03:30:48,319
而对那种用例
this kind of use case and for use cases

4398
03:30:48,319 --> 03:30:50,800
即客户端需要直接与
where client needs to communicate with

4399
03:30:50,800 --> 03:30:53,200
其中一个pod通信
one of those parts directly like a

4400
03:30:53,200 --> 03:30:54,960
比如master节点直接执行命令
master node directly to

4401
03:30:54,960 --> 03:30:59,120
或者pod之间互相交流
perform the right commands or the pods to talk to each other

4402
03:30:59,120 --> 03:31:01,760
用于数据同步
for data synchronization the headless

4403
03:31:01,760 --> 03:31:04,560
headless service将派上用场
service will be used for that

4404
03:31:04,560 --> 03:31:07,520
当我们定义service的配置时
when we define a service configuration

4405
03:31:07,520 --> 03:31:08,800
我们可以指定
we can specify

4406
03:31:08,800 --> 03:31:12,319
service的类型
a type of the service and the type attribute

4407
03:31:12,319 --> 03:31:14,560
type属性可以有三个不同的值
can have three different values it could

4408
03:31:14,560 --> 03:31:16,800
默认为ClusterIP
be cluster ip which is a default

4409
03:31:16,800 --> 03:31:19,040
这就是为什么我们不需要明确指明
that's why we don't have to specify that

4410
03:31:19,040 --> 03:31:22,000
此外还有NodePort和Load Balancer(负载均衡器)
we have a node port and load balancer

4411
03:31:22,000 --> 03:31:24,640
NodePort类型创建了一个service
so type node port basically creates a

4412
03:31:24,640 --> 03:31:26,560
该service在每个worker节点上
service that is accessible

4413
03:31:26,560 --> 03:31:29,760
可通过静态端口访问
on a static port on each worker node

4414
03:31:29,760 --> 03:31:32,000
现在来比较一下
in the cluster now to compare that to

4415
03:31:32,000 --> 03:31:33,760
我们之前的例子
our previous example

4416
03:31:33,760 --> 03:31:36,880
ClusterIP仅仅是在进群内部可访问的
the cluster ip service is only accessible

4417
03:31:36,880 --> 03:31:40,720
没有外部路由可以
within the cluster itself so no external traffic can

4418
03:31:40,720 --> 03:31:44,720
直接访问ClusterIP
directly address the cluster ip service

4419
03:31:44,720 --> 03:31:47,840
然而，NodePort类型的service使
the node port service however makes the

4420
03:31:47,840 --> 03:31:51,359
外部路由可以在每个worker节点
external traffic accessible on static

4421
03:31:51,359 --> 03:31:54,479
的静态端口实现访问
or fixed port on each worker node

4422
03:31:54,479 --> 03:31:56,880
所以在这种情况下，不用Ingress
so in this case instead of ingress the

4423
03:31:56,880 --> 03:31:59,040
浏览器请求将直接来到
browser request will come directly

4424
03:31:59,040 --> 03:32:02,160
该worker节点的端口
to the worker node at the port that

4425
03:32:02,160 --> 03:32:05,200
该端口由service中的spec部分定义
the service specification defines

4426
03:32:05,200 --> 03:32:09,120
而NodePort类service开放的端口
and the port that node port service type exposes

4427
03:32:09,120 --> 03:32:12,160
由nodePort属性定义
is defined in the node port attribute

4428
03:32:12,160 --> 03:32:15,520
这里注意nodePort的值
and here note that the node port value

4429
03:32:15,520 --> 03:32:18,640
有一个预定义范围
has a predefined range between thirty thousand

4430
03:32:18,640 --> 03:32:22,080
介于30000-32767之间
and thirty two thousand seven hundred seven

4431
03:32:22,080 --> 03:32:25,279
你可以从该范围中取一个值
so you can have one of the values

4432
03:32:25,279 --> 03:32:28,560
作为nodePort值
from that range as a node port value

4433
03:32:28,560 --> 03:32:30,160
任何超出这个范围的值都不会被接受
anything outside that range won't be

4434
03:32:30,160 --> 03:32:32,720
这就意味着NodePort类型的service
accepted so this means that

4435
03:32:32,720 --> 03:32:36,160
可以被外部路由，如浏览器的请求
the node port service is accessible for the external traffic

4436
03:32:36,160 --> 03:32:40,560
通过worker节点的ip地址
like browser request for example at ip address of the worker node

4437
03:32:40,560 --> 03:32:43,680
和这里定义的节点端口来访问
and the node port defined here however

4438
03:32:43,680 --> 03:32:46,880
然而就像在ClusterIP中一样
just like in cluster ip we have a port

4439
03:32:46,880 --> 03:32:48,880
我们有一个service的端口
of the service so when we create the

4440
03:32:48,880 --> 03:32:51,200
所以当我们创建NodePort时
node port service a cluster ip service

4441
03:32:51,200 --> 03:32:53,600
一个NodePort service可到达的ClusterIP
to which the node port service will route

4442
03:32:53,600 --> 03:32:56,720
也会自动被创建
is automatically created and here as you see

4443
03:32:56,720 --> 03:33:00,160
如果我列出了service
if i list the services the node port

4444
03:33:00,160 --> 03:33:02,399
NodePort会有一个ClusterIP地址
will have a cluster ip address

4445
03:33:02,399 --> 03:33:06,160
对于每个ip地址，它也将有开放的端口
and for each ip address it will also have the ports

4446
03:33:06,160 --> 03:33:09,520
也就是该service可被访问的地方
open where the service is accessible at

4447
03:33:09,520 --> 03:33:13,520
还要注意service包揽所有worker节点
and also note that service spends all the worker nodes

4448
03:33:13,520 --> 03:33:16,720
所以如果你有三个pod副本
so if you have three pod replicas

4449
03:33:16,720 --> 03:33:18,800
分别在三个不同的节点上
on three different notes basically the

4450
03:33:18,800 --> 03:33:21,600
service有能力处理
service will be able to handle that request

4451
03:33:21,600 --> 03:33:24,560
在任何worker节点上的请求
coming on any of the worker nodes and

4452
03:33:24,560 --> 03:33:26,399
然后转发给其中一个pod副本
then forward it to one of those

4453
03:33:26,399 --> 03:33:29,680
现在这种类型的service
pod replicas now that type of service

4454
03:33:29,680 --> 03:33:32,160
开放能力不是很有效，而且
exposure is not very efficient and also

4455
03:33:32,160 --> 03:33:34,960
不安全，因为你开放了
not secure because you are basically opening the ports

4456
03:33:34,960 --> 03:33:38,640
可以直接与每个worker节点的service对话的端口
to directly talk to the services on each worker node

4457
03:33:38,640 --> 03:33:41,760
所以外部客户端
so the external clients basically have

4458
03:33:41,760 --> 03:33:44,080
能够直接访问worker节点
access to the worker nodes directly

4459
03:33:44,080 --> 03:33:47,359
如果我们让所有的service
so if we give all the services this

4460
03:33:47,359 --> 03:33:51,200
都是NodePort类型
node port service type then we would have a bunch of

4461
03:33:51,200 --> 03:33:53,680
worker节点就会开放一堆端口
ports open on the worker nodes clients

4462
03:33:53,680 --> 03:33:56,080
可供客户端从外面直接通信
from outside can directly talk to

4463
03:33:56,080 --> 03:33:57,840
所以它不是很高效和安全的方式
so it's not very efficient and secure

4464
03:33:57,840 --> 03:33:59,840
有一种更好的选择
way to handle that and as a better

4465
03:33:59,840 --> 03:34:03,040
有一种负载均衡器service类型
alternative there is a load balancer service type

4466
03:34:03,040 --> 03:34:05,040
使用负载均衡器
and the way it works with load balance

4467
03:34:05,040 --> 03:34:08,399
使得service更容易从外部访问
or service type is that the service becomes accessible

4468
03:34:08,399 --> 03:34:11,200
通过云供应商的负载均衡器功能
externally through a cloud provider's

4469
03:34:11,200 --> 03:34:14,160
每个云供应商
load balancer functionality so each cloud provider

4470
03:34:14,160 --> 03:34:17,279
都有自己的原生负载平衡器实现
has its own native load balancer implementation

4471
03:34:17,279 --> 03:34:20,319
而那会在我们创建负载均衡器类型service时
and that is created and used whenever we

4472
03:34:20,319 --> 03:34:22,560
被创建并使用
create a load balancer service type

4473
03:34:22,560 --> 03:34:26,399
谷歌云平台、aws 、zure、openstack等等
uh google cloud platform aws azure leenode

4474
03:34:26,399 --> 03:34:30,160
它们都提供这样的功能
openstack and so on all of them offer this functionality

4475
03:34:30,160 --> 03:34:33,680
所以当我们创建一个负载均衡器类型Service
so whenever we create a load balancer service

4476
03:34:33,680 --> 03:34:36,239
NodePort和ClusterIP类型service
node port and cluster ip services are

4477
03:34:36,239 --> 03:34:38,479
由kubernetes自动创建
created automatically by kubernetes

4478
03:34:38,479 --> 03:34:42,000
云平台的外部负载均衡器
to which the external load balancer of the cloud

4479
03:34:42,000 --> 03:34:45,040
会将路由引向它们
platform will route the traffic to

4480
03:34:45,040 --> 03:34:46,960
这是我们如何
and this is an example of how did we

4481
03:34:46,960 --> 03:34:50,319
定义负载均衡器service的一个例子
define load balancer service configuration

4482
03:34:50,319 --> 03:34:52,080
所以不是NodePort类型，而是
so instead of node port type we have a

4483
03:34:52,080 --> 03:34:54,319
负载平衡器
load balancer and

4484
03:34:54,319 --> 03:34:56,479
同样的，我们有
the same way we have the port of the

4485
03:34:56,479 --> 03:34:59,600
属于ClusterIP的端口
service which belongs to the cluster ip

4486
03:34:59,600 --> 03:35:03,520
我们有nodePort，也就是
and we have the node port which is the port

4487
03:35:03,520 --> 03:35:05,680
在worker节点上开放的
that opens on the worker node but it's

4488
03:35:05,680 --> 03:35:07,120
但是它不能直接从外部访问
not directly accessible

4489
03:35:07,120 --> 03:35:10,880
只能通过负载均衡器本身访问
externally but only through the load balancer itself

4490
03:35:10,880 --> 03:35:12,720
所以入口点变成了一个负载均衡器
so the entry point becomes a load

4491
03:35:12,720 --> 03:35:15,040
它会将路由
balancer first and it can then

4492
03:35:15,040 --> 03:35:18,080
引导到worker节点的nodePort
direct the traffic to node port

4493
03:35:18,080 --> 03:35:22,560
以及内部的ClusterIP
on the worker node and the cluster ip the internal service

4494
03:35:22,560 --> 03:35:24,720
这就是负载均衡器service
so that's how the flow would work with

4495
03:35:24,720 --> 03:35:26,640
的工作流程
the load balancer service

4496
03:35:26,640 --> 03:35:28,399
换句话说，负载均衡器类型service
so in other words the load balancer

4497
03:35:28,399 --> 03:35:30,080
是NodePort类型的拓展
service type is an extension

4498
03:35:30,080 --> 03:35:34,160
而NodePort又是ClusterIP的拓展
of the node port type which itself is an extension

4499
03:35:34,160 --> 03:35:37,359
接着
of the cluster ip type and again

4500
03:35:37,359 --> 03:35:40,640
如果我创建一个负载均衡器类型
if i create a load balancer service type and

4501
03:35:40,640 --> 03:35:42,319
并列出所有service
list all the services you can see the

4502
03:35:42,319 --> 03:35:44,800
您可以看到对于每种service类型在显示上的差异
differences in the display as well

4503
03:35:44,800 --> 03:35:49,840
您可以看到ip地址、类型
where for each service type you see the ip addresses you see the type

4504
03:35:49,840 --> 03:35:54,080
以及开放的端口
and you see the ports that the service has opened

4505
03:35:54,080 --> 03:35:56,399
我应该在这里提一下
and i should mention here that in a real

4506
03:35:56,399 --> 03:35:58,160
在真实的kubernetes设置示例中
kubernetes setup example

4507
03:35:58,160 --> 03:36:01,680
您可能不会将NodePort用于外部连接
you would probably not use node port for external connection

4508
03:36:01,680 --> 03:36:05,439
你可能会用它来进行快速的测试
you would maybe use it to test some surveys very quickly

4509
03:36:05,439 --> 03:36:08,000
但不是用于生产用例
but not for production use cases so for

4510
03:36:08,000 --> 03:36:09,279
举个例子，如果你有
example if you have a

4511
03:36:09,279 --> 03:36:11,120
可通过浏览器访问的应用程序
application that is accessible through

4512
03:36:11,120 --> 03:36:13,279
要么可以为这样的请求
browser you will either configure

4513
03:36:13,279 --> 03:36:16,160
配置一个Ingress
ingress for each such request so you

4514
03:36:16,160 --> 03:36:19,200
这样你会有ClusterIP作为内部service
would have internal services the cluster ip services that

4515
03:36:19,200 --> 03:36:21,680
由Ingress转发到
ingress will route to or you would have

4516
03:36:21,680 --> 03:36:24,800
或者你也可以使用云平台
a load balancer that uses the cloud platform's

4517
03:36:24,800 --> 03:36:27,920
原生的负载均衡器实现
native load balancer implementation

4518
03:36:27,920 --> 03:36:30,399
恭喜你能坚持到最后
congratulations you made it till the end

4519
03:36:30,399 --> 03:36:31,840
我希望你学到了很多
i hope you learned a lot

4520
03:36:31,840 --> 03:36:33,520
并且从这门课中学到了一些有价值的知识
and got some valuable knowledge from

4521
03:36:33,520 --> 03:36:36,560
如果你想了解更多现代化的
this course if you want to learn about modern

4522
03:36:36,560 --> 03:36:38,960
devops工具，请务必查看我的
devops tools be sure to check out my

4523
03:36:38,960 --> 03:36:40,479
关于该主题的教程
tutorials on that topic

4524
03:36:40,479 --> 03:36:42,319
订阅我的频道以了解更多内容
and subscribe to my channel for more

4525
03:36:42,319 --> 03:36:44,479
如果你想与我保持联系
content also if you want to stay

4526
03:36:44,479 --> 03:36:47,200
你可以在社交媒体上关注我
connected you can follow me on social media

4527
03:36:47,200 --> 03:36:50,000
或者加入私人facebook群
or join the private facebook group i

4528
03:36:50,000 --> 03:36:51,840
我将在那里见到你
would love to see you there

4529
03:36:51,840 --> 03:36:53,920
谢谢大家的收看
so thank you for watching and see you in

4530
03:36:53,920 --> 03:36:56,720
下一个视频再见
the next video
